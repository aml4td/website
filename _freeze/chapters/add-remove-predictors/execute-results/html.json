{
  "hash": "3dfed414097fc891e8ba8c00ee5e975c",
  "result": {
    "engine": "knitr",
    "markdown": "---\nknitr:\n  opts_chunk:\n    cache.path: \"../_cache/add-remove-predictors/\"\n---\n\n\n# Interactions and Nonlinear Features {#sec-add-remove-features}\n\n\n\n\n\n\n\nPrevious chapters have primarily focused on preprocessing predictor columns. Models can have sensitivities to aspects of predictors. For instance: \n\n- If a model is sensitive to colinearity, then embeddings are a way to compensate for that weakness.\n- We must find numerical encodings if a model cannot consumer qualitative predictors as non-numeric data. \n\nWe call methods associated _what the model needs_ as preprocessing.\n\nIn this chapter, we’ll discuss techniques that address _what the data requires_. For example, if the relationship between a predictor is nonlinear, how can we represent that predictor so that the relationship can be modeled? This is an _outcome-specific issue_ and not directly motivated by the model. This is one of the primary applications of **feature engineering**: what can we do to make it easier for the model to understand and predict the outcome? \n\nLet’s look at a simple example. Occasionally, predictor pairs work better in unison rather than as main effects. For example, consider the data in @fig-two-class-corr(a), where two predictors are: \n\n- strictly positive,\n- significantly right-skewed, and\n- highly correlated. \n\nIn the predictors' original form, there is a significant overlap between the two classes of samples.  However, when the ratio of the predictors is used, the newly derived predictor better discriminates between classes (shown in @fig-two-class-corr(b)). While not a general rule, the three data characteristics above suggest that the modeler attempts to form ratios from two or more predictors ^[Alternatively, PCA after skewness-correcting transformations may be another good option.].\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Panel (a): two highly correlated, right-skewed predictors with two classes. Panel (b): sepration of classes using $log(A/B)$.](../figures/fig-two-class-corr-1.svg){#fig-two-class-corr fig-align='center' fig-alt='Panel (a): two highly correlated, right-skewed predictors with two classes. Panel (b): sepration of classes using $log(A/B)$.' width=80%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nIt is essential to understand that these _data_ require transformation. We can put the original predictors into a model as-is. The model won’t produce an error but won’t have good predictive performance. We can induce a separation of the classes when a joint feature is used. \n\nThis aspect of feature engineering depends on the data set so it is difficult to enumerate all possible techniques. In this chapter, we’ll describe a few commonly used methods: splines, interactions, and discretization (a.k.a. binning). \n\n## Interactions {#sec-interactions}\n\nWhen building models for prediction, the majority of variation in the outcome is generally explained by the cumulative effect of the important individual predictors.  For many problems, additional variation in the response can be explained by the effect of two or more predictors working in conjunction with each other.  \n\nThe healthcare industry has long understood the concept of interactions among drugs for treating specific diseases [@singh2017suppressive, @mokhtari2017combination, and @altorki2021neoadjuvant].  As an example of an interaction, consider treatment for the disease non-small cell lung cancer (NSCLC).  In a recent study, patients with an advanced stage of NSCLC with an EGFR mutation were given either osimertinib alone or osimertinib in combination with traditional chemotherapy [@tragrisso2023].   Patients taking the combination treatment had a significantly longer progression-free survival time than patients taking osmertinib alone.  Hence, the interaction of the treatments is more effective than the single treatment.  To summarize, two (or more) predictors interact if their combined impact is different (less or greater) than what would be expected from the added impact of each predictor alone.\n\nWe’ve already encountered an example of an interaction in @sec-eda-whole-game where the relationship between delivery time and the time of order differed across days of the week. This trend is reproduced in @fig-delivery-no-interact(a). The telltale sign of the interaction is that the trendlines are not parallel with one another; they have different rates of increase and cross. \n\nHow would this plot change if there was no interaction between the order time and day? To illustrate, we estimated trendlines in a way that coerced the nonlinear trend for order time to be the same.  @fig-delivery-no-interact(b) shows the results: parallel lines for each day of the week. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Delivery times versus the time of the order, colored by the day of the week. (a) A duplicate of a panel from @fig-delivery-predictors. (b) The same data with trendlines where the underlying model did _not_ allow an interaction between the delivery day and hour.](../figures/fig-delivery-no-interact-1.svg){#fig-delivery-no-interact fig-align='center' width=85%}\n:::\n:::\n\n\nThis example demonstrates an interaction between a numeric predictor (hour of order) and a categorical predictor (day of the week). Interactions between any type of predictor can involve more than two variables. Using the delivery data, let’s examine potential interactions solely between categorical predictor columns. \n\nFor regression problems, one visualization technique is to compute the means (or medians) for all combinations of variables and then plot these means in a manner similar to the previous figure. Let’s look at the 27 predictors columns for whether a specific item was included in the order. The original data is a count, but the data are mostly zero or one. We’ll look at two variables at a time and plot the four combinations of whether the item was ordered at all (versus not at all). @fig-delivery-items shows two potential sets of interactions. The x-axis indicates whether Item 1 was in the order or not. The y-axis is the mean delivery time with 90% confidence intervals^[These were computed using the bootstrap, as in @sec-eda-whole-game.].\n\nThe left panel shows the joint effect of items 1 and 9. The lines connecting the means are parallel. This indicates that each of these two predictors affects the outcome independently of one another. The right panel has means for items 1 and 10. The mean delivery times are very similar when neither is contained in the order. Also, when only one of the two items is in the order, the average time is similarly small. However, when both are included, the delivery time becomes much larger.  This means that you cannot consider the effect or either item 1 or 10 alone; their effect on the outcome occurs jointly. \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Interaction examples with two categorical predictors. Items 1 and 9 (left panel) do not interaction, while items 1 and 10 appear to have a strong  interaction (right panel).](../figures/fig-delivery-items-1.svg){#fig-delivery-items fig-align='center' width=70%}\n:::\n:::\n\n\nAs a third example, interactions may occur between continuous predictors. It can be difficult to discover the interaction via visualization for two numeric predictors without converting one of the predictors to categorical bins. To illustrate the _concept_ of an interaction between two numeric predictors, $x_1$ and $x_2$, let’s use a simple linear equation:\n\n$$ \ny = \\beta_0 + \\beta_{1}x_1 + \\beta_{2}x_2 + \\beta_{3}x_{1}x_{2} + \\epsilon\n$$ {#eq-two-way-int}\n\nThe $\\beta$ coefficients represent the overall average response ($\\beta_0$), the average rate of change for each individual predictor ($\\beta_1$ and $\\beta_2$), and the incremental rate of change due to the combined effect of $x_1$ and $x_2$ ($\\beta_3$) that goes beyond what $x_1$ and $x_2$ can explain alone.  The parameters for this equation can be estimated using a technique such as ordinary least squares (REF).  The sign and magnitude of $\\beta_3$ indicate how and the extent to which the two predictors interact:   \n\n - When $\\beta_3$ is positive, the interaction is _synergistic_ since the response increases beyond the effect of either predictor alone.  \n - Alternatively, when $\\beta_3$ is negative, the interaction is _antagonistic_ since the response decreases beyond the effect of either predictor alone.  \n - A third scenario is when $\\beta_3$ is essentially zero.  In this case, there is no interaction between the predictors and the relationship between the predictors is _additive_. \n - Finally, for some data sets, we may find that neither predictor is important individually (i.e., $\\beta_1$ and $\\beta_2$ are zero).  However, the coefficient on the interaction term is not zero.  Because this case occurs very infrequently, it is called _atypical_. \n \nTo understand this better, @fig-interaction-contours shows a contour plot of a predicted linear regression model with various combinations of the model slope parameters. The two predictors are centered at zero with values ranging within $x_j \\pm 4.0$). The default setting shows a moderate synergistic interaction effect since all of the $\\beta_j = 1.0$). In the plot, darker values indicate smaller predicted values.   \n\n::: {#fig-interaction-contours}\n\n::: {.figure-content}\n\n```{shinylive-r}\n#| label: fig-interaction-contours\n#| viewerHeight: 600\n#| standalone: true\n\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(bslib)\n\nui <- fluidPage(\n  theme = bs_theme(bg = \"#fcfefe\", fg = \"#595959\"),\n  mainPanel(\n    fluidRow(\n      column(\n        width = 4,\n        align = \"center\",\n        sliderInput(\n          \"beta_1\",\n          label = \"Predictor 1 slope\",\n          min = -4.0,\n          max =  4.0,\n          step = 0.5,\n          value = 1\n        )\n      ),\n      column(\n        width = 4,\n        align = \"center\",\n        sliderInput(\n          \"beta_2\",\n          label = \"Predictor 2 slope\",\n          min = -4.0,\n          max =  4.0,\n          step = 0.5,\n          value = 1\n        )\n      ),\n      column(\n        width = 4,\n        align = \"center\",\n        sliderInput(\n          \"beta_int\",\n          label = \"Interaction slope\",\n          min = -2.0,\n          max =  2.0,\n          step = 0.25,\n          value = 0.5\n        )\n      )\n    ), # row\n    fluidRow(\n      column(width =  1),\n      column(width = 10.0, align = \"center\", plotOutput('contours')),\n      column(width =  1)\n    ) # row\n  )  # main\n) # ui page\n\n\n\nserver <- function(input, output) {\n  \n  light_bg <- \"#fcfefe\" # from aml4td.scss\n  grid_theme <- bs_theme(\n    bg = \"#fcfefe\", fg = \"#595959\"\n  )\n  \n  # ------------------------------------------------------------------------------\n  \n  theme_light_bl<- function(...) {\n    \n    ret <- ggplot2::theme_bw(...)\n    \n    col_rect <- ggplot2::element_rect(fill = light_bg, colour = light_bg)\n    ret$panel.background  <- col_rect\n    ret$plot.background   <- col_rect\n    ret$legend.background <- col_rect\n    ret$legend.key        <- col_rect\n    \n    ret$legend.position <- \"top\"\n    \n    ret\n  }\n  \n  # ------------------------------------------------------------------------------\n  \n  n_grid <- 100\n  grid_1d <- seq(-1, 1, length.out = n_grid)\n  grid <- expand.grid(A = grid_1d, B = grid_1d)\n\n  output$contours <-\n    renderPlot({\n      # browser()\n      grid$outcome <- \n        input$beta_1 * grid$A + input$beta_2 * grid$B + \n        input$beta_int * grid$A * grid$B\n      \n      p <- \n        ggplot(grid, aes(A, B)) +\n        coord_equal() +\n        labs(x = \"Predictor 1\", y = \"Predictor 1\") +\n        theme_light_bl()\n      \n      if (length(unique(grid$outcome)) >= 15) {\n        p <- p + \n          geom_contour_filled(aes(z = scale(outcome)), bins = 15, show.legend = FALSE) +\n          scale_fill_viridis_d(option = \"G\")\n      }\n\n      print(p)\n      \n    })\n}\n\napp <- shinyApp(ui, server)\n```\n\n:::\n\nPrediction contours for a linear regression model with @eq-two-way-int with $\\beta_0 = 0$. Darker values indicate smaller predictions. \n\n:::\n\n\nwhat about categorical data\n\nhierarchical principal; decreasing likelihood of existence with number of terms. \n\n\n### Detecting Interactions\n\nAn ideal scenario would be that we would know which predictors interact before modeling the data.  If this would be the case, then these terms could be included in a model.  The model would have better predictive performance than a model with no interactions.  Unfortunately, knowledge of which predictors interact is usually not available prior to initiating the modeling process.  \n\nIf meaningful interactions are unknown before modeling, can models still discover and utilize these potentially important features? Recent studies using various advanced modeling techniques have shown that some methods can inherently detect interactions. For example, tree-based models [@elith2008working], random forests [@garcia2009evaluating], boosted trees [@lampa2014identification], and support vector machines [@chen2008support] are effective at uncovering them. \n\nIf modern modeling techniques can naturally find and utilize interactions, then why is it necessary to spend any time uncovering these relationships?  The first reason is interpretability.  Recall the trade-off between prediction and interpretation that was discussed in Chapter TODO.  More complex models are less interpretable and generally more predictive, while simpler models are more interpretable and less predictive. A second reason is that, by identifying essential interactions, we can include them in simpler models to improve predictive performance and maintain easy interpretability.  \n\n \n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n \nWhat should we do if we already have candidate interaction sets?  If we use a more formal statistical model, such as linear or logistic regression, the traditional tool for evaluating whether additional model terms in a set of nested models are worth including is the conventional analysis of variance (ANOVA). This uses the statistical likelihood value as the objective function. This is equivalent to comparing the RMSE values between models for linear regression ^[It so happens that the Gaussian likelihood function is equivalent to the sums of squared errors (SSE). That, in turn, is equivalent to the RMSE. That simplification does not automatically occur for other probability distributions.]. The error reduction and how many additional terms are responsible for the improvement are computed. Using these results and some probability assumptions about the data, we can formally test the null hypothesis that the additional parameters all have coefficient values of zero. Looking at the delivery data, our model in @sec-model-development-whole-game included a single set of interactions (e.g., hour-by-day). What if we included one more interaction: item 1 $\\times$ item 10? @tbl-interaction-anova shows the ANOVA results. The RMSE _computed on the training set_ is listed in the first and second rows. The reduction by including this additional model term is 0.18 (decimal minutes). Assuming normality of the model residuals, the p-value for this test is exceedingly small. This indicates that there is no evidence that this parameters is truly zero. This statistical difference may not make much of a practical difference. However, machine learning models often behave like \"a game of inches\" where every small improvement adds up to an overall improvement that matters. \n\n\n::: {#tbl-interaction-anova .cell layout-align=\"center\" tbl-cap='ANOVA table and validation set statistics for three models with different interaction sets.'}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"hhmpqowhwm\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#hhmpqowhwm table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#hhmpqowhwm thead, #hhmpqowhwm tbody, #hhmpqowhwm tfoot, #hhmpqowhwm tr, #hhmpqowhwm td, #hhmpqowhwm th {\n  border-style: none;\n}\n\n#hhmpqowhwm p {\n  margin: 0;\n  padding: 0;\n}\n\n#hhmpqowhwm .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#hhmpqowhwm .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#hhmpqowhwm .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#hhmpqowhwm .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#hhmpqowhwm .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#hhmpqowhwm .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#hhmpqowhwm .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#hhmpqowhwm .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#hhmpqowhwm .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#hhmpqowhwm .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#hhmpqowhwm .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#hhmpqowhwm .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#hhmpqowhwm .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#hhmpqowhwm .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#hhmpqowhwm .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hhmpqowhwm .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#hhmpqowhwm .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#hhmpqowhwm .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#hhmpqowhwm .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hhmpqowhwm .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#hhmpqowhwm .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hhmpqowhwm .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#hhmpqowhwm .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hhmpqowhwm .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#hhmpqowhwm .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#hhmpqowhwm .gt_left {\n  text-align: left;\n}\n\n#hhmpqowhwm .gt_center {\n  text-align: center;\n}\n\n#hhmpqowhwm .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#hhmpqowhwm .gt_font_normal {\n  font-weight: normal;\n}\n\n#hhmpqowhwm .gt_font_bold {\n  font-weight: bold;\n}\n\n#hhmpqowhwm .gt_font_italic {\n  font-style: italic;\n}\n\n#hhmpqowhwm .gt_super {\n  font-size: 65%;\n}\n\n#hhmpqowhwm .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#hhmpqowhwm .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#hhmpqowhwm .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#hhmpqowhwm .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#hhmpqowhwm .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#hhmpqowhwm .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#hhmpqowhwm .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" style=\"table-layout: fixed;\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <colgroup>\n    <col style=\"width:100px;\"/>\n    <col/>\n    <col/>\n    <col/>\n    <col style=\"width:80px;\"/>\n    <col/>\n    <col/>\n  </colgroup>\n  <thead>\n    \n    <tr class=\"gt_col_headings gt_spanner_row\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"Interactions\">Interactions</th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Training Set RMSE\">\n        <span class=\"gt_column_spanner\">Training Set RMSE</span>\n      </th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"2\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"Deg. Free.\">Deg. Free.</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"p-Value\">p-Value</th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Validation Set\">\n        <span class=\"gt_column_spanner\">Validation Set</span>\n      </th>\n    </tr>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"Decimal\">Decimal</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"Time\">Time</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"RMSE\">RMSE</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 1.8px; border-top-style: solid; border-top-color: #000000; border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\" scope=\"col\" id=\"MAE\">MAE</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Interactions\" class=\"gt_row gt_left\">Hour x Day</td>\n<td headers=\"Decimal\" class=\"gt_row gt_right\">2.30</td>\n<td headers=\"Time\" class=\"gt_row gt_left\">(2m, 17s)</td>\n<td headers=\"Deg. Free.\" class=\"gt_row gt_right\">5,890</td>\n<td headers=\"p-Value\" class=\"gt_row gt_left\"><div data-qmd=\"\"><div class='gt_from_md'></div></div></td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\">2.29</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\">1.61</td></tr>\n    <tr><td headers=\"Interactions\" class=\"gt_row gt_left\">Add One Item Interaction</td>\n<td headers=\"Decimal\" class=\"gt_row gt_right\">2.12</td>\n<td headers=\"Time\" class=\"gt_row gt_left\">(2m, 6s)</td>\n<td headers=\"Deg. Free.\" class=\"gt_row gt_right\">5,889</td>\n<td headers=\"p-Value\" class=\"gt_row gt_left\"><div data-qmd=\"10<sup>-219.8</sup>\"><div class='gt_from_md'><p>10<sup>-219.8</sup></p>\n</div></div></td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\">2.10</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\">1.56</td></tr>\n    <tr><td headers=\"Interactions\" class=\"gt_row gt_left\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\">Add All Item Interactions</td>\n<td headers=\"Decimal\" class=\"gt_row gt_right\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\">2.06</td>\n<td headers=\"Time\" class=\"gt_row gt_left\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\">(2m, 3s)</td>\n<td headers=\"Deg. Free.\" class=\"gt_row gt_right\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\">5,539</td>\n<td headers=\"p-Value\" class=\"gt_row gt_left\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\"><div data-qmd=\"10<sup>-18.4</sup>\"><div class='gt_from_md'><p>10<sup>-18.4</sup></p>\n</div></div></td>\n<td headers=\"RMSE\" class=\"gt_row gt_right\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\">2.13</td>\n<td headers=\"MAE\" class=\"gt_row gt_right\" style=\"border-bottom-width: 1.8px; border-bottom-style: solid; border-bottom-color: #000000;\">1.60</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\nWhat if there are other two-way interactions between the other item predictors? Since the training set is fairly large (compared to the current number of model parameters), it might be feasible to include the remaining 350 pairwise interactions and use the ANOVA method to validate this choice. These results are contained in the third row of @tbl-interaction-anova where the RMSE dropped further by 0.05 minutes. The p-value is also very small, indicating that there is no evidence that all of the  350 parameter estimates are zero. More extensive testing would be required to determine which actually are zero. This can be tedious and a potentially dangerous \"Fishing expedition\" that could result in serious bias creeping into the modeling process. \n\nOne problem with the ANOVA method is that it calculates the model error using the training set, which we know may not indicate what would occur with previously unseen data. In fact, it is well known that, for linear regression via ordinary least squares estimation, it is impossible for the training set error to ever increase when adding new model terms. You can see this in @tbl-interaction-anova where the validation set RMSE and MAE values are included. Note that, when the large set of interactions were added, these metrics both _increase_ in the validation set, a result contrary to what the ANOVA results tell us.  \n\nThe observed and predicted visualizations for each model in @tbl-interaction-anova are shown in @fig-lin-reg-interactions. Adding the additional interaction yielded a slight numerical improvement. However, the visualization in the middle panel shows fewer very large residuals. The figure also shows the model results that include the full set of  351 two-way interactions; this panel shows no significant reduction in large residuals, further casting doubt on using the entire set. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Validation set predicted vs. observed delivery times for linear regression models with and without additional interactions.](../figures/fig-lin-reg-interactions-1.svg){#fig-lin-reg-interactions fig-align='center' width=90%}\n:::\n:::\n\n\nSo far, we have used visualizations to unearth potential interactions. This can be an effective strategy when the number of potential interactions is large, but the visual nature of this process is subjective. There are some specialized quantitative tools for identifying interactions. For example, @lim2015learning used regularized generalized linear models (sections X and X) to estimate all possible two-way interactions and use a penalization method to determine which should be retained. @miller1984selection and @fes ([Section 7.4.3](https://bookdown.org/max/FES/approaches-when-complete-enumeration-is-practically-impossible.html#the-feasible-solution-algorithm)) describe the feasible solution algorithm, an iterative search method for interaction discovery. Another, which we will now describe in more detail, is Friedman's H-statistic [@friedman2008predictive]. \n\nWe can estimate the joint effect of a set of predictors on the outcome as well as the effect of individual predictors. If we thought that only main effects and two-factor interactions were possible, we could factor out the individual effects from the joint effect. The leftover predictive ability would then be due to interactions. Consider the linear model in @eq-two-way-int. The joint effect would include all possible model terms associated with a predictor. We can also create main effects too: \n\n\\begin{align}\nf(x_1, x_2) &= \\beta_{1}x_1 + \\beta_{2}x_2 + \\beta_{3}x_{1}x_{2} \\notag \\\\\nf(x_1) &= \\beta_{1}x_1  \\notag \\\\\nf(x_2) &= \\beta_{2}x_2 \\notag \n\\end{align}\n\nTo isolate the potential interaction effect: \n\n$$\nf(x_1\\times x_2) = f(x_1, x_2) - f(x_1) - f(x_2) = \\beta_{3}x_{1}x_{2}\n$$ {#eq-int-isolate}\n\nThis shows that, for this situation, we can isolate the effect of an interaction by removing any other systematic effects in the data. This approach doesn't work if the model is not _capable_ of detecting one; not all models can. Tree-based ensembles are good at estimating them, as are other complex black-box models such as neural networks and support vector machines. \n\n@eq-int-isolate shows a simple parametric linear model. For models with more complex prediction equations, we can’t analytically pick out which model parameters should be used to investigate potential interactions. \n\nHowever, for any model, the joint and marginal effects can be quantified using _partial dependence profiles_ (PDP) (@molnar2020interpretable, [Section 8.1](https://christophm.github.io/interpretable-ml-book/pdp.html)). First, we determine a sequence of values covering the observed range of the predictor(s) of interest. Then we randomly sample a data point, perhaps from the training set, and over-ride the value of the predictor of interest with values from the grid. This produces a prediction profile over the grid. We can repeat this process many times to approximate $f(\\cdot)$ by averaging the multiple prediction values for each grid point. \n\n@fig-bagging-pdp visualizes^[The results are unsurprising; we can see a similarity between these results and the initial visualizations in @fig-delivery-predictors.] the PDP data derived from using the emsembles of regression trees for $f(hour)$, $f(day)$, and $f(hour, day)$. The first panel shows the random realizations of the relationship between delivery time and order hour from 1,000 randomly sampled rows of the training set. The single trend line in panel (b) is the average of these profiles for each value of the predictor (delivery hour). There appears to be, on average, a nonlinear effect of the delivery hour. The day of the week is an informative predictor and the _joint effect_ profile in panel (d) shows that its effect induces different patterns in the delivery hour. If this were not the case, the patterns in panels (b) and (c) would, when combined, approximate the pattern in panel (d).  \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![“Partial dependence profiles for the food delivery hour and day, derived for the tree-based ensemble. Panel (a) shows the individual grid predictions from 1,000 randomly sampled points in the training set. The other panels show the average trends.”](../figures/fig-bagging-pdp-1.svg){#fig-bagging-pdp fig-align='center' width=70%}\n:::\n:::\n\n\nFriedman’s H-statistic can quantify the effect of interaction terms using partial dependence profiles. When investigating two-factor interactions between predictors $j$ and $j'$, the statistic is \n\n$$\nH^2_{jj'}=\\frac{\\sum_\\limits{i=1}^B\\left[\\hat{f}(x_{ij},x_{ij'})-\\hat{f}(x_{ij})-\\hat{f}(x_{ij'})\\right]}{ \\sum_\\limits{i=1}^B\\hat{f}^2(x_{ij}, x_{ij'})}\n$$\n\nwhere the $\\hat{f}(x_{ij})$ term represents the partial dependence profile for predictor $j$ for sample point $i$ along the grid for that predictor.  The denominator captures the total joint effect of predictors $j$ and $j'$ so that $H^2$ can be interpreted as the fraction of the joint effect explained by the potential interaction. \n\nFor a set of $p$ predictors, we could compute all $p(p-1)/2$ pairwise interactions and rank potential interactions by their statistic values. This can become computationally intractable at some point. One potential shortcut is to quantify the importance of the $p$ predictors and look at all pairwise combinations of the $p^*$ more important values.  For $p^* = 10$, @fig-hstats-interaction shows the top five interactions detected by this procedure. We’ve already visually identified the hour $\\times$ day interaction, so seeing this in the rankings is comforting. However, the largest interaction effect corresponds to the variables for items #1 and #10. Discovering this led us to visually confirm the effect back in @fig-delivery-items. \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![$H^2$ statistics for the top five pairwise interaction terms.](../figures/fig-hstats-interaction-1.svg){#fig-hstats-interaction fig-align='center' width=60%}\n:::\n:::\n\n\nNote that the _overall_ importance of the features are being quantified. From this analysis alone, we are not informed that the relationships between the hour and distance predictors and the outcome are nonlinear. It also doesn’t give any sense of the direction of the interaction (e.g., synergistic or antagonistic). We suggest using this tool early in the exploratory data analysis process to help focus visualizations on specific variables to understand how they relate to the outcome and other predictors. \n\nThere is a version of the statistic that can compute how much a specific predictor is interacting with _any other_ predictor. It is also possible to compute a statistical test to understand if the H statistic is different than zero. In our opinion, it is more helpful to use these values as diagnostics rather than the significant/insignificant thinking that often accompanies formal statistical hypothesis testing results.  \n\nTODO correlated predictors, use logit for classification models. @inglis2022visualizing have a good summary of the potential issues with using $H^2$. Alternatives to the H statistic can be found in @hooker2004discovering, @greenwell2018simple, @herbinger2022repid, and @oh2022predictive\n\nThe H-statistic, and its alternative, can be an incredibly valuable tool for learning about the data early on as well as suggesting new features that should be included in the model. However, it is computationally expensive. This technique, and similar approaches, are discussed in \n\n## Basis Expansions and Splines {#sec-splines}\n\nIn the food delivery data, we have thoroughly demonstrated that there are quantitative predictors that have nonlinear relationships with the outcome. In @sec-model-development-whole-game, two of the three models for these data could naturally estimate nonlinear trends. Linear regression, however, could not. To fix this, the hour predictor spawned multiple features called spline terms and adding these to the model enables it to fit nonlinear patterns. This approach is called a _basis expansion_. In this section, we’ll consider a few techniques for this purpose. \n\nThe most traditional approach is a polynomial expansion. If we start with a simple linear regression model with a single predictor: \n\n$$ \ny_i = \\beta_0 + \\beta_1 x_{i} + \\epsilon_i\n$$ \n\nthe expansion would add additional terms with values of predictor expoentiated to the $p^{th}$ power^[In actuality, a more computationally preferred method is to use _orthogonal polynomials_ which rescale the variables before we exponentiate them. We’ll denote these modified versions of the predictor in equation @eq-poly-linear-reg as just $x$ to reduce mathematical clutter.]. For a cubic polynomial model:\n\n$$ \ny_i = \\beta_0 + \\beta_1 x_{i} + \\beta_2 x_{i}^2 + \\beta_3 x_{i}^3 + \\epsilon_i\n$$ {#eq-poly-linear-reg}\n\nThis is a _linear model_ in the sense that it is linear in the statistical parameters (the $\\beta$ values), so we can use standard parameter estimation procedures (e.g., least squares). \n\n@fig-basis-expansions(a) shows data from @Silverman collected to measure the efficacy of motorcycle helmets. After a set amount of time since impact, device readings were taken to measure the acceleration of the head. The data set contains 133 data points for these two variables. The relationship is highly nonlinear, with an initial period with no acceleration followed by periods of decreasing results and then significantly increasing acceleration. The final phase of the data is a relatively constant period of no acceleration (but with a fairly high scatter). \n\nThe default 13-degree polynomial is used in the visualization. It fits well in the middle of the data where the pattern is most dynamic. At the edges of the distribution, where the pattern is flat, it is too wiggly. Decreasing the polynomial degree will result in less complex patterns that tend to underfit the data. Increasing the degree will result in the fitted line being closer to the data, but, as evidenced by the confidence interval in the shaded region, the uncertainty in the model explodes (especially on the far right side). This is due to severe overfitting. Eventually, you can increase the degree until the curve passes through every data point. However, the fit for any other values will be wildly inaccurate and unstable.\n\n::: {#fig-basis-expansions}\n\n::: {.figure-content}\n\n```{shinylive-r}\n#| label: fig-basis-expansions\n#| viewerHeight: 600\n#| viewerWidth: \"100%\"\n#| standalone: true\n\nlibrary(shiny)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(splines2)\nlibrary(bslib)\nlibrary(viridis)\nlibrary(MASS)\n\ndata(mcycle)\n\nui <- fluidPage(\n  theme = bs_theme(bg = \"#fcfefe\", fg = \"#595959\"),\n  mainPanel(\n    tabsetPanel(\n      id = \"tabset\",\n      tabPanel(\n        \"(a) Global polynomials.\",\n        fluidRow(\n          column(width = 3),\n          column(\n            width = 6,\n            align = \"center\",\n            sliderInput(\n              \"global_deg\",\n              label = \"Polynomial Degree\",\n              min = 0L,\n              max = 20L,\n              step = 1L,\n              value = 13L\n            )\n          )\n        ),\n        plotOutput('global')\n      ),\n      tabPanel(\n        \"(b) Piecewise polynimials.\",\n        label = \"Polynomial Degree\",\n        fluidRow(\n          column(\n            width = 6,\n            align = \"center\",\n            sliderInput(\n              \"piecewise_deg\",\n              label = \"Polynomial Degree\",\n              min = 0L,\n              max = 6L,\n              step = 1L,\n              value = 3L\n            )\n          ),\n          column(\n            width = 6,\n            align = \"center\",\n            sliderInput(\n              \"cuts\",\n              label = \"Cutpoints\",\n              min = 5L,\n              max = 52L,\n              step = 1L,\n              value = c(20, 38)\n            )\n          )\n        ),\n        plotOutput('pieces')\n      ),\n      tabPanel(\n        \"(c) Natural splines.\",\n        fluidRow(\n          column(width = 3),\n          column(\n            width = 6,\n            align = \"center\",\n            sliderInput(\n              \"spline_df\",\n              label = \"# Spline Terms\",\n              min = 3L,\n              max = 20L,\n              step = 1L,\n              value = 9L\n            )\n          )\n        ),\n        plotOutput('spline')\n      )\n    )\n  )\n)\n\nserver <- function(input, output, session) {\n\n  light_bg <- \"#fcfefe\" # from aml4td.scss\n  grid_theme <- bs_theme(\n    bg = \"#fcfefe\", fg = \"#595959\"\n  )\n\n  # ------------------------------------------------------------------------------\n\n  theme_light_bl<- function(...) {\n\n    ret <- ggplot2::theme_bw(...)\n\n    col_rect <- ggplot2::element_rect(fill = light_bg, colour = light_bg)\n    ret$panel.background  <- col_rect\n    ret$plot.background   <- col_rect\n    ret$legend.background <- col_rect\n    ret$legend.key        <- col_rect\n\n    ret$legend.position <- \"top\"\n\n    ret\n  }\n\n  # ------------------------------------------------------------------------------\n\n  spline_example <- tibble(x = mcycle$times, y = mcycle$accel)\n  grid <- seq(min(mcycle$times), max(mcycle$times), length.out = 1000)\n  alphas <- 1 / 4\n  line_wd <- 1.0\n\n  base_p <-\n    spline_example %>%\n    ggplot(aes(x = x, y = y)) +\n    geom_point(alpha = 3 / 4, pch = 1, cex = 3) +\n    # geom_line(data = truth, col = \"black\", lty = 2, linewidth = 1) +\n    labs(x = \"Time\", y = \"Acceleration\") +\n    theme_light_bl()\n\n  output$global <- renderPlot({\n\n    global_p <- base_p\n\n    if (input$global_deg > 0) {\n      global_p <-\n        global_p+\n        geom_smooth(\n          se = TRUE,\n          formula = y ~ poly(x, input$global_deg),\n          method = lm,\n          col = \"#377EB8\",\n          linewidth = line_wd,\n          alpha = 1 / 7)\n\n    }\n    print(global_p)\n\n  })\n\n  output$pieces <- renderPlot({\n    maybe_lm <- function(x) {\n      try(lm(y ~ poly(x, input$piecewise_deg), data = x), silent = TRUE)\n    }\n    cuts <- c(0, sort(input$cuts), 60)\n    piece_cols <- c(\"#1B9E77\", \"#D95F02\", \"#7570B3\")\n    piece_p <- base_p\n\n    if (input$piecewise_deg > 0) {\n      data_splt <-\n        spline_example %>%\n        dplyr::mutate(x_cut = cut(x, breaks = cuts, include.lowest = TRUE)) %>%\n        tidyr::nest(.by = x_cut) %>%\n        mutate(\n          fit = lapply(data, maybe_lm)\n        )\n      grid_splt <-\n        dplyr::tibble(x = grid) %>%\n        dplyr::mutate(x_cut = cut(x, breaks = cuts, include.lowest = TRUE))  %>%\n        tidyr::nest(.by = x_cut)\n\n      for (i in 1:3) {\n        sub_pred <- grid_splt$data[[i]]\n        if (!inherits(data_splt$fit[[i]], \"try-error\")) {\n          sub_pred <-\n            sub_pred %>%\n            dplyr::bind_cols(predict(data_splt$fit[[i]], sub_pred, interval = \"conf\"))\n\n          piece_p <-\n            piece_p +\n            geom_ribbon(\n              data = sub_pred,\n              aes(y = NULL, ymin = lwr, ymax = upr),\n              alpha = 1 / 15\n            ) +\n            geom_line(\n              data = sub_pred,\n              aes(y = fit),\n              col = piece_cols[i],\n              linewidth = line_wd\n            )\n        }\n      }\n    }\n\n    print(piece_p)\n\n  })\n\n  output$spline <- renderPlot({\n\n    spline_p <- base_p +\n      geom_smooth(\n        se = TRUE,\n        formula = y ~ naturalSpline(x, df = input$spline_df),\n        method = lm,\n        col = \"#E6AB02\",\n        linewidth = line_wd,\n        alpha = 1 / 7)\n\n    print(spline_p)\n\n  })\n\n}\n\napp <- shinyApp(ui = ui, server = server)\n```\n\n:::\n\nSeveral approaches to modeling data from @Silverman. The black dashed line is the true function and the shaded regions are 95% confidence intervals around the mean. \n\n:::\n\nThe issue here is that a global polynomial pattern is often insufficient because of the nonlinear relationships is different in different data sections. There may be steep increases in one area, gradual increases in others, and potnetially flat regions. Rather than using a global polynomial, what if we used different basis expansions in regions with more manageable or simplistic trends rather than a global polynomial? \n\nPanel (b) shows a crude approach where three different regions have different polynomial fits with the same degree. This isn’t terribly effective. Achieving a good fit in the interior region produces poor fits in the two exterior regions where the pattern is nearly constant. Also, as it stands, the curves do not connect to one another, and this discontinuity is visually discordant, but it is most likely inconsistent with the true, underlying pattern that we are attempting to estimate. We can resolve the latter issue with a more complex modeling approach that guarantees that the curves touch (and even touch smoothly). However, let’s move on to a much better approach for basis expansions.\n\nSpline functions (or just \"splines\") are specialized basis functions that use polynomial trends in specific regions defined by a set of knots. They are designed so that the transitions between regions are continuous and smooth^[This is accomplished by constrains on the basis functions that allow the functions, and some of their derivatives, to be continuous at the knots. See @ruppert2003semiparametric and @arnold2019computational.]. \n\nThere are many types of splines but one, the \"natural spline,\" is shown in Panel (c) of @fig-basis-expansions. \n\n\nThe function demonstrates an excellent fit to the data with smooth transitions between regions. \n\nSplines can be configured in different ways. Two details to specify are how many regions should be separately modeled and how they are apportioned. The number of regions is related to how many features are used in the basis expansion. As the number of regions increases, so does the ability of the spline to adapt to whatever trend might be in the data. However, the risk of over-fitting the model to individual data points increases as the flexibility increases.\n\nFor this reason, we often tune the amount of complexity that the spline will accommodate. Generally, since the number of regions is related to the number of features, we'll refer to the complexity of the basis function via the number of degrees of freedom afforded by the spline. We don't necessarily know how many degrees of freedom to use. There are two ways to determine this. First, we can treat the complexity of the spline as a tuning parameter and optimize it with the tuning methods mentioned in Chapters [-@sec-grid] and [-@sec-iterative]. Another option is to over-specify the number of degrees of freedom and let specialized training methods solve the potential issue of over-fitting. From @wood2006generalized: \n\n> An alternative to controlling smoothness by altering the basis dimension, is to keep the basis dimension fixed, at a size a little larger than it is believed it could reasonably be necessary, but to control the model’s smoothness by adding a \"wiggliness\" penalty to the least squares fitting objective. \n\nThis approach is advantageous when there are separate basis expansions for multiple predictors. The overall smoothness can be estimated along with the parameter estimates in the model. The process could be used with general linear models (Chapters [-@sec-ols] and [-@sec-ordinary-logistic-regression]) or other parametric linear models. \n\nHow do we choose the knots? We can select them manually, and some authors advocate for this point of view. As stated by @breiman1988monotone: \n\n> My impression, after much experimentation, is the same - that few knots suffice providing that they are in the right place.\n\nA good example is seen in the motorcycle helmet data, where there are clear regions that are linear and nonlinear. Specifying two interior knows at roughly 14s and 45s would suffice. However hand curating each feature becomes practically infeasible as the number of features increases.  Otherwise, they can be set algorithmically.\n\nThere are two main choices for automatic knot selection. The first uses a sequence of equally-spaced values encompassing the predictor space. The second is to estimate percentiles of the predictor data so that regions have about the same number of values they capture. For example, a fourth degree of freedom spline would have three split points within the data arranged at the 25th, 50th, and 75th percentiles (with the minimum and maximum values bracketing the outer regions). It would be unwise to place knots as evenly spaced values between the minimum and maximum values. Without taking the distribution of the predictor into account, it is possible that the region between some knots might not contain any data. \n\nMany, but not all, splines specify how complex the fit should be in the area between the knots. However, cubic splines are a common choice because they allow for greater flexibility than linear or quadratic fits, but are not overly flexible, which could lead to over-fitting. Increasing the polynomial degree beyond three has more disadvantages than advantages. Recall that, in @fig-basis-expansions(a), there was an explosive variance at the ends of the predictor distribution when the polynomial degree is very large. \n\nOne way to address the variability at the ends of the predictor space is to use a _natural spline_. It employs a cubic polynomial but only uses a linear fit in the two most extreme regions of the predictor space. \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nAs another example, consider the Ames housing data. The (log10) sale price is related to the geo-location of the properties. @fig-ames-latitude shows a scatter plot of the training data where the latitude values are a predictor. There is a gap in the data toward the left-hand side (corresponding to the location of [Iowa State University](https://www.google.com/maps/@42.0266573,-93.6464516,15z)). \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The price of houses in Ames versus latitude.](../figures/fig-ames-latitude-1.svg){#fig-ames-latitude fig-align='center' width=60%}\n:::\n:::\n\n\nHow would the data be modeled if a natural spline with six degrees of freedom were created from this predictor? @fig-spline-features shows how each spline feature relates to the underlying data, where the dashed lines delineate the regions defined by the appropriate percentiles. The solid lines indicate the weight the term puts on any particular latitude value. We can see that the third feature isolates latitudes between 42.02 and 42.05, while the sixth spline value focuses on latitudes greater than 42.035. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Predictor coverage of six natural spline terms based on latitude.](../figures/fig-spline-features-1.svg){#fig-spline-features fig-align='center' width=70%}\n:::\n:::\n\n\nLet’s use a set of 20 natural spline features to model these data using ordinary linear regression. @fig-ames-latitude-fit shows the resulting fit on the training set. The red line shows the fitted curve resulting from the 21 parameter estimates. The different curves on the top of the plot area indicate how much each feature represents each portion of the predictor space.  This illustration demonstrates that as the number of features increases, the model fit becomes more flexible.\n\n::: {#fig-ames-latitude-fit}\n\n::: {.figure-content}\n\n```{shinylive-r}\n#| label: fig-ames-latitude-fit\n#| viewerHeight: 550\n#| standalone: true\n\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(bslib)\nlibrary(viridis)\nlibrary(patchwork)\nlibrary(splines2)\nlibrary(rsample)\nlibrary(modeldata)\n\n# from recipes::names0\nnames0 <- function (num, prefix = \"x\")  {\n  ind <- format(seq_len(num))\n  ind <- gsub(\" \", \"0\", ind)\n  paste0(prefix, ind)\n}\n\n# ------------------------------------------------------------------------------\n\nlight_bg <- \"#fcfefe\" # from aml4td.scss\ngrid_theme <- bs_theme(\n  bg = light_bg, fg = \"#595959\"\n)\n\n# ------------------------------------------------------------------------------\n\ntheme_light_bl<- function(...) {\n\n  ret <- ggplot2::theme_bw(...)\n\n  col_rect <- ggplot2::element_rect(fill = light_bg, colour = light_bg)\n  ret$panel.background  <- col_rect\n  ret$plot.background   <- col_rect\n  ret$legend.background <- col_rect\n  ret$legend.key        <- col_rect\n\n  ret$legend.position <- \"top\"\n\n  ret\n}\n\n# ------------------------------------------------------------------------------\n\nui <- fluidPage(\n  theme = grid_theme,\n  fluidRow(\n    column(width = 2),\n    column(\n      width = 4,\n      align = \"center\",\n      sliderInput(\n        inputId = \"num_terms\",\n        label = \"Degrees of Freedom\",\n        min = 2L,\n        max = 50L,\n        value = 20L,\n        width = \"100%\",\n        step = 1L\n      )\n    )\n  ),\n  fluidRow(\n    column(\n      width = 8,\n      align = \"center\",\n      plotOutput('latitude')\n    )\n  )\n)\n\nserver <- function(input, output) {\n\n  data(ames, package = \"modeldata\")\n\n  ames$Sale_Price <- log10(ames$Sale_Price)\n\n  set.seed(3024)\n  ames_split <- initial_split(ames, strata = Sale_Price, breaks = 5)\n  ames_train <- training(ames_split)\n  ames_test  <- testing(ames_split)\n\n  latitude_p <-\n    ggplot(ames_train, aes(Latitude, Sale_Price)) +\n    geom_point(pch = 1, alpha = 1 / 3) +\n    ylab(\"Sale Price (log10)\")\n\n  col_rect <- ggplot2::element_rect(fill = light_bg, colour = light_bg)\n\n  output$latitude <-\n    renderPlot({\n\n      natural_res <- naturalSpline(ames_train$Latitude, df = input$num_terms)\n      natural_knots <- attributes(natural_res)$knots\n      natural_res <- t(apply(natural_res, 1, I))\n      colnames(natural_res) <- names0(ncol(natural_res), \"natural spline \")\n      natural_res <- as.data.frame(natural_res)\n      natural_res <- stack(natural_res)\n      colnames(natural_res) <- c(\"value\", \"feature\")\n      natural_res$Latitude <- rep(ames_train$Latitude, input$num_terms)\n      natural_res <- natural_res[natural_res$value > 0,]\n\n      latitude_fit_p <-\n        latitude_p +\n        geom_smooth(\n          se = FALSE,\n          formula = y ~ splines2::naturalSpline(x, df = input$num_terms),\n          method = lm,\n          col = \"red\"\n        ) +\n        theme_bw() +\n        theme(\n          plot.margin = margin(t = -20, r = 0, b = 0, l = 0),\n          panel.background = col_rect,\n          plot.background = col_rect,\n          legend.background = col_rect,\n          legend.key = col_rect\n        )\n\n      spline_p <-\n        ggplot(natural_res, aes(Latitude, value, group = feature, col = feature)) +\n        geom_line(show.legend = FALSE, linewidth = 1, alpha = 1 / 2) +\n        theme_void() +\n        theme(\n          plot.margin = margin(t = 0, r = 0, b = -20, l = 0),\n          panel.background = col_rect,\n          plot.background = col_rect,\n          legend.background = col_rect,\n          legend.key = col_rect\n        ) +\n        scale_color_viridis(discrete = TRUE, option = \"turbo\")\n\n      p <- (spline_p / latitude_fit_p) + plot_layout(heights = c(1, 4))\n\n      print(p)\n\n    })\n}\n\napp <- shinyApp(ui = ui, server = server)\n```\n\n\n:::\n\nThe price of houses in Ames versus latitude with a 20 degree of freedom natural spline. The curves above the plot illustrate how much each of the 20 features represents a different portion of the predictor space.\n\n:::\n\n\nSplines are extremely useful and are especially handy when we want to encourage a simple model (such as linear regression) to approximate the predictive performance of a much more complex black-box model (e.g., a neural network or tree ensemble). We’ll also see splines and spline-like features used within different modeling techniques, such as generalized additive models (Sections [-@sec-reg-gam] and [-@sec-cls-gam]), multivariate adaptive regression splines (@sec-mars), and a few others.  \n\n## Discretization\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![An unfortunate visualization of two predictors and the outcome in the food delivery data. The colors of the pie chart reflect delivery time cut points are 20 and 30 minutes with lighter blue indicating eariler times.](../figures/fig-wall-of-pie-1.svg){#fig-wall-of-pie fig-align='center' width=60%}\n:::\n:::\n\n\nOur general advice, described in more detail in @fes, is that the first inclination should never be to engineer continuous predictors via discretization. Other tools, such as splines, are both theoretically and practically superior to converting quantitative data to qualitative data. \n\nThe literature supporting this is extensive, such as: @Cohen1983mn, @Altman1991ro, @Maxwell1993ig, @Altman1994oa, @Buettner1997bt, @Altman1998vs, @Taylor2002jj, @MacCallum2002ox, @Irwin2003mp, @Owen2005do, @Altman2006gn, @Royston2006md, @VanWalraven2008ne, @Fedorov2009jy, @Naggara2011xu, @Bennette2012ua, @Kuss2013zi, @Kenny2013cf, @BarnwellMenard2015xa, @Fernandes2019na, as well as the references shown in @harrell2017regression. These articles identify the main problems of discretization as follows:\n\n* Arbitrary (non-methodological) choice of breaks for binning can lead to significant bias. \n* The predictor suffers a significant loss of information, making it less effective. Moreover, there is reduced statistical power to detect differences between groups when they exist.\n* The number of features are increased, thus exacerbating the challenge of feature selection. \n* Correlations between predictors are inflated due to the unrealistic reduction in the variance of predictors. \n\n@pettersson2016quantitative shows differences in analyses with and without discretization. Their Fig. 1 shows a common binning analysis: a continuous outcome and one or more predictors are converted to qualitative formats and a grid of pie charts is created. Inferences are made from this visualization. One main problem is related to uncertainty. The noise in the continuous data is squashed so that any visual signal that is seen appears more factual than it is in reality^[@Kenny2013cf does an excellent job illustrating this issue.]. Also, the pie charts do not show measures of uncertainty; how do we know when two different pie charts are \"significant\"? \n\nAlternatively, Figs. 4 and 5 of their paper shows the results of a logistic regression model where all predictors were left as-is and splines were used to model the probability of the outcome. This has a much simpler interpretation and confidence bands give the reader a sense that the differences are real. \n\nAs a counter-example that shows appropriate discretization, one type of measurement that is often appropriately discretized is date. For example, @fes show a data set where daily ridership data was collected for the Chicago elevated train system. The primary trend in the data was whether or not the day was a weekday. Ridership was significantly higher when people commute to work. A simple indicator for Saturday/Sunday (as well as major holiday indicators) was the driving force behind many regression models on those data. In this case, making qualitative versions of the date was rational, non-arbitrary, and driven by data analysis.\n\nNote that several models, such as classification/regression trees and multivariate adaptive regression splines, estimate cut points in the model-building process. The difference between these methodologies and manual binning is that the models use all the predictors to derive bins based on a single objective (such as maximizing accuracy). They evaluate many variables simultaneously and are usually based on statistically sound methodologies.  \n\nIf it is the last resort, how should one go about discretizing predictors? First and most important: _any_ methodology should be well validated using data that were not used to build the model (or choose the cut points for binning). To convert data to a qualitative format, there are both supervised and unsupervised methods. \n  \nThe most reliable unsupervised approach is to choose the number of new features and use an appropriate number of percentiles to bin the data. For example, if four new features are required, the 0, 25%, 50%, 75%, and 100% quantiles would be used. This ensures that each resulting bin contains about the same number of samples from the training set.  \n  \nIf you noticed that this is basically the same approach suggested for choosing spline knots in the discussion earlier in this chapter, you are correct. This connection helps illustrate how superior the spline approach is; fitting a model with the discrete bins is the same as using a zero degree of freedom spline model. In essence, we are severely handicapping our data analysis by fitting a flat model to the data within the bins. \n \nA supervised approach would, given a specific number of new features to create, determine the breakpoints by optimizing a performance measure (e.g., RMSE, classification accuracy, etc.). A good example is a tree-based model (as mentioned above). After fitting a single tree or, better yet, an ensemble of trees, the split values in the trees can be used as the breakpoints.  \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nLet's again use the Ames housing data, specifically the latitude predictor, illustrated in @fig-ames-latitude. We can fit a linear regression with qualitative terms for latitude derived using: \n\n- An unsupervised approach using percentiles at cut-points. \n- A supervised approach where a regression tree model is used to set the breakpoints for the bins. \n\nIn each case, the number of new features requires tuning. Using the basic grid search tools described in @sec-grid, the number of required terms was set for each method (ranging from 2 to 25 terms) by minimizing the RMSE from a simple linear regression model. The results are that both approaches required the same number of new features and produced about the same level of performance; the unsupervised approach required 24 breaks to achieve an RMSE of 0.143 and the supervised model has an RMSE of 0.145 with 6 cut points. @fig-ames-bins shows the fitted model using the unsupervised terms. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The estimated relationship between sale price and latitude using discretization methods. The fitted line corresponds to an unsupervised set of features and the \"rugs\" at the top and bottom of the plots illustrate where the breakpoints were estimated.](../figures/fig-ames-bins-1.svg){#fig-ames-bins fig-align='center' width=70%}\n:::\n:::\n\n\nThe blue and red marks on the top and bottom of the plot show the locations of the breakpoints for each procedure. They are remarkably similar to one another. The blocky nature of the fitted trend reflects that, within each bin, a simple mean is used to estimate the sale price. For this fit, 25 means were estimated. This number is likely larger than the corresponding number of parameters required by a spline model to produce a smooth trend line. \n\nzero-order spline model? \n\n## Other Features\n\n\nAnother common approach to creating features is to calculate distances between landmarks or pairs of predictors. For example, the distance to desirable grade schools (or the university campus) could affect house prices in the Ames housing data. Potential predictors can be created that measure how close each home is to these points of interest. To calculate distance, a simple Euclidean metric can be used. However, for spatial data across longer distances, the Haversine metric [@sinnott1984virtues] is a better alternative because it takes into account the curvature of the earth.\n\nNote that distance-based features are often right skewed.  When a metric produces a right-skewed distribution, the log-transformation often helps improve predictive performance when the predictor is truly informative. \n\nDistance-based features can also be effective for classification models. A centroid is another name for the multivariate mean of a collection of data. It is possible to compute class-specific centroids using only the data from each class. When a new sample is predicted, this distance to each class centroid can be used as a predictor. These features would be helpful when a model could be better at detecting/emulating linear class boundaries. An example of this would be tree-based models; these models have to work hard to approximate linear trends in the data. Supplementing the data with simple centroid features might improve performance. \n\nAgain, there are several choices for the distance metric.  Mahalanobis distance is a good choice when there is not an overwhelming number of predictors:\n\n$$\nD_c(\\boldsymbol{x}_0) = (\\boldsymbol{x}_0 - \\boldsymbol{\\bar{x}}_{c})' \\boldsymbol{S}^{-1}_c (\\boldsymbol{x}_0 - \\boldsymbol{\\bar{x}}_{c})\n$$\n\nwhere $\\boldsymbol{x}_0$ is the new data point being predicted, $\\boldsymbol{\\bar{x}}$ is a vector of sample means, $\\boldsymbol{S}$ is the estimated covariance matrix (the subscript of $c$ denotes the class-specific statistics). This metric requires fewer data points within each class than the number of predictors being used. It also assumes that there are no linear dependencies between the predictors. \n \nWhen the model has many features, regularizing the centroid distances can be a good approach. This approach, similar to the tools described in @sec-effect-encodings, will shrink the class-specific centroids towards the overall (class-nonspecific) centroid at different rates. If a predictor does have any discriminative ability in the training set, its contribution to the class-specific centroids can be removed. \n\nWe'll let $x_{ij}$ denote sample $i$ ($i=1\\ldots n_{tr}$) for predictor $j$ ($j=1\\ldots p$). The approach by @tibshirani2003class estimates the standardized difference between the class-specific centroid and the global centroid using the following:\n\n\\begin{align}\n\\delta_{jc} &= \\frac{\\bar{x}_{jc} - \\bar{x}_j}{w_c s_j} &&\\text{ where } \\notag \\\\\n\\bar{x}_{jc} &= \\frac{1}{{n_{tr}^c}}\\sum_{i=1}^{{n_{tr}^c}} x_{ij}\\, I(y_i = c) && \\text{\\textcolor{grey}{(class-specific centroid elements)}} \\notag \\\\\n\\bar{x}_{j} &= \\frac{1}{n_{tr}}\\sum_{i=1}^{n_{tr}} x_{ij}  && \\text{\\textcolor{grey}{(global centroid elements)}}\\notag \\\\\nw_c &= \\sqrt{\\frac{1}{{n_{tr}^c}}  - \\frac{1}{n_{tr}}}  && \\text{\\textcolor{grey}{{(weights)}}} \\notag \\\\\ns_j &= \\frac{1}{n_{tr}-C}\\sum_{c=1}^C\\sum_{i=1}^{n_{tr}} \\left(x_{ij} - \\bar{x}_{jc}\\right)^2 I(y_i = c)  && \\text{\\textcolor{grey}{(pooled standard deviation for predictor $j$)}}\\notag \n\\end{align}\n\nwhere $n_{tr}^c$ is the number of training set points for class $c$ and $I(x)$ is a function that returns a value of one when $x$ is true. \n\nTo shrink this difference towards zero, a tuning parameter $\\lambda$ is used to create a modified version of the each predictors contribution to the difference:\n\n\\begin{equation}\n\\delta^*_{jc} = sign(\\delta_{jc})\\,h(|\\delta_{jc}| - \\lambda)\n\\end{equation}\n\nwhere $h(x) = x$ when $x > 0$ and zero otherwise. If the difference between the class-specific and global centroid is small (relative to $\\lambda$), $\\delta^*_{jc} = 0$ and predictor $j$ does not functionally affect the calculations for class $c$. The class-specific shrunken centroid is then\n\n\\begin{equation}\n\\bar{x}^*_{jc}= \\bar{x}_j + w_c\\, s_j\\, \\delta^*_{jc}\n\\end{equation}\n\nNew features are added to the model based on the distance between $\\boldsymbol{x}_0$ and $\\boldsymbol{\\bar{x}}^*_{c}$. The amount of shrinkage is best optimized using the tuning methods described in later chapters. There are several variations of this specific procedure. @wangImprovedCentroids describe several different approaches and @efron2009empirical demonstrates the connection to Bayesian methods. \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![An example of shrunken, class-specific centroids. Panel (a) shows data where there are three classes. Panel(b) demonstrates how, with increasing regularization, the centorids converge towards the global centroid (in black).](../figures/fig-nsc-1.svg){#fig-nsc fig-align='center' fig-alt='Nearest centroids' width=70%}\n:::\n:::\n\n\n@fig-nsc shows the impact of regularization for a simple data set with two predictors and three classes. The data are shown in Panel (a), while Panel (b) displays the raw, class-specific centroids. As regularization is added, the lines indicate the path each takes toward the global centroid (in black). Notice that the centroid for the first class eventually does not use predictor $x_1$; the path becomes completely vertical when that predictor is removed from the calculations. As a counter-example, the centroid for the third class moves in a straight line towards the center. This indicates that both predictors showed a strong signal, and neither was removed as regularization increased.  \n\nLike distance-based methods, predictors based on _data depth_ [@liu1999multivariate; @ghosh2005data;  @mozharovskyi2015classifying] can be helpful for separating classes. The depth of the data was initially defined by @tukey1975mathematics, and it can be roughly understood as the inverse of the distance to a centroid. For example, Mahalanobis depth would be:\n\n$$\nDepth_c(\\boldsymbol{x}_0) = \\left[1 + D_c(\\boldsymbol{x}_0)\\right]^{-1}\n$$\n\nThere are more complex depth methods, and some are known for their robustness to outliers. Again, like distances, class-specific depth features can be used as features in a model. \n\n## Chapter References {.unnumbered}\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}