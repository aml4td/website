{
  "hash": "f8a4ceafdcab288280a9d2e9274b4f06",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n# Preface  {.unnumbered}\n\nWelcome! This is a work in progress. We want to create a practical guide to creating quality machine learning (ML) from tabular data. We'll publish materials here as we create them and welcome community contributions in the form of discussions, suggestions, and edits. \n\nWe also want these materials to be reusable and open. The sources are in the source [GitHub repository](https://github.com/aml4td/website) with a Creative Commons license attached (see below).\n\nOur intention is to write these materials and, when we feel we're done, pick a publishing partner to produce a print version.\n\nThe book takes a holistic view of the ML process and focuses on a few areas that are usually left out of similar works. For example, the effectiveness of the model can be driven by how the predictors are represented. We tightly couple feature engineering methods with machine learning models. Also, quite a lot of work happens after we have determined our best model and created the final fit. Post-modeling activities are also described here. \n\nWe deliberately avoid using the term \"artificial intelligence.\" Eugen Rochko's (`@Gargron@mastodon.social`) comment on [Mastodon](https://mastodon.social/@Gargron/111554885513300997) does a good job of summarizing our reservations regarding the term: \n\n> It’s hard not to say \"AI\" when everybody else does too, but technically calling it AI is buying into the marketing. There is no intelligence there, and it’s not going to become sentient. It's just statistics, and the danger they pose is primarily through the false sense of skill or fitness for purpose that people ascribe to them.\n\nTo cite this website, we suggest: \n\n\n::: {.cell layout-align=\"center\"}\n```{bib}\n@online{aml4td,\n  author = {Kuhn, M and Johnson, K},\n  title = {{Applied Machine Learning for Tabular Data}},\n  year = {2023},\n  url = { https://aml4td.org},\n  urldate = {2023-12-11}\n}\n```\n:::\n\n\n## License {.unnumbered}\n\n<p xmlns:cc=\"http://creativecommons.org/ns#\" >This work is licensed under <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1\" target=\"_blank\" rel=\"license noopener noreferrer\" style=\"display:inline-block;\">CC BY-NC-SA 4.0<img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1\"><img style=\"height:22px!important;margin-left:3px;vertical-align:text-bottom;\" src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\"></a></p> \n\nThis license requires that reusers give credit to the creator. It allows reusers to distribute, remix, adapt, and build upon the material in any medium or format, for noncommercial purposes only. If others modify or adapt the material, they must license the modified material under identical terms.\n\n- BY: Credit must be given to you, the creator.\n- NC: Only noncommercial use of your work is permitted. Noncommercial means not primarily intended for or directed towards commercial advantage or monetary compensation.\n- SA: Adaptations must be shared under the same terms. \n\nOur goal is to have an open book where people can reuse and reference the materials but can't just put their names on them and resell them (without our permission). \n\n## Intended Audience {.unnumbered}\n\nOur intended audience is data analysts of many types: statisticians, data scientists, laboratory scientists, and anyone else who needs to create a model for prediction. We don't expect readers to be experts in these methods or the math behind them. Our approach is applied. We want readers to have intuition about what are good and bad ideas for their data and what to look out for. \n\nSome background in modeling and statistics is required. Having seen or used basic regression models is good, and understanding basic statistical concepts, such as variance, correlation, populations, samples, etc., is needed. There is some mathematical notation, so you'll need to be able to read those. There are a few more statistically sophisticated sections, but these are not pivotal topics. \n\nIf you want a more theoretical treatment of machine learning models, we recommend @HastieEtAl2017. Other books for learning more about machine learning are @bishop2006pattern,  @arnold2019computational and, for more of a deep learning focus, @goodfellow2016deep and/or @udl2023. \n\n## Is there code?  {.unnumbered}\n\nWe definitely want to decouple the content from specific software. [One of our other books](http://appliedpredictivemodeling.com/) on modeling had computing sections. They are nice to peruse, and people enjoyed having them there. However, they can quickly become outdated and take up a lot of space. \n\nThe sources for the material use R, and early adopters can find them in the [GitHub repository](https://github.com/aml4td/website). \n\nHowever, we will create other websites with computing supplements for R and/or Python (and hopefully more in the future). The supplement currently in-progress is: \n\n- [`tidymodels.aml4td.org`](https://tidymodels.aml4td.org)\n\nIf you are interested in working on a python/scikit-learn supplement, please [file an issue](https://github.com//aml4td/website/issues)  \n\n\n## How can I ask questions? \n\nIf you have questions about the content, it is probably best to ask on a public forum, like [cross-validated](https://stats.stackexchange.com/). You'll most likely get a faster answer there if you take the time to ask the questions in the best way possible.   \n\nIf you want a direct answer from us, you should follow what I call [_Yihui's Rule_](https://yihui.org/en/2017/08/so-gh-email/): add an issue to GitHub (labeled as \"Discussion\") first. It may take some time for us to get back to you. \n\nIf you think there is a bug, please [file an issue](https://github.com//aml4td/website/issues). \n\n## Can I contribute?  {.unnumbered}\n\nThere is a [contributing page](chapters/contributing.html) with details on how to get up and running to compile the materials (there are a lot of software dependencies) and suggestions on how to help. \n\nIf you just want to fix a typo, you can make a pull request to alter the appropriate `.qmd` file. \n\nPlease feel free to improve the quality of this content by submitting **pull requests**. A merged PR will make you appear in the contributor list. It will, however, be considered a donation of your work to this project. You are still bound by the conditions of the license, meaning that you are **not considered an author, copyright holder, or owner** of the content once it has been merged in.\n\n## Computing Notes {.unnumbered}\n\n\n\n\n\n[Quarto](https://quarto.org/) was used to compile and render the materials\n\n\n::: {.cell layout-align=\"center\"}\n\n```\nQuarto 1.4.510\n[✓] Checking versions of quarto binary dependencies...\n      Pandoc version 3.1.9: OK\n      Dart Sass version 1.69.5: OK\n      Deno version 1.37.2: OK\n[✓] Checking versions of quarto dependencies......OK\n[✓] Checking Quarto installation......OK\n      Version: 1.4.510\n[✓] Checking tools....................OK\n      TinyTeX: (external install)\n      Chromium: (not installed)\n[✓] Checking LaTeX....................OK\n      Using: TinyTex\n      Version: 2022\n[✓] Checking basic markdown render....OK\n[✓] Checking Python 3 installation....OK\n      Version: 3.11.4\n      Jupyter: (None)\n      Jupyter is not available in this Python installation.\n[✓] Checking R installation...........OK\n      Version: 4.3.1\n      LibPaths:\n      knitr: 1.45\n      rmarkdown: 2.25\n[✓] Checking Knitr engine render......OK\n```\n:::\n\n\n[R version 4.3.1 (2023-06-16)](https://en.wikipedia.org/wiki/R_(programming_language)) was used for the majority of the computations. [torch](https://en.wikipedia.org/wiki/Torch_(machine_learning)) 1.13.1 was also used. The versions of the primary R modeling and visualization packages used here are: \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|                       |                        |                        |\n|:----------------------|:-----------------------|:-----------------------|\n|`applicable` (0.1.0)   |`baguette` (1.0.1)      |`bestNormalize` (1.9.1) |\n|`bonsai` (0.2.1)       |`broom` (1.0.5)         |`brulee` (0.2.0)        |\n|`C50` (0.1.8)          |`Cubist` (0.4.2.1)      |`DALEXtra` (2.3.0)      |\n|`dbarts` (0.9-23)      |`desirability2` (0.0.1) |`dials` (1.2.0)         |\n|`dimRed` (0.2.6)       |`discrim` (1.0.1)       |`doMC` (1.3.8)          |\n|`dplyr` (1.1.4)        |`e1071` (1.7-13)        |`earth` (5.3.2)         |\n|`embed` (1.1.3)        |`finetune` (1.1.0)      |`GA` (3.2.3)            |\n|`gganimate` (1.0.8)    |`ggiraph` (0.8.7)       |`ggplot2` (3.4.4)       |\n|`glmnet` (4.1-8)       |`gt` (0.10.0)           |`hardhat` (1.3.0)       |\n|`ipred` (0.9-14)       |`irlba` (2.3.5.1)       |`kernlab` (0.9-32)      |\n|`kknn` (1.3.1)         |`klaR` (1.7-2)          |`lightgbm` (3.3.5)      |\n|`mda` (0.5-4)          |`mgcv` (1.9-0)          |`mixOmics` (6.25.1)     |\n|`modeldata` (1.2.0)    |`modeldatatoo` (0.2.1)  |`pamr` (1.56.1)         |\n|`parsnip` (1.1.1)      |`partykit` (1.2-20)     |`patchwork` (1.1.3)     |\n|`plsmod` (1.0.0)       |`probably` (1.0.2)      |`pROC` (1.18.5)         |\n|`purrr` (1.0.2)        |`ragg` (1.2.6)          |`ranger` (0.16.0)       |\n|`recipes` (1.0.8)      |`rpart` (4.1.21)        |`rsample` (1.2.0)       |\n|`rstudioapi` (0.15.0)  |`rules` (1.0.2)         |`sparsediscrim` (0.3.0) |\n|`sparseLDA` (0.1-9)    |`spatialsample` (0.5.1) |`splines2` (0.5.1)      |\n|`stacks` (1.0.3)       |`stopwords` (2.3)       |`textrecipes` (1.0.6)   |\n|`themis` (1.0.2)       |`tidymodels` (1.1.1)    |`tidyposterior` (1.0.1) |\n|`tidyr` (1.3.0)        |`torch` (0.11.0)        |`tune` (1.1.2)          |\n|`usethis` (2.2.2)      |`VBsparsePCA` (0.1.0)   |`workflows` (1.1.3)     |\n|`workflowsets` (1.0.1) |`xgboost` (1.7.5.1)     |`xrf` (0.2.2)           |\n|`yardstick` (1.2.0)    |                        |                        |\n\n\n:::\n:::\n\n\n\n## Chapter References {.unnumbered}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}