<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.3">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>11&nbsp; Grid Search – Applied Machine Learning for Tabular Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/resampling.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-grid-search" class="quarto-section-identifier"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Grid Search</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../"></a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/aml4td/website/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/news.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">News</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/contributing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/whole-game.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Whole Game</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Preparation</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/initial-data-splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Initial Data Splitting</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/missing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Missing Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/numeric-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transforming Numeric Predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/categorical-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Working with Categorical Predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Embeddings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/interactions-nonlinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Interactions and Nonlinear Features</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Optimization</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/overfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Overfitting</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/resampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Measuring Performance with Resampling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/grid-search.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Grid Search</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Classification</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Regression</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Characterization</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Finalization</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-regular-grid" id="toc-sec-regular-grid" class="nav-link active" data-scroll-target="#sec-regular-grid"><span class="header-section-number">11.1</span> Regular Grids</a></li>
  <li><a href="#sec-irregular-grid" id="toc-sec-irregular-grid" class="nav-link" data-scroll-target="#sec-irregular-grid"><span class="header-section-number">11.2</span> Irregular Grids</a></li>
  <li><a href="#sec-efficient-grid" id="toc-sec-efficient-grid" class="nav-link" data-scroll-target="#sec-efficient-grid"><span class="header-section-number">11.3</span> Efficient Computations for Conventional Grid Search</a>
  <ul class="collapse">
  <li><a href="#sec-Submodels" id="toc-sec-Submodels" class="nav-link" data-scroll-target="#sec-Submodels"><span class="header-section-number">11.3.1</span> Submodels</a></li>
  <li><a href="#sec-parallel" id="toc-sec-parallel" class="nav-link" data-scroll-target="#sec-parallel"><span class="header-section-number">11.3.2</span> Parallel Processing</a></li>
  <li><a href="#sec-racing" id="toc-sec-racing" class="nav-link" data-scroll-target="#sec-racing"><span class="header-section-number">11.3.3</span> Racing</a></li>
  </ul></li>
  <li><a href="#sec-nested-resampling" id="toc-sec-nested-resampling" class="nav-link" data-scroll-target="#sec-nested-resampling"><span class="header-section-number">11.4</span> Optimization Bias and Nested Resampling</a></li>
  <li><a href="#setting-parameter-ranges" id="toc-setting-parameter-ranges" class="nav-link" data-scroll-target="#setting-parameter-ranges"><span class="header-section-number">11.5</span> Setting Parameter Ranges</a></li>
  <li><a href="#chapter-references" id="toc-chapter-references" class="nav-link" data-scroll-target="#chapter-references">Chapter References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-grid-search" class="quarto-section-identifier"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Grid Search</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Grid search is a method to optimize a model pipeline’s tuning parameters. It creates a pre-defined set of candidate values and computes performance for each. From there, the numerically best candidate could be chosen, or the relationship between the tuning parameter(s) and model performance can be inspected to see if the model might benefit from additional optimization.</p>
<p>Suppose there is a single tuning parameter, as in the <span class="math inline">\(n_{min}\)</span> example of <a href="overfitting.html#sec-external-validation" class="quarto-xref"><span>Section 9.3</span></a>; each candidate takes a scalar value (quantitative or qualitative). For other models, there are multiple tuning parameters. For example, support vector machine models can have two or three tuning parameters, the Elastic Net model has two tuning parameters, and the boosted tree model has multiple tuning parameters. We’ll look at two of the boosted tree parameters in detail below.</p>
<p>The previous chapter demonstrated that using external data to evaluate the model is crucial (be it resampling or a validation set). Grid search has no free lunch: we cannot simply fit the model to each candidate set and evaluate them by simply re-predicting the same data.</p>
<p><a href="#alg-grid-search" class="quarto-xref">Algorithm&nbsp;<span>11.1</span></a> formally describes the grid search process. For a model with <span class="math inline">\(m\)</span> tuning parameters, we let <span class="math inline">\(\Theta\)</span> represent the collection of <span class="math inline">\(s\)</span> candidate values. For each specific combination of parameters (<span class="math inline">\(\theta_j\)</span>), we resample the model to produce some measure of efficacy (e.g., <span class="math inline">\(R^2\)</span>, accuracy, etc.)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. From there, the best value is chosen, or additional work is carried out to find a suitable candidate.</p>
<div id="alg-grid-search" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-alg figure">
<div aria-describedby="alg-grid-search-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="columns">
<div class="column" style="width:10%;">

</div><div class="column" style="width:80%;">
<div class="pseudocode-container" data-pseudocode-index="1" data-alg-title="Algorithm" data-line-number="true" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \begin{algorithmic} \State $\mathfrak{D}^{tr}$: training set of predictors $X$ and outcome $y$ \State $B$: number of resamples \State $M(\mathfrak{D}^{tr}, B)$: a mapping function to split $\mathfrak{D}^{tr}$ for each of $B$ iterations. \State $f()$: model pipeline \State $\Theta$: Parameter set ($s \times m$) with candidates $\theta_j$ \For{$j=1$ \To $s$} \State Generate $\hat{Q}_{j} =$ \Call{Resample}{$\mathfrak{D}^{tr}, f(\cdot;\theta_j), M(\mathfrak{D}^{tr}, B)$} corresponding to candidate $\theta_j$. \EndFor \State Determine $\hat{\theta}_{opt}$ that optimizes $\hat{Q}_{j}$. \end{algorithmic} \end{algorithm}
</div>
</div>
</div><div class="column" style="width:10%;">

</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-alg" id="alg-grid-search-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Algorithm&nbsp;11.1: Grid search for tuning parameter optimization that loops over the resampling algorithm shown in <a href="resampling.html#alg-resampling" class="quarto-xref">Algorithm&nbsp;<span>10.1</span></a>.
</figcaption>
</figure>
</div>
<p>To demonstrate, this chapter will initially focus on grids for a boosted tree model with two tuning parameters. Recall that a boosted tree is a collection of individual decision trees created sequentially. One parameter related to the process of creating the ensemble is the learning rate: the next tree uses information from the last tree to improve it. An important parameter is how much, or how <em>fast</em> it learns. It could be that some data sets need a large number of trees that evolve slowly (i.e., low learning rate) to find an optimal value of the performance metric. Alternatively, other data sets require fewer trees that change rapidly for optimal predictive performance. The learning rate parameter must be greater than zero, and is typically in the range of 10<sup>-5</sup> to 10<sup>-1</sup>. Because the range of this parameter is very large, it is best conceptualized in log units.</p>
<p>We’ll illustrate different strategies of grid search using this model setup with varying configurations of the learning rate and the number of trees in the ensemble.</p>
<p>There are two main classes of grids: regular and irregular. We can view generating a collection of candidate models as a statistical design of experiments (DOE) problem <span class="citation" data-cites="BHH">(<a href="#ref-BHH" role="doc-biblioref">Box, Hunter, and Hunter 1978</a>)</span>. There is a long history of DOE, and we’ll invoke relevant methods for each grid type. <span class="citation" data-cites="santner2018design">Santner, Williams, and Notz (<a href="#ref-santner2018design" role="doc-biblioref">2018</a>)</span> and <span class="citation" data-cites="gramacy2020surrogates">Gramacy (<a href="#ref-gramacy2020surrogates" role="doc-biblioref">2020</a>)</span> have excellent overviews of the DOE methods discussed in this chapter.</p>
<p>The following two sections describe different methods for creating the candidate set <span class="math inline">\(\Theta\)</span>. Subsequent sections describe strategies for making grid search efficient using tools such as parallel processing and model racing.</p>
<section id="sec-regular-grid" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="sec-regular-grid"><span class="header-section-number">11.1</span> Regular Grids</h2>
<p>A regular grid starts with a sequence or set of candidate values for each tuning parameter and then creates all combinations. In statistics, this is referred to as a factorial design. The number of values per tuning parameter does not have to be the same.</p>
<p>To illustrate a regular grid, we’ll use five values of the number of trees (1, 500, 1000, 1500, and 2000) and three values of the learning rate (10<sup>-3</sup>, 10<sup>-2</sup>, and 10<sup>-1</sup>). This grid of 15 candidates is shown in <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a>. The grid covers the entire space with significant lacuna in between.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bst-grids" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bst-grids-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-bst-grids-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bst-grids-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.1: Three types of grids (in columns) are illustrated with tuning parameters from a boosting model. Each grid contains 15 candidates. The space-filling design was created using the Audze-Eglais method described in <a href="#sec-irregular-grid" class="quarto-xref"><span>Section 11.2</span></a>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We’ll use the simulated training set in <a href="overfitting.html#sec-complexity" class="quarto-xref"><span>Section 9.1</span></a> with the same 10-fold cross-validation scheme described there. Once again, Brier scores were used to measure how well each of the 15 configurations of boosted tree model predicted the data. <a href="#fig-bst-regular-grid-tuning" class="quarto-xref">Figure&nbsp;<span>11.2</span></a> shows the results: a single tree is a poor choice (due to underfitting), and there are several learning rate values that work well. Even though this is not a diverse set of candidate values, we can probably pick out a reasonable candidate with a small Brier score, such as 500 trees and and a learning rate of 10<sup>-2</sup> (although there are a few other candidates that would be good choices).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bst-regular-grid-tuning" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bst-regular-grid-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-bst-regular-grid-tuning-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bst-regular-grid-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.2: The boosted tree tuning results for the regular grid shown in <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The pattern shown in this visualization is interesting: the trajectory for the number of trees is different for different values of the learning rate. The two larger learning rates are similar, showing that the optimal number of trees is in the low- to mid-range of our grid. The results for the smallest learning rate indicate that better performance might be found using <em>more</em> trees than were evaluated. This indicates that there is an <em>interaction effect</em> in our tuning parameters (just as we saw for predictors in <a href="interactions-nonlinear.html#sec-interactions" class="quarto-xref"><span>Section 8.1</span></a>). This might not affect how we select the best candidate value for the grid, but it does help build some intuition for this particular model that might come in handy when tuning future models.</p>
<p>Gaining intuition is much easier for regular grids than other designs since we have a full set of combinations. As we’ll see shortly, this interaction is very hard to see for a space-filling design.</p>
<p>The primary downside to regular grids is that, as the number of tuning parameters increases, the number of points required to fill the space becomes extremely large (due to the curse of dimensionality). However, for some models and pre-processing methods, regular grids can be very efficient despite the number of tuning parameters (see the following section that describes the “submodel trick”).</p>
</section>
<section id="sec-irregular-grid" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="sec-irregular-grid"><span class="header-section-number">11.2</span> Irregular Grids</h2>
<p>Irregular grids are not factorial in nature. A simple example is a <em>random grid</em> where points are randomly placed using a uniform distribution on an appropriate range for each tuning parameter. A design of size 15 is shown in <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a>. There are some gaps and clustering of the points, but the space for each individual dimension is covered well. The tuning results are shown in the top panels of <a href="#fig-bst-irregular-grid-tuning" class="quarto-xref">Figure&nbsp;<span>11.3</span></a>. Because it is an irregular design, we can’t use the same visualization as in <a href="#fig-bst-regular-grid-tuning" class="quarto-xref">Figure&nbsp;<span>11.2</span></a>. Instead, a “marginal” plot is shown, where each numeric tuning parameter is plotted against performance in a separate panel.</p>
<p>The top left panel suggests that a very small learning rate is bad, but otherwise, there is not a strong trend. For the number of trees (in the top right panel), a small number of trees should be avoided, and perhaps the maximum number tested would be a good choice. From this plot, it is impossible to discover the interaction effect seen with the regular grid. However, this marginal plot is the main technique for visualizing the results when there are a moderate to large number of tuning parameters. The numerically best candidate was not too dissimilar from the regular grid: 1,898 trees and and a learning rate of 10<sup>-2.7</sup></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bst-irregular-grid-tuning" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bst-irregular-grid-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-bst-irregular-grid-tuning-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bst-irregular-grid-tuning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.3: The tuning results for the irregular grids shown in <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a>. The lines are spline smooths.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Another type of irregular grid is a <em>space-filling design</em> <span class="citation" data-cites="joseph2016space">(<a href="#ref-joseph2016space" role="doc-biblioref">Joseph 2016</a>)</span>, where the goal is to make sure that the tuning parameter space is covered and that there is minimal redundancy in the candidate values. There are a variety of methods for achieving this goal.</p>
<p>For example, <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a> shows a 15 point Audze-Eglais space-filling design. The space is covered more compactly than the regular design of the same size and is much more uniform than the 15 point random design. The lower panels of <a href="#fig-bst-irregular-grid-tuning" class="quarto-xref">Figure&nbsp;<span>11.3</span></a> show the tuning results. The results are somewhat cleaner than the random grid results but show similar trends. Here, the numerically best candidate was: 286 trees and and a learning rate of 10<sup>-2</sup>.</p>
<p>There are many types of space-filling designs, and it is worth taking the time to take a quick tour of some of them.</p>
<p>The Latin hypercube design (LHD) is the most popular method for constructing space-filling designs <span class="citation" data-cites="Viana2016 husslage2011space">(<a href="#ref-husslage2011space" role="doc-biblioref">Husslage et al. 2011</a>; <a href="#ref-Viana2016" role="doc-biblioref">Viana 2016</a>)</span>. These designs have a simple definition. Suppose our hyperparameter space is rectangular and partitioned into smaller (hyper)cubes. From this, a LHD is a set of distinct points where no one dimension has multiple values in any bins<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. We desire candidates that fill the space of each parameter and are not close to one another.</p>
<p>The most basic approach to creating a Latin hypercube design is random sampling <span class="citation" data-cites="Mckay2000">(<a href="#ref-Mckay2000" role="doc-biblioref">Mckay, Beckman, and Conover 2000</a>)</span>. If there are <span class="math inline">\(m\)</span> parameters and we request <span class="math inline">\(s\)</span> candidate values, the parameter space is initially divided into <span class="math inline">\(s^m\)</span> hypercubes of equal size. For each tuning parameter, <span class="math inline">\(s\)</span> regions in its dimension are selected at random, and a value is placed in this box (also at random). This process repeats for each dimension. Suppose there are ten bins for a parameter that ranges between zero and one. If the first design point selects bin two, a random uniform value is created in the range <code>[0.1 0.2)</code>. <a href="#fig-lhs-sampled" class="quarto-xref">Figure&nbsp;<span>11.4</span></a> shows three such designs, each generated with different random numbers.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-lhs-sampled" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-lhs-sampled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-lhs-sampled-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-lhs-sampled-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.4: Three replicate Latin hypercube sampling designs of size ten for two parameters. Each design uses different random numbers. The grid lines illustrate the 100 hypercubes used to generate the values.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Technically, these designs cover the space of each predictor uniformly. However, large multivariate regions can be empty. For example, one design only samples combinations along the diagonal. Additional constraints can make the design more consistent with our desires.</p>
<p>For example, we could choose points to maximize the minimum pairwise distances between the candidates. These designs are usually referred to as MaxiMin designs <span class="citation" data-cites="pronzato2017minimax">(<a href="#ref-pronzato2017minimax" role="doc-biblioref">Pronzato 2017</a>)</span>. Comparing the two irregular designs in <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a>, the random grid has a maximum minimum distance between candidates of 0.09. In contrast, the corresponding space-filling design’s value (0.26) is 2.9-fold larger<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The latter design was optimized for coverage, and we can see far less redundancy in this design.</p>
<p>A similar method, initially proposed by <span class="citation" data-cites="audze1977new">Audze and Eglais (<a href="#ref-audze1977new" role="doc-biblioref">1977</a>)</span>, maximizes a function of the inverse distances between <span class="math inline">\(s\)</span> candidate points:</p>
<p><span class="math display">\[
criterion = \sum_{i=1}^s \sum_{j=1,\;i\ne j}^s\frac{1}{dist(\theta_i, \theta_j)^2}
\]</span></p>
<p><span class="citation" data-cites="bates2004formulation">Bates, Sienz, and Toropov (<a href="#ref-bates2004formulation" role="doc-biblioref">2004</a>)</span> devised search methods to find optimal designs for this criterion.</p>
<p>Some other space-filling designs of note:</p>
<ul>
<li><p>Maximum entropy sampling selects points based on assumptions related to the distributions of the tuning parameters and their covariance matrix <span class="citation" data-cites="shewry1987maximum joseph2015maximum">(<a href="#ref-shewry1987maximum" role="doc-biblioref">Shewry and Wynn 1987</a>; <a href="#ref-joseph2015maximum" role="doc-biblioref">Joseph, Gul, and Ba 2015</a>)</span>.</p></li>
<li><p>Uniform designs <span class="citation" data-cites="fang2000uniform wang2022design">(<a href="#ref-fang2000uniform" role="doc-biblioref">Fang et al. 2000</a>; <a href="#ref-wang2022design" role="doc-biblioref">Wang, Sun, and Xu 2022</a>)</span> optimally allocate points so that they are uniformly distributed in the space.</p></li>
</ul>
<p>While these methods can be generally constructed by sampling random points and using a search method to optimize a specific criterion, there has been scholarship that has pre-optimized designs for some combination of the number of tuning parameters and the requested grid size.</p>
<p>The advantage of space-filling designs over random designs is that, for smaller designs, the candidates do a better job covering the space and have a low probability of producing redundant points. Also, it is possible to create a space-filling design so that the candidates for each numerical parameter are nearly equally spaced (as was done in <a href="#fig-bst-grids" class="quarto-xref">Figure&nbsp;<span>11.1</span></a>).</p>
<p>Many designs assume that all the tuning parameter values are quantitative. That may not always be the case. For example, K-nearest neighbors can adjust its predictions by considering how far the cost are from a new point; more distant points should not have the same influence as close cost. A weighting function can be used for this purpose. For example, weights based on the inverse of the distance between neighbors may produce better results. Equal weighting is often called a “rectangular weighting” function. The type of algebraic function used for weighting is a qualitative tuning parameter.</p>
<p>A simple workaround for creating a space-filling design is to repeat the unique parameter values as if they were <span class="math inline">\(s\)</span> distinct values when making the design. This allows them to be used with a Latin hypercube design and any space-filling design that uses this approach is not technically optimal. Practically speaking, this is an effective approach for tuning models. However, there are <em>sliced</em> LHD that can accomplish the same goal <span class="citation" data-cites="qian2012sliced ba2015optimal">(<a href="#ref-qian2012sliced" role="doc-biblioref">Qian 2012</a>; <a href="#ref-ba2015optimal" role="doc-biblioref">Ba, Myers, and Brenneman 2015</a>)</span>.</p>
<p>We recommend space-filling designs since they are more efficient than regular designs. Regular designs have a lot of benefits when using an unfamiliar modeling methodology since you will learn a lot more about the nuances of how the tuning parameters affect one another.</p>
</section>
<section id="sec-efficient-grid" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="sec-efficient-grid"><span class="header-section-number">11.3</span> Efficient Computations for Conventional Grid Search</h2>
<p>The computational cost of grid search can become large, depending on the resampling strategy and the number of candidates under consideration. In our example, a total of 150 boosted tree models are evaluated (5 values of the number of trees, 3 values of the learning rate, and 10-fold cross-validation) before determining which candidates are most favorable to our data.</p>
<p>We’ll look at three approaches to making grid search more efficient. One method (submodels) happens automatically for some types of models, another approach (parallel processing) uses software engineering tools, and the last tool (racing) is a statistical solution.</p>
<p>To illustrate these more efficient search approaches, a 100 grid point space-filling design will be used with a large parameter range (1 to 3000 trees) and learning rates between 10<sup>-5</sup> and 10<sup>-1</sup>.</p>
<section id="sec-Submodels" class="level3" data-number="11.3.1">
<h3 data-number="11.3.1" class="anchored" data-anchor-id="sec-Submodels"><span class="header-section-number">11.3.1</span> Submodels</h3>
<p>Let’s begin by understanding the submodel trick. For some models a single training model can be used to predict many tuning parameter candidates. For example, the boosted tree model that we have been using creates a sequential ensemble of decision trees, each depending on the previous. Suppose that a boosting model with 3,000 trees is created. Most implementations of boosted trees can use this model to predict the outcomes of any smaller ensemble size. Therefore, we only need to build the boosted tree model using the largest number of trees for each specific combination of the remaining tuning parameters. For a regular grid, this can effectively drop a dimension of the computations. Depending on the model and grid, the speed-up for using this approach can be well into double digits.</p>
<p>Some different models and pre-processors can have this quality, including the glmnet model (<span class="quarto-unresolved-ref">?sec-penalized-logistic-regression</span>), partial least squares (<a href="embeddings.html#sec-pls" class="quarto-xref"><span>Section 7.2.3</span></a>), principal component feature extraction (<a href="embeddings.html#sec-pca" class="quarto-xref"><span>Section 7.2.1</span></a>), and others.</p>
<p>Unfortunately, irregular designs cannot exploit the submodel trick since they are not factorial in nature. A hybrid design could be used where a dense sequence of <span class="math inline">\(s_1\)</span> parameter values is created for the tuning parameter associated with submodels and a separate space-filling design of size <span class="math inline">\(s_2\)</span> for the other parameters. These two grids can be crossed so that the space-filling design is replicated for each value of the submodel parameter. This produces <span class="math inline">\(s_1\times s_2\)</span> grid points but, effectively, only <span class="math inline">\(s_2\)</span> models are fit.</p>
<p>For our larger grid, we created a similar regular grid of 100 points with the same expanded ranges of parameters. There were 10 unique, evenly spaced values for both parameters. To evaluate this grid, we only need to train 10 models. Compared to the analogous space-filling design, the regular grid was 3.8 times faster to evaluate.</p>
</section>
<section id="sec-parallel" class="level3" data-number="11.3.2">
<h3 data-number="11.3.2" class="anchored" data-anchor-id="sec-parallel"><span class="header-section-number">11.3.2</span> Parallel Processing</h3>
<p>Fortunately, none of the 1,000 models in our large grid depend on one another and can be computed separately. Since almost all modern computers have GPUs and multiple CPUs, we can break the computations into different “chunks” of work and execute them simultaneously on distinct processors (or separate computers entirely). The parallel processing of models can significantly reduce the time it takes to tune using grid search.</p>
<p>For example, consider the space-filling designs with 15 candidates evaluated across 10 resamples. We spread the 150 model fits across 10 worker processes (on the same computer). Despite the meager computation costs of training each boosted tree, there was still a 6.4-fold speedup (26s versus 4.1s) when run in parallel.</p>
<p>However, there are some important nuances that we should consider before initiating parallel processing.</p>
<p>First, it is an excellent idea to parallelize the “longest loop” (literally or figuratively). Looking back at <a href="#alg-grid-search" class="quarto-xref">Algorithm&nbsp;<span>11.1</span></a>, there is a loop across the <span class="math inline">\(s\)</span> candidates in line 6. Line 7 contains the resampling loop across <span class="math inline">\(B\)</span> resamples. If the data set is large, it may be optimal to invert the loop where we parallel process across the <span class="math inline">\(B\)</span> resamples and execute the <span class="math inline">\(s\)</span> models within each. Keeping each resample on a single worker means less input/output traffic across the workers. See <span class="citation" data-cites="tmwr">Kuhn and Silge (<a href="#ref-tmwr" role="doc-biblioref">2022</a>)</span> <a href="https://www.tmwr.org/grid-search#parallel-processing">Section 13.5.2</a>. Alternatively, if the data are not large, it could be best to “flatten” the two loops into a single loop with <span class="math inline">\(s\times B\)</span> iterations (with as many workers as possible).</p>
<p>Additionally, if expensive preprocessing is used, a naive approach where each pipeline is processed in parallel might be counterproductive because we unnecessarily repeat the same preprocessing. For example, suppose we are tuning a supervised model along with UMAP preprocessing. By sending each of the <span class="math inline">\(s\)</span> candidates to a worker, the same UMAP training occurs for each set of candidates that correspond to the supervised model. Instead, a <em>conditional process</em> can be used where we loop across the UMAP tuning parameter combinations and, for each, run another loop across the parameters associated with the supervised model.</p>
<p>Another consideration is memory. If the data used to train and evaluate the model are copied for each worker, the number of workers can be restricted to fit within system memory. A well thought out process can avoid this unnecessary restriction.</p>
<p>When we understand the computational aspects of parallel processing, we can almost always use it to greatly reduce the time required for model tuning.</p>
</section>
<section id="sec-racing" class="level3" data-number="11.3.3">
<h3 data-number="11.3.3" class="anchored" data-anchor-id="sec-racing"><span class="header-section-number">11.3.3</span> Racing</h3>
<p>A third way we can improve the model tuning process is through Racing <span class="citation" data-cites="maron1997racing">(<a href="#ref-maron1997racing" role="doc-biblioref">Maron and Moore 1997</a>)</span>. This technique adaptively resamples the data during grid search. The goal is to cull tuning parameter combinations that have no real hope of being optimal before they are completely resampled. For example, in our previous tuning of the boosting model using a regular grid, it is clear that a single tree performs very poorly. Unfortunately, we will not know this until all the computations are finished.</p>
<p>Racing tries to circumvent this issue by doing an interim statistical analysis of the tuning results. From this, we can compute a probability (or score) that measures how likely each candidate will be the best (for some single metric). If a candidate is exceedingly poor, we usually can tell that after just a few resamples<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p>There are a variety of ways to do this. See <span class="citation" data-cites="kuhn2014futility">Kuhn (<a href="#ref-kuhn2014futility" role="doc-biblioref">2014</a>)</span>, <span class="citation" data-cites="krueger2015fast">Krueger, Panknin, and Braun (<a href="#ref-krueger2015fast" role="doc-biblioref">2015</a>)</span>, and <span class="citation" data-cites="bergman2024don">Bergman, Purucker, and Hutter (<a href="#ref-bergman2024don" role="doc-biblioref">2024</a>)</span>. The general process is shown in <a href="#alg-race" class="quarto-xref">Algorithm&nbsp;<span>11.2</span></a>. The resampling process starts normally for the first <span class="math inline">\(B_{min}\)</span> resamples. Lines 7-12 can be conducted in parallel for additional computation speed. After the initial resampling for all candidates, the interim analysis at iteration <span class="math inline">\(b\)</span> results in a potentially smaller set of <span class="math inline">\(s_b\)</span> candidates. Note that parallel processing can be incorporated into this process for each loop and the speed-up from using submodels also occurs automatically.</p>
<p>At each resampling estimate beyond the first <span class="math inline">\(B_{min}\)</span> iterations, the current candidate set is evaluated for a single resample, and the interim analysis potentially prunes tuning parameter combinations.</p>
<div id="alg-race" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-alg figure">
<div aria-describedby="alg-race-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="columns">
<div class="column" style="width:10%;">

</div><div class="column" style="width:80%;">
<div id="alg-race" class="pseudocode-container" data-pseudocode-index="2" data-alg-title="Algorithm" data-line-number="true" data-line-number-punc=":">
<div class="pseudocode">
\begin{algorithm} \begin{algorithmic} \State $\mathfrak{D}^{tr}$: training set of predictors $X$ and outcome $y$ \State $B$: number of resamples \State Initial number of resamples $1 \lt B_{min} \lt B$ executed prior to analysis \State $M(\mathfrak{D}^{tr}, B)$: a mapping function to split $\mathfrak{D}^{tr}$ for each of $B$ iterations. \State $f()$: model pipeline \State $\Theta$: Parameter set ($s \times m$) with candidates $\theta_j$ \For{$j=1$ \To $s$} \For{$b=1$ \To $B_{min}$} \State Generate $\hat{Q}_{jb} =$ \Call{Resample}{$\mathfrak{D}^{tr}, f(\cdot;\theta_j), M_b(\mathfrak{D}^{tr}, B)$} \EndFor \State Compute $\hat{Q}_{j} = 1/B_{min}\sum_b \hat{Q}_{jb}$. \EndFor \State Eliminate candidates to produce $\Theta^b$ ($s_b \times m$) \For{$b = B_{min} + 1$ \To $B$} \For{$j=1$ \To $s$} \State Generate $\hat{Q}_{jb} =$ \Call{Resample}{$\mathfrak{D}^{tr}, f(\cdot;\theta_j), M_b(\mathfrak{D}^{tr}, B)$} \State Update candidate subset $\Theta^b$ by applying the filtering analysis \Endfor \Endfor \State Determine $\hat{\theta}_{opt}$ that optimizes $\hat{Q}_j^k$. \end{algorithmic} \end{algorithm}
</div>
</div>
</div><div class="column" style="width:10%;">

</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-alg" id="alg-race-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Algorithm&nbsp;11.2: Using racing for grid search tuning parameter optimization.
</figcaption>
</figure>
</div>
<p>The details are in the analysis used to discard tuning parameter combinations. For simplicity, we’ll focus on a basic method that uses a form of analysis of variance (ANOVA), a standard statistical tool for determining whether there are differences between conditions <span class="citation" data-cites="kutner2004applied">(<a href="#ref-kutner2004applied" role="doc-biblioref">Kutner, Nachtsheim, and Neter 2004</a>)</span>. In our context, the conditions are the tuning parameter candidates; we ignore their values and treat them as qualitative samples from the distribution of all possible tuning parameter combinations. The ANOVA model uses the candidate conditions as the predictor and the metric of choice as the numeric outcome.</p>
<p>There are two statistical considerations that we need to understand when using an ANOVA model for evaluating Racing results.</p>
<p>First, the ANOVA model is used for statistical inference. Specifically, we’ll use it to compute confidence intervals on differences in performance. This means that the probabilistic assumptions about our data matter. The ANOVA method requires that the errors follow a Gaussian distribution. That distribution can be strongly influenced by the distribution of the outcome, and, in our case, this is a performance metric. Previously, we used the Brier score, which has non-negative values and might be prone to follow a right-skewed statistical distribution. However, each resampled Brier score is the average of differences, and the Central Limit Theorem suggests that as the number of data points used to compute the score increases, the sampling distribution will become more Gaussian. If we use this approach to assess parameter candidates, then we should check the normality assumptions of the errors.</p>
<p>The second statistical complication is related to the resamples. Basic ANOVA methods require the data to be independent of one another, which is definitely not the case for resampling results. A “within-resample” correlation occurs since some resamples are “easier” to predict than others. This means that the metrics associated with each resample are more similar to one another than to the metrics from other resamples.</p>
<p>This extra correlation means that a simple ANOVA model cannot be used. Instead, our interim analysis should instead use a hierarchical random effects model. This is the same methodology used in <a href="categorical-predictors.html#sec-effect-encodings" class="quarto-xref"><span>Section 6.4.3</span></a> for effect encodings. We’ll treat our set of resamples as a random sample of possible resampling indices. The ANOVA model itself is:</p>
<p><span id="eq-perf-mod-racing"><span class="math display">\[
Q_{ij} =(\beta_0 + \beta_{0i}) + \beta_1x_{i1} + \ldots +  \beta_{s-1}x_{i(s-1)}+ \epsilon_{ij}
\tag{11.1}\]</span></span></p>
<p>for <span class="math inline">\(i=1,\ldots, B\)</span> resamples and <span class="math inline">\(j=1, \ldots, s\)</span> candidates. This random intercept model assumes that the ranking of candidates is the same across resamples and only the magnitude of the pattern changes from resample to resample.</p>
<p>This model’s form is the reference cell parameterization discussed in <a href="categorical-predictors.html#sec-indicators" class="quarto-xref"><span>Section 6.2</span></a>. For each interim analysis, the reference cell will be set to the current best candidate. This means that the <span class="math inline">\(\hat{\beta}_j\)</span> parameter estimates represent the loss of performance relative to the current best. A one-sided confidence interval is constructed to determine if a candidate should be removed. We can stop considering candidates whose interval does not contain zero.</p>
<p>To demonstrate the racing procedure, we re-evaluated our larger a space-filling design. The order of the folds was randomized, and after 3 resamples, the ANOVA method was used to analyze the results. <a href="#fig-racing-initial" class="quarto-xref">Figure&nbsp;<span>11.5</span></a> shows the one-sided 95% confidence intervals for the loss of Brier score relative to the current best configuration (2030 trees and a learning rate of 10<sup>-2.78</sup>). Sixty-Six were eliminated at this round.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-racing-initial" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-racing-initial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-racing-initial-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-racing-initial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.5: The first interim analysis in racing using a larger space-filling design for the boosted tree model.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In the end, the racing process eliminated all but 7 candidates. The process eliminated candidates at iterations three (66 configurations), four (14 configurations), five (7 configurations), six (1 configuration), seven (2 configurations), eight (2 configurations), and nine (1 configuration). In all, 404 models were fit out of the possible 1,000 (40.4%). The numerically best candidate set for racing and basic grid search were the same: 576 trees and and a learning rate of 10<sup>-2.3</sup>.</p>
<p>The model in <a href="#eq-perf-mod-racing" class="quarto-xref">Equation&nbsp;<span>11.1</span></a> allows us to estimate the within-resample correlation coefficient. This estimates how similar the performance metric values are to one another relative to values between resamples. In our example, the estimate of within resample correlation is 0.6, and is a good example of why we should use <a href="#eq-perf-mod-racing" class="quarto-xref">Equation&nbsp;<span>11.1</span></a> when culling parameter candidates.</p>
<p>In summary, racing can be an effective tool for screening a large number of models while using comprehensive grids.</p>
</section>
</section>
<section id="sec-nested-resampling" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="sec-nested-resampling"><span class="header-section-number">11.4</span> Optimization Bias and Nested Resampling</h2>
<p>In the last section, we found that the numerically best candidate was 576 trees and and a learning rate of 10<sup>-2.3</sup>. The corresponding resampling estimate of the Brier score was 0.0783 with a standard error of 0.0053. If someone were to ask us how well the optimal boosted tree performs, we would probably give them these performance estimates.</p>
<p>However, there is an issue in doing so that may affect our decision for selecting the optimal tuning parameters. We are using grid search and resampling to find the best combination of parameters <em>and</em> to estimate the corresponding performance. The problem is that we don’t know how accurate or precise the estimate of the <em>optimal</em> candidate may be. In some situations, this dual use of the model tuning process can introduce <strong>optimization bias</strong> where, to some degree, our performance statistics are optimistic.</p>
<p>This issue has been studied extensively in the high-dimensional biology literature, where there could be dozens of samples but thousands of predictors. In this case, feature selection is of paramount importance. However, the process of selecting important predictors in this situation can be very difficult and often leads to unstable models or preprocessing methods that overfit the predictor set to the data. Discussions of these issues can be found in <span class="citation" data-cites="varma2006bias">Varma and Simon (<a href="#ref-varma2006bias" role="doc-biblioref">2006</a>)</span>, <span class="citation" data-cites="boulesteix2009optimal">Boulesteix and Strobl (<a href="#ref-boulesteix2009optimal" role="doc-biblioref">2009</a>)</span>, <span class="citation" data-cites="bischl2012resampling">Bischl et al. (<a href="#ref-bischl2012resampling" role="doc-biblioref">2012</a>)</span>, and <span class="citation" data-cites="bernau2013correcting">Bernau, Augustin, and Boulesteix (<a href="#ref-bernau2013correcting" role="doc-biblioref">2013</a>)</span>.</p>
<p>In this section, we’ll introduce a few methods to quantify and correct for optimization bias. These approaches are not specific to traditional grid search; they can be used with racing, iterative search, or any algorithm that we use to optimize a model. Some of the concepts can be difficult and, for this reason, we’ll use a simplified grid search scenario. Let’s optimize our boosted tree by fixing the number of boosting iterations to 500 and only optimize the learning rate. But the tools that we are about to discuss are not limited to a single tuning parameter. Simplifying the task in this way allos us to visualize and explain the process<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>Using the same 10-fold cross-validation scheme, <a href="#fig-1d-boost" class="quarto-xref">Figure&nbsp;<span>11.6</span></a> shows the results of a conventional grid search over the learning rate where 100 values of that parameter were evaluated. As usual, the line indicates the average of the Brier scores produced by the 10 assessment sets. The results of this process indicates that the smallest Brier score is achieved with a learning rate of 10<sup>-2.23</sup>. The Brier score that corresponds to this tuning parameter value is estimated to be 0.0782 with corresponding standard error of 0.00536.</p>
<div id="fig-1d-boost" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1d-boost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="figure-content">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-1d-boost" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center" width="70%">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-1d-boost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-1d-boost-1.svg" id="fig-1d-boost" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" style="width:70.0%" data-ref-parent="fig-1d-boost">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-1d-boost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1d-boost-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.6: Basic grid search for learning rate with 100 grid points. The dotted vertical line shows the optimal learning rate using the overall resampling estimates. The colored rug values show the learning rates that were optimal <em>within each resample</em>. There were 2 learning rates selected more than once: 10<sup>-2.27</sup> and 10<sup>-1.91</sup>.
</figcaption>
</figure>
</div>
<p>How can we estimate the potential bias in the process that led to this performance metric? <span class="citation" data-cites="tibshirani2009bias">Tibshirani and Tibshirani (<a href="#ref-tibshirani2009bias" role="doc-biblioref">2009</a>)</span> describes a simple analytical estimator applicable when multiple resamples are used to estimate performance. First, we obtain the performance estimates corresponding to the optimal tuning parameter candidate <em>within each fold</em>. Let’s call these <span class="math inline">\(\hat{Q}_j^*\)</span> (where <span class="math inline">\(j=1\ldots B\)</span>). They are represented in <a href="#fig-1d-boost" class="quarto-xref">Figure&nbsp;<span>11.6</span></a> as the colored “rug” lines at the bottom of the figure. We know that our conventional analysis of this grid search finds that a learning rate of 10<sup>-2.23</sup> to be optimal. We can find the metric values associated with the global optimum for each resample (denoted as <span class="math inline">\(\hat{Q}_j^{opt}\)</span>). For each resample, we now have matched performance estimates for the local optima as well as the global optimum. The difference between these values is an estimate of the bias in optimization. If different resamples have very different optimal performance metrics compared to the optimal performance determined using the averages of the resamples (as shown in <a href="#fig-1d-boost" class="quarto-xref">Figure&nbsp;<span>11.6</span></a>), bias can increase. The estimate of the bias is then:</p>
<p><span class="math display">\[\widehat{bias} = \frac{1}{B}\sum_{j=1}^B\left[\hat{Q}_j^{opt} - \hat{Q}_j^*\right]\]</span> For this particular example, the bias is fairly small (0.000931 with standard error 0.000304). To correct the conventional estimator, we add the bias; the Brier score is adjusted from 0.0782 to 0.0791. A more complex analytical method can be found in <span class="citation" data-cites="tibshirani2018excess">Tibshirani and Rosset (<a href="#ref-tibshirani2018excess" role="doc-biblioref">2019</a>)</span>.</p>
<p>We can also estimate optimization bias with more complex resampling schemes. Recall that the issue is that we are overextending the conventional resampling scheme by doing too much with the same data (i.e., estimating overall performance assessment and the optimal performance value). Nested resampling <span class="citation" data-cites="varma2006bias boulesteix2009optimal">(<a href="#ref-varma2006bias" role="doc-biblioref">Varma and Simon 2006</a>; <a href="#ref-boulesteix2009optimal" role="doc-biblioref">Boulesteix and Strobl 2009</a>)</span> prevents this overuse by using two layers of resampling: the “inner resamples” are used to estimate the optimal candidate values, and the “outer resamples” estimate performance at those values.</p>
<p>For example, our current resampling scheme is 10-fold cross-validation. Since the training set has 2,000 samples, each fold uses 1,800 to fit the model and a separate 200 for assessment. Nested resampling would create 10 more independent resampling schemes within each of the 1,800-point analysis sets. If we once again used 10-fold cross-validation for the inner resamples, each would contain 10 analysis sets of size 1,620 with corresponding assessment sets of 180 data points.</p>
<p>The process starts with the inner resamples. The same model tuning procedure is used (basic grid search in our example), and each of the inner resamples estimates its own optimal candidate <span class="math inline">\(\hat{\theta}_k\)</span>. The outer resample takes this candidate value and estimates its performance using the assessment sets from the outer resampling loop. These outer estimates, whose data were never used to tune the model, are averaged to produce the nested resampling estimate of performance.</p>
<p>Consider <a href="#fig-nested" class="quarto-xref">Figure&nbsp;<span>11.7</span></a>. The colored lines in the left-hand panel show the results of the 10 inner resamples. Each line is made up of the averages of the inner 10 assessment sets of size 180. The filled circles along these lines indicate the optimal learning rate for that inner resample. Each outer resample takes its corresponding learning rate, trains that model using its analysis set of 1,800 points, and computes performance using its 200 assessment samples. These 10 statistics are averaged to get the final performance estimate, which should be free of any optimization bias.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-nested" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nested-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-nested-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nested-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11.7: Each line corresponds to a complete resampled grid search that uses the inner resamples. The points indicate the estimates of the optimal learning rate as determined by the inner results. The panel on the right contrasts the Brier score for the inner assessment set with the outer assessment sets.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see that the resample-specific optimal learning rates vary but are within a consistent region. There are a few resamples that found the same optimal value. There is some variation in the y-axis too; different assessment sets produce different values. The standard error of these inner statistics, 0.000537, is much smaller than the value of the conventional estimate (0.00536).</p>
<p>The panel on the left shows boxplots of the Brier scores for the inner resamples and the corresponding outer resample estimates. The standard error of the outer resamples is very similar to the the level of noise in the conventional estimate.</p>
<p>In the end, the nested resampling estimate of the Brier score was estimated as 0.0784; a value very close to the single 10-fold cross-validation result shown in <a href="#fig-1d-boost" class="quarto-xref">Figure&nbsp;<span>11.6</span></a>.</p>
<div class="important-box">
<p>It is important to emphasize that nested resampling is for <strong>verification, not optimization</strong>. It provides a better estimate of our model optimization process; it does not replace it.</p>
</div>
<p>We might best communicate the results of nested resampling like this:</p>
<blockquote class="blockquote">
<p>We tuned the learning rate of our boosted classification tree using grid search and found that a rate of 10<sup>-2.23</sup> to be best. We think that this model has a corresponding Brier score, measured without optimization bias, of 0.0784.</p>
</blockquote>
<p>We can look at the candidates produced by the inner resamples to understand the stability of the optimization process and potentially diagnose other issues. We <em>would not</em> choose “the best” inner resampling result and move forward with its candidate value<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<p>It is a good idea to use nested resampling when the training set is small, the predictor set is very large, or both. The lack of significant bias in the analysis above does not discount the problem of optimization bias. It exists but can sometimes be within the experimental noise.</p>
<p>It is a good idea to choose an inner resampling scheme that is as close as possible to the single resampling scheme that you used for optimization. The outer scheme can vary depending on your needs. Care should be used when the outer resampling method is the bootstrap. Since it replicates training set points in its analysis sets, the inner resamples need to use the <em>unique</em> rows of the original training set. Otherwise the same data point might end up in both the inner analysis and assessment sets.</p>
<p>The primary downside to nested resampling is the computational costs. Two layers of resampling have a quadratic cost, and only the inner resamples can be executed in parallel. Using 10 workers, the analysis in <a href="#fig-nested" class="quarto-xref">Figure&nbsp;<span>11.7</span></a> took 6.6-fold longer to compute than the basic grid search that produced <a href="#fig-1d-boost" class="quarto-xref">Figure&nbsp;<span>11.6</span></a>.</p>
</section>
<section id="setting-parameter-ranges" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="setting-parameter-ranges"><span class="header-section-number">11.5</span> Setting Parameter Ranges</h2>
<p>Specifying the range of parameters used to define the grid may involve some guesswork. For some parameter types, there is a well understood and defined range. For others, such as learning rate, there is a lower bound (zero) and a loosely defined upper bound mostly based on convention and prior experience. For grids, we want to avoid configurations with few unique values and a wide range. This might not sample the section of the parameter space that includes nonlinearity and the region of optimal results. <a href="overfitting.html#fig-learn-rate-seq" class="quarto-xref">Figure&nbsp;<span>9.6</span></a> shows an example of this for the learning rate. The initial grid included three points that missed the regions of interest. <a href="overfitting.html#fig-learn-rate-grid" class="quarto-xref">Figure&nbsp;<span>9.5</span></a> did a better job with more grid points. In high dimensional parameter space, the likelihood of a poor grid increases, especially for relatively “small” grid sizes.</p>
<p>We often envision the relationship between a predictor and model performance as being a sharp peak. If we cannot find the pinnacle, the model optimization would fail. Luckily, as seen in <a href="#fig-nested" class="quarto-xref">Figure&nbsp;<span>11.7</span></a>, there are often substantial regions of parameter space with good performance. Model optimization may not be superficially easy but it is often not impossible. We only need to sample the optimal region once to be successful.</p>
<p>If we worry that our tuning grid did not produce good results, another strategy is to <em>increase</em> the parameter ranges and use an iterative approach that can naturally explore the parameter space and let the current set of results guide the exploration about the space. These methods are discussed in the next chapter.</p>
</section>
<section id="chapter-references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="chapter-references">Chapter References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-audze1977new" class="csl-entry" role="listitem">
Audze, P, and V Eglais. 1977. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=New+approach+to+planning+out+of+experiments&amp;as_ylo=1977&amp;as_yhi=1977&amp;btnG=">New Approach to Planning Out of Experiments</a>.”</span> <em>Problems of Dynamics and Strengths</em> 35: 104–7.
</div>
<div id="ref-ba2015optimal" class="csl-entry" role="listitem">
Ba, S, R Myers, and W Brenneman. 2015. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Optimal+sliced+Latin+hypercube+designs&amp;as_ylo=2015&amp;as_yhi=2015&amp;btnG=">Optimal Sliced Latin Hypercube Designs</a>.”</span> <em>Technometrics</em> 57 (4): 479–87.
</div>
<div id="ref-bates2004formulation" class="csl-entry" role="listitem">
Bates, S, J Sienz, and V Toropov. 2004. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Formulation+of+the+optimal+Latin+hypercube+design+of+experiments+using+a+permutation+genetic+algorithm&amp;as_ylo=2004&amp;as_yhi=2004&amp;btnG=">Formulation of the Optimal Latin Hypercube Design of Experiments Using a Permutation Genetic Algorithm</a>.”</span> In <em>45th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics &amp; Materials Conference</em>, 2011.
</div>
<div id="ref-bergman2024don" class="csl-entry" role="listitem">
Bergman, E, L Purucker, and F Hutter. 2024. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Don+t+Waste+Your+Time+Early+Stopping+Cross+Validation&amp;as_ylo=2024&amp;as_yhi=2024&amp;btnG=">Don’t Waste Your Time: Early Stopping Cross-Validation</a>.”</span> <em>arXiv</em>.
</div>
<div id="ref-bernau2013correcting" class="csl-entry" role="listitem">
Bernau, C, T Augustin, and AJ Boulesteix. 2013. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Correcting+the+optimal+resampling+based+error+rate+by+estimating+the+error+rate+of+wrapper+algorithms&amp;as_ylo=2013&amp;as_yhi=2013&amp;btnG=">Correcting the Optimal Resampling-Based Error Rate by Estimating the Error Rate of Wrapper Algorithms</a>.”</span> <em>Biometrics</em> 69 (3): 693–702.
</div>
<div id="ref-bischl2012resampling" class="csl-entry" role="listitem">
Bischl, B, O Mersmann, H Trautmann, and C Weihs. 2012. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Resampling+methods+for+meta+model+validation+with+recommendations+for+evolutionary+computation&amp;as_ylo=2012&amp;as_yhi=2012&amp;btnG=">Resampling Methods for Meta-Model Validation with Recommendations for Evolutionary Computation</a>.”</span> <em>Evolutionary Computation</em> 20 (2): 249–75.
</div>
<div id="ref-boulesteix2009optimal" class="csl-entry" role="listitem">
Boulesteix, AL, and C Strobl. 2009. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Optimal+classifier+selection+and+negative+bias+in+error+rate+estimation+an+empirical+study+on+high+dimensional+prediction&amp;as_ylo=2009&amp;as_yhi=2009&amp;btnG=">Optimal Classifier Selection and Negative Bias in Error Rate Estimation: An Empirical Study on High-Dimensional Prediction</a>.”</span> <em>BMC Medical Research Methodology</em> 9: 1–14.
</div>
<div id="ref-BHH" class="csl-entry" role="listitem">
Box, GEP, W Hunter, and J. Hunter. 1978. <em>Statistics for Experimenters</em>. New York: Wiley.
</div>
<div id="ref-fang2000uniform" class="csl-entry" role="listitem">
Fang, KT, D Lin, P Winker, and Y Zhang. 2000. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Uniform+design+T+heory+and+application&amp;as_ylo=2000&amp;as_yhi=2000&amp;btnG=">Uniform Design: <span>T</span>heory and Application</a>.”</span> <em>Technometrics</em> 42 (3): 237–48.
</div>
<div id="ref-gramacy2020surrogates" class="csl-entry" role="listitem">
Gramacy, R. 2020. <em><a href="http://bobby.gramacy.com/surrogates/">Surrogates: <span>G</span>aussian Process Modeling, Design and Optimization for the Applied Sciences</a></em>. Chapman Hall/CRC.
</div>
<div id="ref-husslage2011space" class="csl-entry" role="listitem">
Husslage, B, G Rennen, E Van Dam, and D Den Hertog. 2011. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Space+filling+Latin+hypercube+designs+for+computer+experiments&amp;as_ylo=2011&amp;as_yhi=2011&amp;btnG=">Space-Filling <span>Latin</span> Hypercube Designs for Computer Experiments</a>.”</span> <em>Optimization and Engineering</em> 12: 611–30.
</div>
<div id="ref-joseph2016space" class="csl-entry" role="listitem">
Joseph, V. 2016. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Space+filling+designs+for+computer+experiments+A+review&amp;as_ylo=2016&amp;as_yhi=2016&amp;btnG=">Space-Filling Designs for Computer Experiments: <span>A</span> Review</a>.”</span> <em>Quality Engineering</em> 28 (1): 28–35.
</div>
<div id="ref-joseph2015maximum" class="csl-entry" role="listitem">
Joseph, V, E Gul, and S Ba. 2015. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Maximum+projection+designs+for+computer+experiments&amp;as_ylo=2015&amp;as_yhi=2015&amp;btnG=">Maximum Projection Designs for Computer Experiments</a>.”</span> <em>Biometrika</em> 102 (2): 371–80.
</div>
<div id="ref-krueger2015fast" class="csl-entry" role="listitem">
Krueger, T, D Panknin, and ML Braun. 2015. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Fast+cross+validation+via+sequential+testing&amp;as_ylo=2015&amp;as_yhi=2015&amp;btnG=">Fast Cross-Validation via Sequential Testing</a>.”</span> <em>Journal of Machine Learning Research</em> 16 (1): 1103–55.
</div>
<div id="ref-kuhn2014futility" class="csl-entry" role="listitem">
Kuhn, M. 2014. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Futility+analysis+in+the+cross+validation+of+machine+learning+models&amp;as_ylo=2014&amp;as_yhi=2014&amp;btnG=">Futility Analysis in the Cross-Validation of Machine Learning Models</a>.”</span> <em>arXiv</em>.
</div>
<div id="ref-tmwr" class="csl-entry" role="listitem">
Kuhn, M, and J Silge. 2022. <em><a href="https://www.tmwr.org">Tidy Modeling with <span>R</span></a></em>. O’Reilly Media, Inc.
</div>
<div id="ref-kutner2004applied" class="csl-entry" role="listitem">
Kutner, M, C Nachtsheim, and J Neter. 2004. <em>Applied Linear Regression Models</em>. McGraw-Hill/Irwin.
</div>
<div id="ref-maron1997racing" class="csl-entry" role="listitem">
Maron, O, and AW Moore. 1997. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=The+racing+algorithm+Model+selection+for+lazy+learners&amp;as_ylo=1997&amp;as_yhi=1997&amp;btnG=">The Racing Algorithm: Model Selection for Lazy Learners</a>.”</span> <em>Artificial Intelligence Review</em> 11: 193–225.
</div>
<div id="ref-Mckay2000" class="csl-entry" role="listitem">
Mckay, M, R Beckman, and W Conover. 2000. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+comparison+of+three+methods+for+selecting+values+of+input+variables+in+the+analysis+of+output+from+a+computer+code&amp;as_ylo=2000&amp;as_yhi=2000&amp;btnG=">A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code</a>.”</span> <em>Technometrics</em> 42 (1): 55–61.
</div>
<div id="ref-pronzato2017minimax" class="csl-entry" role="listitem">
Pronzato, L. 2017. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Minimax+and+maximin+space+filling+designs+some+properties+and+methods+for+construction&amp;as_ylo=2017&amp;as_yhi=2017&amp;btnG=">Minimax and Maximin Space-Filling Designs: Some Properties and Methods for Construction</a>.”</span> <em>Journal de La Société Française de Statistique</em> 158 (1): 7–36.
</div>
<div id="ref-qian2012sliced" class="csl-entry" role="listitem">
Qian, P. 2012. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Sliced+Latin+hypercube+designs&amp;as_ylo=2012&amp;as_yhi=2012&amp;btnG=">Sliced Latin Hypercube Designs</a>.”</span> <em>Journal of the American Statistical Association</em> 107 (497): 393–99.
</div>
<div id="ref-santner2018design" class="csl-entry" role="listitem">
Santner, T, B Williams, and W Notz. 2018. <em>The Design and Analysis of Computer Experiments</em>. Springer.
</div>
<div id="ref-shewry1987maximum" class="csl-entry" role="listitem">
Shewry, M, and H Wynn. 1987. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Maximum+entropy+sampling&amp;as_ylo=1987&amp;as_yhi=1987&amp;btnG=">Maximum Entropy Sampling</a>.”</span> <em>Journal of Applied Statistics</em> 14 (2): 165–70.
</div>
<div id="ref-tibshirani2018excess" class="csl-entry" role="listitem">
Tibshirani, RJ, and S Rosset. 2019. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Excess+optimism+H+ow+biased+is+the+apparent+error+of+an+estimator+tuned+by+SURE+&amp;as_ylo=2019&amp;as_yhi=2019&amp;btnG=">Excess Optimism: <span>H</span>ow Biased Is the Apparent Error of an Estimator Tuned by <span>SURE</span>?</a>”</span> <em>Journal of the American Statistical Association</em> 114 (526): 697–712.
</div>
<div id="ref-tibshirani2009bias" class="csl-entry" role="listitem">
Tibshirani, RJ, and R Tibshirani. 2009. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+bias+correction+for+the+minimum+error+rate+in+cross+validation&amp;as_ylo=2009&amp;as_yhi=2009&amp;btnG=">A Bias Correction for the Minimum Error Rate in Cross-Validation</a>.”</span> <em>The Annals of Applied Statistics</em> 3 (2): 822–29.
</div>
<div id="ref-varma2006bias" class="csl-entry" role="listitem">
Varma, S, and R Simon. 2006. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Bias+in+error+estimation+when+using+cross+validation+for+model+selection&amp;as_ylo=2006&amp;as_yhi=2006&amp;btnG=">Bias in Error Estimation When Using Cross-Validation for Model Selection</a>.”</span> <em>BMC Bioinformatics</em> 7: 1–8.
</div>
<div id="ref-Viana2016" class="csl-entry" role="listitem">
Viana, F. 2016. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+tutorial+on+Latin+hypercube+design+of+experiments&amp;as_ylo=2016&amp;as_yhi=2016&amp;btnG=">A Tutorial on <span>Latin</span> Hypercube Design of Experiments</a>.”</span> <em>Quality and Reliability Engineering International</em> 32 (5): 1975–85.
</div>
<div id="ref-wang2022design" class="csl-entry" role="listitem">
Wang, Y, F Sun, and H Xu. 2022. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=On+design+orthogonality+maximin+distance+and+projection+uniformity+for+computer+experiments&amp;as_ylo=2022&amp;as_yhi=2022&amp;btnG=">On Design Orthogonality, Maximin Distance, and Projection Uniformity for Computer Experiments</a>.”</span> <em>Journal of the American Statistical Association</em> 117 (537): 375–85.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>This process was illustrated in <a href="resampling.html#alg-resampling" class="quarto-xref">Algorithm&nbsp;<span>10.1</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Other applications may want the points to have properties such as orthogonality, symmetry, etc.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Using Euclidean distance.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Note that racing requires multiple assessment sets. A single validation set could not be used with racing.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Unfortunately, this is an example that is not prone to optimization bias. We’ll see examples later on this website where we can more effectively use these tools.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>To reiterate, the nested resampling process is used to characterize our optimization process. If it <em>becomes</em> our optimization process, we would need to nest it inside <em>another</em> nested resample.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/aml4td\.org");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/resampling.html" class="pagination-link" aria-label="Measuring Performance with Resampling">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Measuring Performance with Resampling</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>




</body></html>