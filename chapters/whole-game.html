<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.510">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Applied Machine Learning for Tabular Data - 2&nbsp; The Whole Game</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/initial-data-splitting.html" rel="next">
<link href="../chapters/introduction.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-whole-game" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Whole Game</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../"></a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/aml4td/website/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/news.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">News</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/contributing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/whole-game.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Whole Game</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Preparation</span></span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/initial-data-splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Initial Data Splitting</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Optmization</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Classification</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Regression</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Characterization</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Finalization</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-delivery-times" id="toc-sec-delivery-times" class="nav-link active" data-scroll-target="#sec-delivery-times"><span class="header-section-number">2.1</span> Predicting Delivery Time</a></li>
  <li><a href="#sec-data-spending-whole-game" id="toc-sec-data-spending-whole-game" class="nav-link" data-scroll-target="#sec-data-spending-whole-game"><span class="header-section-number">2.2</span> Data Spending</a></li>
  <li><a href="#sec-eda-whole-game" id="toc-sec-eda-whole-game" class="nav-link" data-scroll-target="#sec-eda-whole-game"><span class="header-section-number">2.3</span> Exploratory Data Analysis</a></li>
  <li><a href="#sec-model-development-whole-game" id="toc-sec-model-development-whole-game" class="nav-link" data-scroll-target="#sec-model-development-whole-game"><span class="header-section-number">2.4</span> Model Development</a>
  <ul class="collapse">
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear Regression</a></li>
  <li><a href="#rule-based-ensemble" id="toc-rule-based-ensemble" class="nav-link" data-scroll-target="#rule-based-ensemble">Rule-Based Ensemble</a></li>
  <li><a href="#neural-network" id="toc-neural-network" class="nav-link" data-scroll-target="#neural-network">Neural Network</a></li>
  </ul></li>
  <li><a href="#sec-model-selection-whole-game" id="toc-sec-model-selection-whole-game" class="nav-link" data-scroll-target="#sec-model-selection-whole-game"><span class="header-section-number">2.5</span> Choosing Between Model</a></li>
  <li><a href="#sec-calibration-whole-game" id="toc-sec-calibration-whole-game" class="nav-link" data-scroll-target="#sec-calibration-whole-game"><span class="header-section-number">2.6</span> Calibration</a></li>
  <li><a href="#sec-test-results-whole-game" id="toc-sec-test-results-whole-game" class="nav-link" data-scroll-target="#sec-test-results-whole-game"><span class="header-section-number">2.7</span> Test Set Results</a></li>
  <li><a href="#sec-themes-whole-game" id="toc-sec-themes-whole-game" class="nav-link" data-scroll-target="#sec-themes-whole-game"><span class="header-section-number">2.8</span> Themes</a></li>
  <li><a href="#sec-summary-whole-game" id="toc-sec-summary-whole-game" class="nav-link" data-scroll-target="#sec-summary-whole-game"><span class="header-section-number">2.9</span> Summary</a></li>
  <li><a href="#chapter-references" id="toc-chapter-references" class="nav-link" data-scroll-target="#chapter-references">Chapter References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-whole-game" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Whole Game</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter is a self-contained case study. Many resources for teaching machine learning gloss over some crucial details that might appear to be tangential to the model. As a result, they omit parts that are critical to the overall project.</p>
<p>The notion of “the whole game” is to illustrate machine learning in a way that reflects the complexity of the entire process. <span class="citation" data-cites="perkins2010">Perkins (<a href="#ref-perkins2010" role="doc-biblioref">2010</a>)</span> uses this phrase in the context of learning baseball. Instead of focusing players on one or two key aspects of the game, it is better to be exposed (at some level) to everything. In his words, a smaller focus “was kind of like batting practice without knowing the whole game.”</p>
<p>Our goal is to provide a somewhat abbreviated, high-level overview to help readers understand the overall strategy before we get into the specific set of tactics that we might use. This chapter previews what is to come and sets the stage to discuss some important themes that may not be obvious at first glance.</p>
<p>We’ll avoid many details in this chapter by copiously referencing upcoming chapters.</p>
<section id="sec-delivery-times" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-delivery-times"><span class="header-section-number">2.1</span> Predicting Delivery Time</h2>
<p>The illustrative example focuses on predicting the food delivery time (i.e., the time from the initial order to receiving the food). There is a collection of data containing 10,012 orders from a specific restaurant. The predictors, previously shown in <a href="introduction.html#tbl-deliveries" class="quarto-xref">Table&nbsp;<span>1.1</span></a>, include:</p>
<ul>
<li>The time, in decimal hours, of the order.</li>
<li>The day of the week for the order.</li>
<li>The approximate distance between the restaurant and the delivery location.</li>
<li>A set of 27 predictors that count the number of distinct menu items in the order.</li>
</ul>
<p>The outcome is the time<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> (in minutes).</p>
<p>The next section describes the process of <em>splitting</em> the overall data pool into different subsets and signifies the start of the modeling process. However, <em>how</em> we make that split depends on some aspects of the data. Specifically, it is a good idea to examine the distribution of our outcome data (i.e., delivery time) to determine how to randomly split the data<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p><a href="#fig-delivery-hist" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> (panel (a)) uses a histogram to examine the distribution of the outcome data. It is right-skewed and there is a subset of long delivery times that stand out from the mainstream of the data. The most likely delivery time is about 27 minutes, but there is also a hint of a second mode a few minutes earlier.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-hist" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-hist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-hist-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-hist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: Histrograms of the training set outcome data with and without a transformation.
</figcaption>
</figure>
</div>
</div>
</div>
<p>This skewness might affect how we split the data and is discussed in the next section. Another important question is: should we model a transformed version of the delivery times? If we have large outlying values, the model might be inappropriately pulled to these values, often at the expense of the overall quality of fit. One approach is to model the logarithm of the times (as shown in <a href="introduction.html#eq-log-linear" class="quarto-xref">Equation&nbsp;<span>1.1</span></a>). <a href="#fig-delivery-hist" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> (panel (b)) shows the distribution of the log (base 2) deliveries. It is more symmetric, and the potential second mode is more pronounced. This isn’t a bad idea, and the primary consequence is how we interpret some of the metrics that are used to quantify how well the model fits the data<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. In the end, we decided to model the data in the original units but did try the analysis both ways (and did not find huge differences in the results).</p>
</section>
<section id="sec-data-spending-whole-game" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-data-spending-whole-game"><span class="header-section-number">2.2</span> Data Spending</h2>
<p>An important aspect of machine learning is to use the right data at the right time. We don’t start modeling with the entire pool of data. As will be seen in <span class="quarto-unresolved-ref">?sec-resampling</span>, we need to reserve some data to evaluate the model and make sure that those data do not overlap with those used to fit the model.</p>
<p>Often, our data spending strategy is to split the data into at least two subsets:</p>
<ul>
<li>The <strong>training set</strong> is used to develop the model pipeline. It is used for investigating, fitting, and comparing them.</li>
<li>The <strong>test set</strong> is a smaller fraction of the data that is only used at the very end to independently validate how well we did.</li>
</ul>
<p>The training set is used for <em>a lot</em> of our activities. We do need to evaluate multiple model pipelines along the way. We reserve the test set for this function and should not use it for development. There are two main strategies for characterizing model efficacy during development.</p>
<p>The first is to <em>resample</em> the training set. This is an iterative computational tool to find good statistical estimates of model performance using the training set.</p>
<p>The other option is to initially split the data into three subsets: the training set, the testing set, and the <strong>validation set</strong>. The latter is another data partition, smaller than the training set, that is used for evaluating the model repeatedly during development.</p>
<p>Generally, we suggest using resampling unless the initial data pool is “sufficiently large.” For these data, 10,012 food orders is probably sufficient to choose a validation set over the resampling approach.</p>
<p>To split the data, we’ll allocate 60% for the training set and then use 20% for the validation set, and the remaining 20% for testing. The splitting will be conducted by stratification. To ensure that our delivery time distributions are approximately the same, it is temporarily “binned” into four quartiles. The three-way split is executed within each quartiles and the overall training/validation/testing sets are assembled by aggregating the corresponding data from the quartiles. As a result, the respective sample sizes are 6004/2004/2004 deliveries.</p>
<p>As previously stated, the majority of our time is spent with the training set samples. The first step in any model-building process is to understand the data, which can most easily be done through visualizations of the training set.</p>
</section>
<section id="sec-eda-whole-game" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-eda-whole-game"><span class="header-section-number">2.3</span> Exploratory Data Analysis</h2>
<p>Our goal now is to determine if there are aspects of predictors that would affect how we provide them to the model. We should look at individual variables as well as combinations multiple variables.</p>
<p>To start, for the dense numeric predictors, how would we characterize their relationship to the outcome? Is it linear, nonlinear, or random? Let’s start with the distance predictor. <a href="#fig-delivery-predictors" class="quarto-xref">Figure&nbsp;<span>2.2</span></a>(a) shows the values with the “scatter plot smoother” fit. The line is a flexible nonlinear approach that can adapt to any apparent pattern in the plot<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. First, the plot shows that the distance distribution is also right-skewed (although a separate histogram would better illustrate this). The smoother shows a slightly nonlinear trend, although the nonlinearity is mainly in the right tail of the distances and might be an artifact of the small sample size in that region. It is an informative variable that we can use in the model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-predictors" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-predictors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-predictors-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-predictors-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: Visualizations of relationship between the outcome and several predictors using the training set.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Panel (b) has a similar visualization for the order time. In this case, there is another nonlinear trend where the order increases with the hour, then peaks around 17:30, then begins to decrease. There is also an increase in delivery time variation as the order time approaches the peak.</p>
<p>The day of the week is visualized via box plots in panel (c). There is an increasing trend in both mean and variation as we move from Monday to Friday/Saturday, then a decrease on Sunday. Again, this appears to be an important predictor.</p>
<p>These three panels show relationships between individual predictors and delivery times. It is possible that multiple predictors can act <em>in concert</em>; their effect on the outcome occurs jointly. Panel (d) of <a href="#fig-delivery-predictors" class="quarto-xref">Figure&nbsp;<span>2.2</span></a> shows that there is an <strong>interaction effect</strong> between the day and hour of the order. Mondays and Tuesdays have shorter delivery times that don’t change much over hours. Conversely, on Fridays and Saturdays, the delivery times are generally longer, with much higher peaks. This might explain the increase in delivery time variation that was seen in Panel (b). Now that we know of the existence of this interaction, we might add additional model terms to help the model understand and exploit this pattern in the training set.</p>
<p>For the 27 itemized frequency counts, we might want to know if there was a change in delivery time when a specific item was in the order (relative to those where it is not purchased). To do this, mean delivery times were computed for orders with and without the item. The ratio of these times was computed and then converted to the percent increase in time. This is used to quantify the effect of item on delivery time. We’d also like to know what the variation is on this statistic and a technique called the bootstrap <span class="citation" data-cites="davison1997bootstrap">(<a href="#ref-davison1997bootstrap" role="doc-biblioref">Davison and Hinkley 1997</a>)</span> was used to create 90% confidence intervals for the ratio. <a href="#fig-delivery-increases" class="quarto-xref">Figure&nbsp;<span>2.3</span></a> shows the results.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-increases" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="50%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-increases-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-increases-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-increases-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: Ranking the items by the increase in delivery time when ordered at least once.
</figcaption>
</figure>
</div>
</div>
</div>
<p>There is a subset of items that increase the delivery time (relative to the experimental noise), many that seem irrelevant, and one that <em>decreases</em> the time.</p>
<p>More investigations into the data would be pursued to better understand the data and help us with feature engineering. For brevity, we’ll stop here and introduce three ML models.</p>
</section>
<section id="sec-model-development-whole-game" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="sec-model-development-whole-game"><span class="header-section-number">2.4</span> Model Development</h2>
<p>Which model to use? There is a multitude of tools that can be used to represent and predict these data. We’ll illustrate three in this section and the essential concepts to consider along the way.</p>
<p>Before proceeding, we need to pick a performance metric. This is used to quantify how well the model fits the data. For any model fit, the <em>residual</em> (usually denoted as <span class="math inline">\(\epsilon\)</span>, also called the error) is the difference between the model prediction and the observed outcome. We’d like our model to produce residuals near zero. One metric<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> is the mean absolute error (MAE). For a data set with <span class="math inline">\(n\)</span> data points, the equation is</p>
<p><span id="eq-mae"><span class="math display">\[
MAE = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i| = \frac{1}{n}\sum_{i=1}^n |\epsilon_i|
\tag{2.1}\]</span></span></p>
<p>where <span class="math inline">\(\hat{y}\)</span> is the predicted numeric outcome value and <span class="math inline">\(\epsilon\)</span> is the model error. The MAE units are the same as the outcome which, in this case, is minutes. We desire to minimize this statistic.</p>
<p>To get started, we’ll use a basic linear model for these data.</p>
<section id="linear-regression" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="linear-regression">Linear Regression</h3>
<p>Linear regression is probably the most well-known statistical model in history. It can predict a numeric outcome using one or more predictors using the equation:</p>
<p><span id="eq-basic-linear-reg"><span class="math display">\[
y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \ldots + \beta_px_{ip} + \epsilon_i
\tag{2.2}\]</span></span></p>
<p>where <span class="math inline">\(y_i\)</span> is the outcome for the <span class="math inline">\(i^{th}\)</span> data point (out of <span class="math inline">\(n_{tr}\)</span>), and <span class="math inline">\(x_{ij}\)</span> is value for the <span class="math inline">\(j^{th}\)</span> predictor (out of <span class="math inline">\(p\)</span>).</p>
<p>For <a href="#eq-basic-linear-reg" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>, there are many ways to estimate the model parameters (<span class="math inline">\(\beta\)</span>’s). <em>Ordinary least squares</em> is used most often. It finds the values of the <span class="math inline">\(\beta_j\)</span> that that minimize sum of squared errors (SSE). <span class="quarto-unresolved-ref">?sec-reg-linear</span> discusses several other ways to estimate the model parameters that use other criteria (variations of the SSE).</p>
<p>The main assumptions about the data for ordinary least squares are that they are independent and identically distributed. Given what we know about the problem, both assumptions are at least mildly incorrect. Orders are being processed simultaneously (affecting independence), and our visualizations have indicated that there is an increase in variation with the mean (i.e., not identically distributed). However, we are most interested in prediction here, so we can often overlook slight to moderate violations of these assumptions<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>What are our <span class="math inline">\(x_{ij}\)</span> values in <a href="#eq-basic-linear-reg" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>? We can’t give the model equations values of <code>"Monday"</code> or <code>"Friday"</code>; OLS requires numbers in its equations. A simple workaround is to create binary indicator variables for six of the seven days of the week. For example, the indicator for Friday would have a value of one for orders placed on a Friday and zero otherwise<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>Also, for <a href="#eq-basic-linear-reg" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>, what do we do about the numeric predictors that appear to have nonlinear trends? We can emulate the approach taken by the smoothing methods and <em>augment</em> the predictor columns. <a href="#eq-basic-linear-reg" class="quarto-xref">Equation&nbsp;<span>2.2</span></a> shows that linear regression is <strong>linear in the parameters</strong> (not the predictors). We can add terms such as <span class="math inline">\(x_{ij} = distance_i^2\)</span> to allow the fit to be nonlinear. An effective tool for enabling nonlinear trends is <em>spline functions</em><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. These are special polynomial terms. For example, we could represent that original predictor with 10 spline terms (i.e., columns in the data) for the order hour. As we add more terms, the model fit has increased capacity to be nonlinear. We’ll use 10 separate splines for both distance and the order hour (in lieu of the original data columns.)</p>
<p>How do we encode the interaction seen in <a href="#fig-delivery-predictors" class="quarto-xref">Figure&nbsp;<span>2.2</span></a>(d)? We have six indicator columns for the order day and ten spline columns for the order hour. We can facilitate having different nonlinear hour trends for each day by making 60 cross-product terms. For example, the interactions for Fridays would multiply each of the ten spline terms by the binary indicator associated with Fridays.</p>
<p>These feature engineering operations result in a model with <span class="math inline">\(p = 114\)</span> <span class="math inline">\(\beta\)</span> parameters. We fit this model to the training set to estimate the model parameters. To evaluate it, we use the trained model to predict the validation set, and these predictions are the substrate to compute the MAE. For this model, the validation set MAE is 1.609 (i.e., 1 minute and 36 seconds). If we think of MAE as an average error, this doesn’t seem too bad. However, what does this <em>look like</em>? Let’s plot the observed times against predicted values to get a better sense of how well this model did. <a href="#fig-delivery-lm-obs-pred" class="quarto-xref">Figure&nbsp;<span>2.4</span></a> has the results which also feature a scatter plot smoother.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-lm-obs-pred" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="40%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-lm-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-lm-obs-pred-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-lm-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: A scatter plot of the observed and predicted delivery times, via a linear regression model, for the validation set. The red line is a smooth trend estimate.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The best case would be that the points arrange themselves tightly around the diagonal line. The model slightly under-predicts for very rapid deliveries but substantially under-predicts for times greater than 40 minutes. However, overall, the model works well for the majority of the deliveries.</p>
<p>From here, our next step would be to investigate poorly predicted samples and determine if there is some commonality to them. For example, are they short distances that are ordered late on a Friday, etc? If there appears to be a pattern, we would add additional model terms to compensate for the flaw and see if the validation set MAE decreases. We would iterate between exploratory analysis of the residuals, adding or subtracting features, then refitting the model.</p>
<p>For illustration, we stop here and take a look at very different model.</p>
</section>
<section id="rule-based-ensemble" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="rule-based-ensemble">Rule-Based Ensemble</h3>
<p>Cubist is a rule-based ensemble method. It creates a rule set by first generating a regression tree that is composed of a hierarchical set of if/then statements<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. <a href="#fig-reg-tree" class="quarto-xref">Figure&nbsp;<span>2.5</span></a> shows a simple tree for our data. A set of splits on different predictors results in six terminal nodes (at the bottom of the tree). A rule is a distinct path through the tree to a terminal node. For example, Node 11 in the figure has the corresponding rule: <code>hour &gt;= 14.77 &amp; day in {Fri, Sat} &amp; distance &gt;= 4.045</code>. For each rule, Cubist fits a linear regression to the data that the rule covers (<span class="math inline">\(n = 261\)</span> for Node 11). It builds new rule sets sequentially and uses many rules/regression equations to predict new samples.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-reg-tree" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-reg-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../premade/delivery-tree.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-reg-tree-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: An example of a regression tree used to create a set of six rules.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The method isolates different parts of the predictor space and models the data using linear functions. The local nature of the rules enables the model to emulate nonlinear functions easily. When a rule consists of multiple predictors, this constitutes an interaction effect. Additionally, the data preprocessing requirements are minimal: it can internally account for any missing predictor values, and there is no need to convert categorical predictors into binary indicator columns, and so on.</p>
<p>When fit to the training set, the Cubist model created an ensemble with 105,327 rules. On average, the rules consisted of 2.7 variables and the the regression models contained 12.7 predictors. Two example rules, and their regression models, were:</p>
<div class="cell" data-layout-align="center">
<pre><code>if
   hour &lt;= 14.252
   day in {Fri, Sat}
then
   outcome = -23.039 + 2.85 hour + 1.25 distance + 0.4 item_24
             + 0.4 item_08 + 0.6 item_01 + 0.6 item_10 + 0.5 item_21
             + 0.3 item_09 + 0.4 item_23 + 0.2 item_03 + 0.2 item_06</code></pre>
</div>
<p>and</p>
<div class="cell" data-layout-align="center">
<pre><code>if
   hour &gt; 15.828
   hour &lt;= 18.395
   distance &lt;= 4.35
   item_10 &gt; 0
   day = Thu
then
   outcome = 11.29956 + 4.24 distance + 14.3 item_01 + 4.3 item_10
             + 2.1 item_02 + 0.03 hour</code></pre>
</div>
<p>These two examples are reasonable and understandable. However, blending so many rules means that this model is a complex, black-box model. For example, the first data point in the validation set is affected by 5,916 rules (about 6% of the total ensemble).</p>
<p>Does this complexity help? The validation set estimated MAE at 1 minute and 24 seconds, which is an improvement over the linear regression model. <a href="#fig-delivery-cubist-obs-pred" class="quarto-xref">Figure&nbsp;<span>2.6</span></a> visualizes the observed and predicted plot. The model under-predicts fewer points with long delivery times than the previous model but does contain a few very large residuals.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-cubist-obs-pred" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="40%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-cubist-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-cubist-obs-pred-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-cubist-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: A scatter plot of the observed and predicted delivery times from the Cubist model, for the validation set.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Would this model have benefited from using the feature set from the linear regression analysis? Not really. Refitting with those predictors had an MAE of 1 minute and 26 seconds. In this particular case, the original Cubist was able to estimate nonlinear trends and interactions without additional feature engineering.</p>
<p>There is more that we can do with the Cubist model but, in this initial model screening phase, we should focus our efforts on evaluating a disparate set of models and features to understand what works, what doesn’t work, and the difficulty level of the problem. Let’s try one additional model.</p>
</section>
<section id="neural-network" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="neural-network">Neural Network</h3>
<p>A neural network is a highly nonlinear modeling technique. They relate the predictors to the outcome through intermediate substructures, called layers, that contain hidden units. The hidden units allow the predictors to affect the outcomes differently<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> allowing the model to isolate essential patterns in the data. As the number of hidden units (or layers of hidden units) increases, so does the complexity of the model. We’ll only consider a single layer network with multiple hidden units for these data.</p>
<p>Neural networks, like linear regression, require numbers as inputs. We’ll convert the day of the week predictor to indicators. Additionally, the model requires that all of the predictors be in the same units. There are a few ways to accomplish this. First, we will compute the training set mean and standard deviation of each feature. To standardize them we subtract the mean and divide the result by the standard deviation. As a result, all features have a zero mean and a unit standard deviation.</p>
<p>One question about this model: how many hidden units should we use<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>? This decision will determine the complexity of the model. As models become model complex, they have more capacity to find complicated relationships between the predictors and response. However, added complexity adds to the risk of overfitting. This situation, discussed in <span class="quarto-unresolved-ref">?sec-model-complexity-and-overfitting</span>, occurs when a model fits exceptionally well to the training data but fails for new data by finding patterns in the training data that are artifacts and do not generalize for other data sets. How should we choose the number of hidden units?</p>
<p>Unfortunately, no equation can directly compute an estimate the number of units from the data. Values such as these are referred to as tuning parameters or hyperparameters. However, one solution is to extend the resampling process previously shown for the linear regression and Cubist models. We will consider a candidate set of tuning parameter values ranging from 3 to 100 hidden units. We’ll fit a model to the training set for each of these 98 values and use the validation set MAE values to select an appropriate value. The results of this process is shown in <a href="#fig-delivery-nnet-tune" class="quarto-xref">Figure&nbsp;<span>2.7</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-nnet-tune" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="60%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-nnet-tune-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-nnet-tune-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-nnet-tune-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.7: The relationship between the number of hidden units and the mean absolute deviation from the validation set data.
</figcaption>
</figure>
</div>
</div>
</div>
<p>A small number of hidden units performs poorly due to underfitting (i.e., insufficient complexity). Adding more improves the situation and, while the numerically best result corresponds to a value of 99, there is appreciable noise in the MAE values<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> . Eventually, adding too much complexity will either result in the MAE values becoming larger due to overfitting or will drastically increase the time to fit each model. The pattern shows a plateau of values with a similar MAE is the absolute optimal value. Given the noise in the system, we’ll select a value of 48 hidden units, by determining the least complex model that is within 1% of the numerically best MAE. The MAE associated with the selected candidate value<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> was 1 minute and 29 seconds (but is likely to be closer to 1 minute and 31 seconds, given the noise in <a href="#fig-delivery-nnet-tune" class="quarto-xref">Figure&nbsp;<span>2.7</span></a>).</p>
<p><a href="#fig-delivery-nnet-obs-pred" class="quarto-xref">Figure&nbsp;<span>2.8</span></a> shows the familiar plot of the observed and predicted delivery times. There are fewer large residuals than the Cubist model but the underfitting for longer delivery times appears more pronounced. There is also a hint of under-predicted times for fast deliveries.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-nnet-obs-pred" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="40%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-nnet-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-nnet-obs-pred-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-nnet-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.8: A scatter plot of the validation set observed and predicted delivery times from a neural network with 48 hidden units.
</figcaption>
</figure>
</div>
</div>
</div>
<p>These results suggest that the Cubist and neural network models have roughly equivocal performance<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>. Like Cubist, the finalized model is very complex; it is a highly nonlinear regression with 5,705,947 model parameters (i.e., slopes and intercepts).</p>
</section>
</section>
<section id="sec-model-selection-whole-game" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="sec-model-selection-whole-game"><span class="header-section-number">2.5</span> Choosing Between Model</h2>
<p>There are a variety of criteria used to rank and compare model fits. Obviously, performance is important. Also, it is good practice to choose a model that is as simplistic as possible (subject to having acceptable performance). There are other practical factors too. If a model is to be deployed, the size of the files(s) required to automate predictions can be a constraint. There may also be data constraints; which predictors are easy or inexpensive to obtain? Does the number of predictors affect how quickly predictions can be made?</p>
<p>While prediction is the focus for ML models, we often have to explain the model and/or predicted values to consumers. While we can develop <em>explainers</em> for any model, some types are easier to explain than others.</p>
<p>For this chapter, we have three models whose MAE values are within about <em>12 seconds</em> of one another. Each has the same deficiency: they all significantly underpredict long delivery times. In fact, a few poor predictions may be a limiting factor for any regression metric; it might be impossible for one model’s MAE to really stand out from the others.</p>
<p>We’ll select the linear regression model as our final model due to its relative simplicity and linear structure.</p>
</section>
<section id="sec-calibration-whole-game" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="sec-calibration-whole-game"><span class="header-section-number">2.6</span> Calibration</h2>
<p>There is one option for remedying the systematic underprediction of long delivery times. <span class="quarto-unresolved-ref">?sec-reg-calibration</span> describes <em>calibration</em> methods that might be able to correct such issues. To do so, we use the held out predictions to estimate the average unwanted trend and remove it from new predictions. For the linear regression results, the estimated average trend is almost identical to the smooth line shown in <a href="#fig-delivery-lm-obs-pred" class="quarto-xref">Figure&nbsp;<span>2.4</span></a>.</p>
<p>For our test set predictions, we’ll remove this trend and, hopefully, this will recenter the long predictions to be closer to the diagonal line.</p>
</section>
<section id="sec-test-results-whole-game" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="sec-test-results-whole-game"><span class="header-section-number">2.7</span> Test Set Results</h2>
<p>We can predict the test set using the linear regression fit from the training set. Recall that the validation set MAE was 1 minute and 36 seconds. Without the additional calibration, the test set value was <em>also</em> 1 minute and 36 seconds. The similarity of these results gives us confidence that the performance statistics we estimated during development are consistent with the test set. The test set plot of the predictions is shown in <a href="#fig-delivery-test-obs-pred" class="quarto-xref">Figure&nbsp;<span>2.9</span></a>(a).</p>
<p>The calibration results are shown in panel (b). There does appear to be an improvement in long delivery times; these are closer to the diagonal line. The MAE value is slightly improved: 1 minute and 32 seconds. The small difference in these results and the similar MAE values across models indicates that the few large residuals are probably the gating factor for these data.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-delivery-test-obs-pred" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="80%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delivery-test-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../figures/fig-delivery-test-obs-pred-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-delivery-test-obs-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.9: Observed versus predicted test set delivery times for the final model. Results are shown for pre-calibrated and post-calibration.
</figcaption>
</figure>
</div>
</div>
</div>
<p>At this point, we should spend a fair amount of time documenting the model and our development process. It might be helpful to employ inferential analyses to explain to interested parties which model components were most important (e.g., how much the interaction or nonlinear terms improve the model, etc.). It is very important to document where the model does not work well, its intended use, and the boundaries of the training set. Finally, if the model is deployed, we should also monitor its effectiveness over time and also understand if the sample population is changing over time too.</p>
<p>The next section accentuates important aspects of this case study.</p>
</section>
<section id="sec-themes-whole-game" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="sec-themes-whole-game"><span class="header-section-number">2.8</span> Themes</h2>
<p>At a high level, let’s review the process that we just used to create a model; <a href="#fig-model-building-process" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> highlights several themes<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>. The overall process involves initial data splitting, model development, then model selection, and validation. We’ll look at each of these in turn to discuss important points.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-model-building-process" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="60%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-building-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../premade/overall_process_validation.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-model-building-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.10: A general high level view of the process of creating a predictive model. The diagram reflects which steps use the test set, validation set, or the entire training set. <a href="#fig-within-model-process" class="quarto-xref">Figure&nbsp;<span>2.11</span></a> describes the operations labeled “model development”.
</figcaption>
</figure>
</div>
</div>
</div>
<section id="data-spending" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="data-spending">Data Spending</h4>
<p>Although discussed in <span class="quarto-unresolved-ref">?sec-initial-data-splitting</span>, how we allocate data to specific tasks (e.g., model building, evaluating performance, etc.) is an essential aspect of modeling. In our analysis, a minority of the data were explicitly allocated to measure how well the model worked. The test set is meant to be unbiased since it was never used to develop the model. This philosophy of empirical validation is a crucial feature for judging how models function.</p>
<p>The majority of the data ends up in the training set. The core activities of creating, optimizing, and selecting are accomplished with these data.</p>
<p><a href="#fig-model-building-process" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> highlights how we use the <strong>right data at the right time</strong>. A lack of a data usage methodology (or an inappropriate one) can lead to having a false sense of the quality of the model.</p>
<p>For example, when the linear regression model was calibrated, we chose to use the held-out samples as the substrate for estimating the unwanted trend. We could have used the re-predicted training set data but, as will be discussed in <span class="quarto-unresolved-ref">?sec-model-complexity-and-overfitting</span>, these values can be unrealistically optimistic. Also, we chose not to compute the MAE on the held-out predictions after they were used to estimate the calibration. This <em>dual use</em> of the same data would result in an MAE value that is smaller than it should be. There are other ways of estimating the utility of the calibration prior to the test set; these are discussed in @<span class="quarto-unresolved-ref">?sec-reg-calibration</span>.</p>
</section>
<section id="investigate-many-options" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="investigate-many-options">Investigate Many Options</h4>
<p>For the delivery data, three different models were evaluated. It is our experience that some modeling practitioners have a favorite model that is relied on indiscriminately (boosted trees immediately come to mind). The “No Free Lunch” Theorem <span class="citation" data-cites="Wolpert">(<a href="#ref-Wolpert" role="doc-biblioref">Wolpert 1996</a>)</span> argues that, without substantive information about the modeling problem and data, no single model will always do better than any other model. Because of this, a strong case can be made to try various techniques and then determine which to focus on. In our example, simple data visualizations elucidated the relationships between the outcome and the predictors. Given this knowledge, we might exclude some models from consideration, but there is still a wide variety of techniques to evaluate.</p>
<p>For individual models, <a href="#fig-within-model-process" class="quarto-xref">Figure&nbsp;<span>2.11</span></a> summarizes the cyclic process of speculation, configuration, and validation of model parameters and features. For these data, we discovered most of the important trends prior to our first model fit. As previously mentioned, we would cycle through a few rounds where we try to make improvments for each of the models.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-within-model-process" class="quarto-figure quarto-figure-center anchored" data-fig-align="center" width="90%">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-within-model-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../premade/diagram_within_model_cycle.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%">
</div>
<figcaption class="figure quarto-float-caption quarto-float-fig" id="fig-within-model-process-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.11: The cycle of developing a specific type of model. EDA standard for exploratory data analysis.
</figcaption>
</figure>
</div>
</div>
</div>
<p>For novel data sets, it is a challenge to know <em>a priori</em> what good choices are for tuning parameters, feature engineering methods, and predictors. The modeler must iterate using choices informed by their experience and knowledge of the problem.</p>
</section>
<section id="predictor-representations" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="predictor-representations">Predictor Representations</h4>
<p>This example revolves around a small set of predictors. In most situations, there will be numerous predictors of different types (e.g., quantitative, qualitative, etc.). It is unclear which predictors should be included in the model for new modeling projects and how they should be represented.</p>
<p>When considering how to approach a modeling project, the stereotype focuses on which new, fancy model to adopt. The reality is that many of the most effective decisions that users must confront are which predictors to use and in what format. Thoughtfully adding the right feature representations often obviates the need (and overhead and risks) for complex models. That is one of the lessons from this particular data set.</p>
<p>We’ll put the feature engineering process on equal footing with model training For this reason, <a href="#fig-within-model-process" class="quarto-xref">Figure&nbsp;<span>2.11</span></a> describes the cyclic nature of developing a single model and its corresponding features. These two processes go hand-in-hand.</p>
<p>While Cubist and the neural network were able to internally determine the more elaborate patterns in the data, our discovery of these same motifs has a higher value. We learned something about the nature of the data and can relate them to the model (via feature engineering) and the end-users. In fact, the day-to-day users of the data are the best resources for feature engineering.</p>
</section>
<section id="model-selection" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="model-selection">Model Selection</h4>
<p>At some point in the process, a specific model pipeline must be chosen. This chapter demonstrated two types of selection. First, we chose some models over others: the linear regression model did as well as more complex models and was the final selection. In this case, we decided <em>between model pipelines</em>. There was also a second type of model selection shown. The number of hidden units for the neural network was determined by trying different values and assessing the results. This was also model selection, where we decided on the configuration of a neural network (as defined by the number of hidden units). In this case, we selected <em>within different neural networks</em>.</p>
<p>In either case, we relied on data separate from the training set to produce quantitative efficacy assessments to help choose. This book aims to help the user gain intuition regarding the strengths and weaknesses of different models to make informed decisions.</p>
</section>
<section id="measuring-performance" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="measuring-performance">Measuring Performance</h4>
<p>Before using the test set, two techniques were used to determine the model’s effectiveness. First, quantitative assessments of statistics (i.e., MAE) from the validation set help the user understand how each technique would perform on new data. The other tool was to create simple visualizations of a model, such as plotting the observed and predicted values, to discover areas of the data where the model does particularly well or poorly. This qualitative information is lost when the model is gauged only using summary statistics and is critical for improving models. There are many more visualization methods for displaying the outcomes, their predictions, and other data. The figures shown here are pretty simplistic.</p>
<p>Note that almost all of our approaches for model evaluation are data-driven in a way where we determine if the predicted values are “close” to the actual values. This focus on empirical validation is critical in proving that a model pipeline is <em>fit for purpose</em>. Our general mantra is</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always have a separate piece of data that can <strong>contradict what you believe</strong>.</p>
</div>
</div>
<p>For models with parametric assumptions, it is a good idea to check these too, primarily if a model will also be used for inference. However, before considering questions regarding theoretical assumptions, empirical validation should be used to ensure that the model can explain the data well enough to be worth our inferences. For example, if our validation set MAE was around 15 minutes, the model predictions would not show much fidelity to the actual times. Any inferences generated from such a model might be suspect.</p>
</section>
</section>
<section id="sec-summary-whole-game" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="sec-summary-whole-game"><span class="header-section-number">2.9</span> Summary</h2>
<p>At face value, model building appears straightforward: pick a modeling technique, plug in the data, and generate a prediction. While this approach will yield a predictive model, it will likely not generate a reliable, trustworthy model. To achieve this we must first understand the data <em>and</em> the objective of the modeling. We finally proceed to building, evaluating, optimizing, and selecting models after these steps.</p>
</section>
<section id="chapter-references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="chapter-references">Chapter References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-davison1997bootstrap" class="csl-entry" role="listitem">
Davison, A, and D Hinkley. 1997. <em><span class="nocase">Bootstrap Methods and Their Application</span></em>. Cambridge University Press.
</div>
<div id="ref-perkins2010" class="csl-entry" role="listitem">
Perkins, D. 2010. <em><span>Making Learning Whole</span></em>. Wiley.
</div>
<div id="ref-Wolpert" class="csl-entry" role="listitem">
Wolpert, D. 1996. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=The+Lack+of+a+priori+Distinctions+Between+Learning+Algorithms&amp;as_ylo=1996&amp;as_yhi=1996&amp;btnG=">The Lack of <span><em>a Priori</em></span> Distinctions Between Learning Algorithms</a>.”</span> <em>Neural Computation</em> 8 (7): 1341–90.
</div>
</div>
</section>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>For event time data, it is possible to get incomplete data due to <em>censoring</em>. Suppose that, after 10 minutes you don’t have your order yet. You don’t know the exact delivery time but you do know that it is at least 10 minutes. There are specialized tools for analyzing and modeling censored data. Thankfully, all of our data are complete since we know the exact time of delivery.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Overall, we advise looking at the other columns in the data <em>after</em> the splitting.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>These are described more in <span class="quarto-unresolved-ref">?sec-outcome-transformation</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>The two strategies for creating flexible, smooth fits are splines and generalized additive models. These are described in detail in Sections <span class="quarto-unresolved-ref">?sec-splines</span> and <span class="quarto-unresolved-ref">?sec-cls-gam</span>, respectively. If you have used the <code>ggplot2</code> function <code>geom_smooth()</code> function, you’ve used a smoother. <a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Discussed in <span class="quarto-unresolved-ref">?sec-reg-metrics</span><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>If we want to make inferences on the parameters, such as p-values and confidence intervals, we we’ll need to make more specific assumptions (such as normality of the errors).<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Different ways to convert categorical predictors to numeric predictors are detailed in <span class="quarto-unresolved-ref">?sec-categorical-predictors</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="quarto-unresolved-ref">?sec-splines</span><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>The details for regression trees and Cubist are in <span class="quarto-unresolved-ref">?sec-reg-trees</span><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>See Sections <span class="quarto-unresolved-ref">?sec-cls-nnet</span> and <span class="quarto-unresolved-ref">?sec-reg-nnet</span> for discussions and details.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>This model description is deliberately vague (so as not to confuse readers who are new to this model). Other details: each model could be trained for up to 5,000 epochs. However, a small amount of the training set was randomly set aside to monitor the sums of squared errors at each epoch. Early stopping was triggered when this out-of-sample loss degraded for 10 consecutive epochs. A rectified linear unit activation function was used between the predictor and hidden layers. A cyclic learning rate scheduler was used with a maximum rate of 0.1 and a weight decay value of 0.01 was applied. In a more complete analysis, all of these values would also be tuned.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>The noisy profile suggests that our validation set might not be large enough to differentiate between subtle differences within or between models. If the problem required more precision in the performance statistics, a more thorough resampling method would be appropriate, such as cross-validation. These are described in Chapter <span class="quarto-unresolved-ref">?sec-resampling</span>.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>To some degree, this is an artificially optimistic estimate since we are using the same data to pick the best result and estimate the model’s overall performance. This is called optimization bias and it is discussed more in <span class="quarto-unresolved-ref">?sec-nested-resampling</span>. For the characteristics of these data, the optimism is likely to be small, especially compared to the noise in the MAE results.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>We will revisit this statement in <span class="quarto-unresolved-ref">?sec-comparing-boot</span>, where methods for estimating confidence intervals for validation and test results are presented.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>When resampling is used in place of a validation set, <span class="quarto-unresolved-ref">?sec-resampling</span> has a similar diagram that reflects the subtle differences in data usage.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/introduction.html" class="pagination-link  aria-label=" &lt;span="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/initial-data-splitting.html" class="pagination-link" aria-label="<span class='chapter-number'>3</span>&nbsp; <span class='chapter-title'>Initial Data Splitting</span>">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Initial Data Splitting</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>