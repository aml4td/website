<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; Comparing Models – Applied Machine Learning for Tabular Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/feature-selection.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-ac94f01b84e0cf733daf4ed4b084c36a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-7T996NL20Z"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-7T996NL20Z', { 'anonymize_ip': true});
</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-comparing-models" class="quarto-section-identifier"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Comparing Models</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../"></a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/aml4td/website/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/news.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">News</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/contributing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/whole-game.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Whole Game</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/initial-data-splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Initial Data Splitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/missing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Missing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/numeric-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transforming Numeric Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/categorical-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Working with Categorical Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/interactions-nonlinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Interactions and Nonlinear Features</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/overfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Overfitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/resampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Measuring Performance with Resampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/grid-search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Grid Search</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/iterative-search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Iterative Search</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/feature-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Feature Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/comparing-models.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Comparing Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Classification</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Regression</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Characterization</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Finalization</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-compare-resamples" id="toc-sec-compare-resamples" class="nav-link active" data-scroll-target="#sec-compare-resamples"><span class="header-section-number">14.1</span> Resampled Data Sets</a>
  <ul class="collapse">
  <li><a href="#sec-compare-stats" id="toc-sec-compare-stats" class="nav-link" data-scroll-target="#sec-compare-stats"><span class="header-section-number">14.1.1</span> Statistical Foundations</a></li>
  <li><a href="#sec-nhtm" id="toc-sec-nhtm" class="nav-link" data-scroll-target="#sec-nhtm"><span class="header-section-number">14.1.2</span> Frequentist Hypothesis Testing Methods</a></li>
  <li><a href="#sec-compare-resample-bayes" id="toc-sec-compare-resample-bayes" class="nav-link" data-scroll-target="#sec-compare-resample-bayes"><span class="header-section-number">14.1.3</span> Comparisons Using Bayesian Models</a></li>
  </ul></li>
  <li><a href="#sec-compare-holdout" id="toc-sec-compare-holdout" class="nav-link" data-scroll-target="#sec-compare-holdout"><span class="header-section-number">14.2</span> Single Holdout Data Sets</a></li>
  <li><a href="#sec-compare-conclusion" id="toc-sec-compare-conclusion" class="nav-link" data-scroll-target="#sec-compare-conclusion"><span class="header-section-number">14.3</span> Conclusion</a></li>
  <li><a href="#chapter-references" id="toc-chapter-references" class="nav-link" data-scroll-target="#chapter-references">Chapter References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-comparing-models" class="quarto-section-identifier"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Comparing Models</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>So far, we have established several key fundamentals of building predictive models. To create an effective model, we must employ strategies to reduce overfitting, use empirical validation techniques to accurately measure predictive performance, and systematically search a tuning parameter space to identify values that optimize model quality. By following these approaches, we can have confidence that our model generalizes well to new, unseen data and provides a realistic estimate of its efficacy.</p>
<p>With this foundation in place, the next step is to select the best model for a given data set. When presented with new data, we typically evaluate multiple machine learning models, each with different sets of tuning parameters. Our goal is to select the model and parameter combination that yields the best results. But how do we determine which is truly the best?</p>
<p>Making this decision requires considering several factors. As briefly discussed in <a href="whole-game.html" class="quarto-xref"><span>Chapter 2</span></a>, practical characteristics such as model complexity, interpretability, and deployability play an important role. Predictive ability, however, is an objective measure that can be evaluated quantitatively. Comparing metrics across models raises an important question: How can we be sure that one model’s quality is truly superior to another’s? Or, conversely, how can we conclude that multiple models have no significant difference in performance?</p>
<p>To address these questions, we will examine both graphical and statistical techniques for comparing the performance statistics of different models. During the model tuning and training process, these comparisons may involve assessing various configurations of tuning parameters within a single model or comparing fundamentally different modeling approaches.</p>
<p>Empirical validation (e.g., resampling) serves as the backbone of the tuning and training process. It systematically partitions the data into multiple subsets, enabling repeated estimation of performance metrics. The variability from the different assessment sets provides critical information for selecting optimal tuning parameters or identifying the best-performing model.</p>
<p>In the first part of this chapter, we will focus on methods for evaluating models when replicate estimates of performance metrics are available. This includes techniques grounded in Frequentist and Bayesian frameworks. After that, we will explore the case of a single data set. This is relevant when a single holdout set is used during model development (i.e., a validation set) and also when the test set is evaluated.</p>
<section id="sec-compare-resamples" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="sec-compare-resamples"><span class="header-section-number">14.1</span> Resampled Data Sets</h2>
<p>As a refresher, resampling produces multiple variations of the training set. These are used to metric estimates, such as accuracy or R<sup>2</sup>, that should mimic the results we would see on data sets similar to the training set.</p>
<p>The tools in this section are very similar to those described for model racing in <a href="grid-search.html#sec-racing" class="quarto-xref"><span>Section 11.3.3</span></a>, and we’ll use the same notation as that section. Similarly, we’ve discussed the two main philosophies of statistical analysis (Frequentist and Bayesian) in <a href="categorical-predictors.html#sec-effect-encodings" class="quarto-xref"><span>Section 6.4.3</span></a> and <a href="iterative-search.html#sec-freq-and-bayes" class="quarto-xref"><span>Section 12.5.2</span></a>. Many of those ideas play out again in this chapter.</p>
<section id="sec-compare-stats" class="level3" data-number="14.1.1">
<h3 data-number="14.1.1" class="anchored" data-anchor-id="sec-compare-stats"><span class="header-section-number">14.1.1</span> Statistical Foundations</h3>
<p>Regardless of whether we take a Frequentist or Bayesian philosophies to comparing model performance, both methods aim to identify key factors that influence the outcome, such as model-to-model effects. We seek to determine whether the effect of these factors is statistically significant—that is, unlikely to be due to random chance.</p>
<p>To illustrate these statistical techniques, we will use the same data that will be used in later chapters on classification: the Washington State forestation data introduced in <a href="initial-data-splitting.html" class="quarto-xref"><span>Chapter 3</span></a>. Our goal is to predict whether a location is classified as forested or non-forested. The data set includes predictors such as elevation, annual precipitation, longitude, latitude, and so on.</p>
<p>Without going into much detail, we’ll focus on comparing three modeling strategies that will be described in Part 4:</p>
<ul>
<li><p>A boosted tree ensemble using C5.0 trees as the base learner. This model was tuned over the number of trees in the ensemble and the amount of data required to make additional splits (a.k.a. <span class="math inline">\(n_{min}\)</span>). Grid search found that 60 trees in the ensemble were optimal, in conjunction with <span class="math inline">\(n_{min}\)</span> = 20 training set points.</p></li>
<li><p>A logistic regression model that was trained using penalization (<span class="quarto-unresolved-ref">?sec-logistic-penalized</span>). Feature engineering included an effect encoding parameterization of the county associated with locations, a small set of interaction terms (described in <span class="quarto-unresolved-ref">?sec-forestation-eda</span>), and ten spline terms for several of its numeric predictors. The optimal tuning parameter values were a penalization value of 10<sup>-4.67</sup> and 0% Lasso penalization.</p></li>
<li><p>A naive Bayes model (<span class="quarto-unresolved-ref">?sec-naive-bayes</span>]) was used where the conditional distributions were modeled using a nonparametric density estimate. No feature preprocessing was used.</p></li>
</ul>
<p>One difference between these analyses and those to come in Part 4 is that we’ve chosen to use classification accuracy as our metric<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Some of these results may differ from upcoming analyses. Previously, the spatially aware resampling scheme that was used generated 10 resamples of the training set. For this reason, there are 10 different accuracy “replicates” for each candidate value that was evaluated.</p>
<p>Similar to previous sections, we’ll produce models where the replicated performance statistics (denoted as <span class="math inline">\(\widehat{Q}_{ij}\)</span>) are the outcomes of the model (for resample <span class="math inline">\(i\)</span> and model <span class="math inline">\(j\)</span>). This is the same general approach shown in <a href="grid-search.html#eq-perf-mod-racing" class="quarto-xref">Equation&nbsp;<span>11.1</span></a> and <a href="iterative-search.html#eq-surrogate" class="quarto-xref">Equation&nbsp;<span>12.5</span></a>. We’ll assume that there are <span class="math inline">\(M\)</span> models to compare (three in our case).</p>
</section>
<section id="sec-nhtm" class="level3" data-number="14.1.2">
<h3 data-number="14.1.2" class="anchored" data-anchor-id="sec-nhtm"><span class="header-section-number">14.1.2</span> Frequentist Hypothesis Testing Methods</h3>
<p>Let’s begin by building towards an appropriate statistical model that will enable us to formally compare the efficacy of models. To begin this illustration, let’s suppose that each of these models was built separately using <strong>different</strong> 10-fold partitions of the training data. In this scenario, the metrics on the first holdout fold would be unique, or independent, for each model. If this were the case, then we could represent the desired performance metric with the following linear statistical model:</p>
<p><span id="eq-one-way-model"><span class="math display">\[
Q_{ij} = \beta_0 + \sum_{j=1}^{M-1}\beta_jx_{ij} + \epsilon_{ij}
\tag{14.1}\]</span></span></p>
<p>In this equation <span class="math inline">\(\beta_0\)</span> is the overall average performance statistic across all assessment sets and models<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. The term <span class="math inline">\(\beta_{j}\)</span> represents the incremental impact on the outcome due to the <span class="math inline">\(j^{th}\)</span> model (<span class="math inline">\(j\)</span> = 1, 2, …, <span class="math inline">\(M-1\)</span> = total number of models), and <span class="math inline">\(x_{ij}\)</span> is an indicator function for the <span class="math inline">\(j^{th}\)</span> model. In this example, the <span class="math inline">\(\beta_j\)</span> will be considered as a <em>fixed</em> effect. This indicates that these are the only models that we are considering. If we were to have taken a random sample of models, then the <span class="math inline">\(\beta_j\)</span> would be treated a <em>random</em> effect which would have a corresponding statistical distribution. The distinction between fixed and random effects will come into play shortly. Finally, <span class="math inline">\(\epsilon_{ij}\)</span>) represents the part of the performance that is not explainable by the <span class="math inline">\(i^{th}\)</span> assessment set and <span class="math inline">\(j^{th}\)</span> model. We’ll assume these residuals follow a Gaussian distribution with a mean of zero and an unknown variance<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. The model, along with the statistical assumption about the distribution of the residuals, provides the statistical foundation for formally comparing models.</p>
<p><a href="#fig-variance-partition-one-way" class="quarto-xref">Figure&nbsp;<span>14.1</span></a> illustrates these separate components for the assessment set with the largest accuracy value for the boosting ensemble, where the overall intercept is determined by the logistic regression. The horizontal dashed line represents the overall mean of the accuracy estimates, and the blue bar shows the mean of the boosting estimates alone. It is slightly higher than the average. For that model, the orange line shows the residual (<span class="math inline">\(\epsilon_{ij}\)</span> for the largest boosted tree accuracy replicate. The totality of such errors is used to measure the overall error in the model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-variance-partition-one-way" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-variance-partition-one-way-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-variance-partition-one-way-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-variance-partition-one-way-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.1: An illustration of how variation is partitioned based on the effect of the model (blue) and unexplained causes (orange) when distinct cross-validation partitions are used to train each model.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#eq-one-way-model" class="quarto-xref">Equation&nbsp;<span>14.1</span></a> enables us to distinctly partition the total variability in the outcome data into two components:</p>
<ol type="1">
<li>Explained variability: The portion attributable to differences among models, represented by the blue bar. This is the <strong>signal</strong> in the data set.</li>
<li>Unexplained variability: The portion due to random or unaccounted-for factors, represented by the orange bar, is commonly called the <strong>noise</strong>.</li>
</ol>
<p>Our key question is whether the observed differences in the mean performance for each model reflect genuine differences among models or if they could simply be due to random variation. The Frequentist approach addresses this question using hypothesis testing. In this framework:</p>
<ul>
<li><p>The null hypothesis (<span class="math inline">\(H_0\)</span>) represents the assumption that all models have the same average performance. Formally, this can be written as:<br>
<span class="math display">\[
H_0: \beta_k = \beta_m,
\]</span> for all <span class="math inline">\(k = m\)</span>.</p></li>
<li><p>The alternative hypothesis (<span class="math inline">\(H_A\)</span>) asserts that at least two models have significantly different average performance:<br>
<span class="math display">\[
H_A: \beta_{k} \neq \beta_{m},
\]</span><br>
for any <span class="math inline">\(k \neq m\)</span>.</p></li>
</ul>
<p>To determine whether we have sufficient evidence to reject the null hypothesis, we compare:</p>
<ul>
<li>Between-group variability (signal): Differences in mean performance across models.<br>
</li>
<li>Within-group variability (noise): Residual variation not explained by the models.</li>
</ul>
<p>This comparison is conducted using a test whose statistic follows an <em>F</em> distribution <span class="citation" data-cites="kutner2004applied">(<a href="#ref-kutner2004applied" role="doc-biblioref">Kutner, Nachtsheim, and Neter 2004</a>)</span>, which assesses whether the signal is large enough relative to the noise to conclude that differences among models are statistically significant.</p>
<p>In this case, the <em>F</em>-statistic is (3.06, 2, 27)<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, with a corresponding p-value of 0.0633. The p-value is small. However, it is not small enough to conclude that there is strong evidence to reject the null hypothesis. Therefore, we would <strong>not</strong> conclude that there are differences in accuracy among the three models. However, remember that we treated these data as if the resamples were completely different, which was not the case. As you’ll see shortly, this is a seriously flawed analysis of our data.</p>
<p>In practice, when tuning and training models, we use the same resampling sets to evaluate their performance. This is a more efficient approach since we only need to set up the resampling scheme once. Moreover, the structure generated by using the same assessment sets will enable us to detect differences in quality between models more effectively.</p>
<p>In this setting, each assessment set forms what is known as a block, which is a group of units that are similar to each other. This grouping is an important piece of information that will aid in assessing whether models have statistically different performance. The predictive performance when tuning multiple models using the same cross-validation assessment sets can now be represented as:</p>
<p><span id="eq-one-way-model-with-blocks"><span class="math display">\[
Q_{ij} = (\beta_0 + \beta_{0i}) + \sum_{j=1}^{M-1}\beta_jx_{ij} + \epsilon_{ij}
\tag{14.2}\]</span></span></p>
<p>Notice that <a href="#eq-one-way-model-with-blocks" class="quarto-xref">Equation&nbsp;<span>14.2</span></a> is nearly the same as <a href="#eq-one-way-model" class="quarto-xref">Equation&nbsp;<span>14.1</span></a>, with the additional term <span class="math inline">\(\beta_{0i}\)</span>. This term represents the incremental impact on performance due to the <span class="math inline">\(i^{th}\)</span> assessment set (<span class="math inline">\(i\)</span> = 1, 2,…, <span class="math inline">\(B\)</span> resamples). In this model, the impact of the <span class="math inline">\(B\)</span> resamples, represented by <span class="math inline">\(\beta_{0i}\)</span> are a random effect. The reason the resamples are considered as random effects is because the 10 folds were selected at random from an overall distribution of resamples. The impacts of each model are still considered as fixed effects. When a model contains both fixed and random effects, it is called a <em>mixed</em> effect model.</p>
<p><a href="#fig-variance-partition-one-way-with-blocks" class="quarto-xref">Figure&nbsp;<span>14.2</span></a> illustrates these separate components for the assessment set with the largest accuracy value for the boosted tree. In this figure, the points are connected based on the fold. The green line shows that the residual for the best boosting accuracy can be explained by the fact that it comes from this specific fold (i.e., resample). For whatever reason, this specific assessment set was easier to predict since all models had the highest accuracies. The resample that is associated with each accuracy is a systematic and explainable effect in these data. It’s also a “<em>nuisance</em> parameter” because we don’t care about this specific trend.</p>
<p>The mixed model can quantify the effect of this nuisance parameter; we can subtract its effect from the overall error, yielding a much smaller value of <span class="math inline">\(\epsilon_{ij}\)</span> as evidenced by the updated vertical orange bar. Notice that the total amount of variability explained by the model is identical to <a href="#fig-variance-partition-one-way" class="quarto-xref">Figure&nbsp;<span>14.1</span></a>. However, the previously unexplainable variability from <a href="#fig-variance-partition-one-way-with-blocks" class="quarto-xref">Figure&nbsp;<span>14.2</span></a> is now mostly explained by the variation due to the fold, thus reducing the <em>unexplainable</em> variability. We have made our analysis much more precise by accounting for the resample effect<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-variance-partition-one-way-with-blocks" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-variance-partition-one-way-with-blocks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-variance-partition-one-way-with-blocks-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-variance-partition-one-way-with-blocks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.2: An illustration of how variation is partitioned based on the effect of the model (blue), folds (green), and unexplainable causes (orange) when the same cross-validation partitions are used to train each model. The lines connecting the points indicate the results for the same cross-validation fold.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To understand if there are differences between models, we again compare the variability explained by the different models with the unexplainable variability. The signal relative to the noise is now much stronger, enabling us to more easily see differences in model performance. The <em>F</em>-statistic from this model is (20.42, 2, 18) and has a corresponding p-value of &lt; 10<sup>-4</sup>. By utilizing the same cross-validation scheme across models, there is now strong evidence of a difference in performance among the models.</p>
<p>This result does not tell us <em>which</em> models are different. To understand that, we need to perform additional tests to compare each pair of models. These tests are referred to as <em>post hoc</em> tests because they are performed after the initial hypothesis test among all means. To learn more details about <em>post hoc</em> tests and the field of multiple comparisons, see <span class="citation" data-cites="hsu1996multiple">Hsu (<a href="#ref-hsu1996multiple" role="doc-biblioref">1996</a>)</span> and/or <span class="citation" data-cites="dudoit2008multiple">Dudoit and Van Der Laan (<a href="#ref-dudoit2008multiple" role="doc-biblioref">2008</a>)</span> .</p>
<p><a href="https://tidymodels.aml4td.org/chapters/comparing-models.html#sec-nhtm"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
<section id="sec-post-hoc" class="level4" data-number="14.1.2.1">
<h4 data-number="14.1.2.1" class="anchored" data-anchor-id="sec-post-hoc"><span class="header-section-number">14.1.2.1</span> Post Hoc Pairwise Comparisons and Protecting Against False Positive Findings</h4>
<p>After detecting a significant effect in a one-way analysis of variance (ANOVA), the next step is to determine which specific groups differ from each other. This is achieved using <em>post hoc</em> pairwise comparisons, which assess all possible pairwise differences while controlling for false positive findings.</p>
<p>When conducting multiple comparisons, the risk of making at least one Type I error (false positive) increases. If we compare many pairs of groups separately, the probability of incorrectly rejecting at least one null hypothesis accumulates, leading to spurious findings. If this issue is not addressed, then we will eventually conclude that models are different when they actually are not. To mitigate this, statistical procedures adjust for multiple comparisons to ensure that the overall false positive rate remains controlled. Two methods for this purpose are Tukey’s Honestly Significant Difference (HSD) <span class="citation" data-cites="tukey1949comparing">(<a href="#ref-tukey1949comparing" role="doc-biblioref">Tukey 1949</a>)</span> and the False Discovery Rate (FDR) procedures <span class="citation" data-cites="EfronHastie2016a">(<a href="#ref-EfronHastie2016a" role="doc-biblioref">Efron and Hastie 2016, chap. 15</a>)</span>.</p>
<p>Tukey’s HSD test focuses on controlling the probability of making at least one false discovery; this is known as the familywise error rate (FWER). The HSD test is specifically designed for one-way ANOVA <em>post hoc</em> comparisons and ensures that the FWER remains at a pre-determined significance level (<span class="math inline">\(\alpha\)</span> = 0.05).</p>
<p>The test considers all possible pairwise differences while maintaining a constant error rate across comparisons. To contrast models <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, the test statistic is calculated as:</p>
<p><span class="math display">\[
T_{HSD} = \frac{\bar{Q}_i - \bar{Q}_j}{\sqrt{MS_{within} / n}}
\]</span></p>
<p>where, <span class="math inline">\(\bar{Q}_i\)</span> and <span class="math inline">\(\bar{Q}_j\)</span> are the sample means of each model’s outcome data, <span class="math inline">\(MS_{within}\)</span> is the mean square error from the ANOVA, and <span class="math inline">\(n\)</span> is the number of observations per group. The critical value for <span class="math inline">\(T_{HSD}\)</span> is obtained from the studentized range distribution, which depends on the number of groups and the degrees of freedom from the ANOVA error term.</p>
<p>When we desire to compare the performance of each pair of models, then Tukey’s HSD procedure will provide the appropriate adjustments to the p-values to protect against false positive findings as it becomes overly conservative.</p>
<p>In settings where <em>many hypotheses</em> are tested simultaneously, we may be more interested in the false discovery rate (FDR): the expected proportion of false positives among all rejected hypotheses. With many comparisons, this can be more appropriate than controlling the familywise error rate.</p>
<p>There are numerous FDR procedures in the literature. The method by <span class="citation" data-cites="benjamini1995controlling">Benjamini and Hochberg (<a href="#ref-benjamini1995controlling" role="doc-biblioref">1995</a>)</span> is the simplest. It ranks the p-values from all pairwise comparisons from smallest to largest (<span class="math inline">\(p_1\)</span>, <span class="math inline">\(p_2\)</span>, …, <span class="math inline">\(p_m\)</span>) and compares them to an adjusted threshold:</p>
<ol type="1">
<li><p>Rank the p-values in ascending order, assigning each a rank <span class="math inline">\(i\)</span>.</p></li>
<li><p>Compute the critical value for each comparison: <span class="math display">\[
p_{crit} = \frac{i}{m} \alpha
\]</span> where <span class="math inline">\(m\)</span> is the total number of comparisons and <span class="math inline">\(\alpha\)</span> is the desired FDR level.</p></li>
<li><p>Find the largest <span class="math inline">\(i\)</span> where <span class="math inline">\(p_i \leq p_{crit}\)</span>, and reject all hypotheses with p-values at or below this threshold.</p></li>
</ol>
<p>Unlike Tukey’s method, FDR control is more appropriate when performing many comparisons. This procedure offers a balance between sensitivity (detecting true differences) and specificity (limiting false positives).</p>
<p>Now, let’s compare how these methods perform when evaluating each pair of models in our example. <a href="#tbl-post-hoc-pvalues" class="quarto-xref">Table&nbsp;<span>14.1</span></a> presents the estimated differences in accuracy, standard error, degrees of freedom, raw, unadjusted p-values, and the p-values adjusted using the Tukey and FDR methods for each pairwise comparison. Notice that the Tukey adjustment results in less significant p-values than the FDR adjustment. Regardless of the adjustment method, the results indicate that each model’s performance differs statistically significantly from the others. Specifically, the boosting model has a higher accuracy than the other two models.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-post-hoc-pvalues" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-post-hoc-pvalues-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="vfmgxxvmhc" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#vfmgxxvmhc table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#vfmgxxvmhc thead, #vfmgxxvmhc tbody, #vfmgxxvmhc tfoot, #vfmgxxvmhc tr, #vfmgxxvmhc td, #vfmgxxvmhc th {
  border-style: none;
}

#vfmgxxvmhc p {
  margin: 0;
  padding: 0;
}

#vfmgxxvmhc .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: 100%;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vfmgxxvmhc .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#vfmgxxvmhc .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vfmgxxvmhc .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vfmgxxvmhc .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vfmgxxvmhc .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vfmgxxvmhc .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vfmgxxvmhc .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vfmgxxvmhc .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vfmgxxvmhc .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vfmgxxvmhc .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vfmgxxvmhc .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vfmgxxvmhc .gt_spanner_row {
  border-bottom-style: hidden;
}

#vfmgxxvmhc .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#vfmgxxvmhc .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vfmgxxvmhc .gt_from_md > :first-child {
  margin-top: 0;
}

#vfmgxxvmhc .gt_from_md > :last-child {
  margin-bottom: 0;
}

#vfmgxxvmhc .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vfmgxxvmhc .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#vfmgxxvmhc .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#vfmgxxvmhc .gt_row_group_first td {
  border-top-width: 2px;
}

#vfmgxxvmhc .gt_row_group_first th {
  border-top-width: 2px;
}

#vfmgxxvmhc .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vfmgxxvmhc .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#vfmgxxvmhc .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#vfmgxxvmhc .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vfmgxxvmhc .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vfmgxxvmhc .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vfmgxxvmhc .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#vfmgxxvmhc .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vfmgxxvmhc .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vfmgxxvmhc .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vfmgxxvmhc .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#vfmgxxvmhc .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vfmgxxvmhc .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#vfmgxxvmhc .gt_left {
  text-align: left;
}

#vfmgxxvmhc .gt_center {
  text-align: center;
}

#vfmgxxvmhc .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vfmgxxvmhc .gt_font_normal {
  font-weight: normal;
}

#vfmgxxvmhc .gt_font_bold {
  font-weight: bold;
}

#vfmgxxvmhc .gt_font_italic {
  font-style: italic;
}

#vfmgxxvmhc .gt_super {
  font-size: 65%;
}

#vfmgxxvmhc .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#vfmgxxvmhc .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#vfmgxxvmhc .gt_indent_1 {
  text-indent: 5px;
}

#vfmgxxvmhc .gt_indent_2 {
  text-indent: 10px;
}

#vfmgxxvmhc .gt_indent_3 {
  text-indent: 15px;
}

#vfmgxxvmhc .gt_indent_4 {
  text-indent: 20px;
}

#vfmgxxvmhc .gt_indent_5 {
  text-indent: 25px;
}

#vfmgxxvmhc .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#vfmgxxvmhc div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings gt_spanner_row header">
<th rowspan="2" id="Comparison" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">Comparison</th>
<th rowspan="2" id="Estimate" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">Estimate</th>
<th rowspan="2" id="SE" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">SE</th>
<th rowspan="2" id="DF" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">DF</th>
<th colspan="3" id="p-value Adjustment" class="gt_center gt_columns_top_border gt_column_spanner_outer" data-quarto-table-cell-role="th" scope="colgroup"><div class="gt_column_spanner">
p-value Adjustment
</div></th>
</tr>
<tr class="gt_col_headings even">
<th id="Unadjusted" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Unadjusted</th>
<th id="Tukey" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Tukey</th>
<th id="FDR" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">FDR</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_center" headers="Comparison">Boosting - Logistic</td>
<td class="gt_row gt_center" headers="Estimate">0.79%</td>
<td class="gt_row gt_center" headers="SE">0.67%</td>
<td class="gt_row gt_center" headers="DF">18</td>
<td class="gt_row gt_right" headers="Unadjusted">0.25544</td>
<td class="gt_row gt_right" headers="Tukey">0.48276</td>
<td class="gt_row gt_right" headers="FDR">0.25544</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Comparison">Boosting - Naive Bayes</td>
<td class="gt_row gt_center" headers="Estimate">4.04%</td>
<td class="gt_row gt_center" headers="SE">0.67%</td>
<td class="gt_row gt_center" headers="DF">18</td>
<td class="gt_row gt_right" headers="Unadjusted">0.00001</td>
<td class="gt_row gt_right" headers="Tukey">0.00003</td>
<td class="gt_row gt_right" headers="FDR">0.00003</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Comparison">Logistic - Naive Bayes</td>
<td class="gt_row gt_center" headers="Estimate">3.25%</td>
<td class="gt_row gt_center" headers="SE">0.67%</td>
<td class="gt_row gt_center" headers="DF">18</td>
<td class="gt_row gt_right" headers="Unadjusted">0.00013</td>
<td class="gt_row gt_right" headers="Tukey">0.00036</td>
<td class="gt_row gt_right" headers="FDR">0.00019</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-post-hoc-pvalues-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;14.1: Pairwise comparisons among the three models for predicting forestation classification. The table includes the estimated difference in accuracy, standard error, degrees of freedom, the unadjusted p-value, and the corresponding Tukey and FDR adjusted p-values.
</figcaption>
</figure>
</div>
</div>
<p>In this table, we can see that we have no evidence that boosting and logistic regression have different accuracies, but both of these models are statistically different from naive Bayes (no matter the adjustment type).</p>
<p><a href="https://tidymodels.aml4td.org/chapters/comparing-models.html#sec-post-hoc"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
</section>
<section id="sec-comparing-equivalence" class="level4" data-number="14.1.2.2">
<h4 data-number="14.1.2.2" class="anchored" data-anchor-id="sec-comparing-equivalence"><span class="header-section-number">14.1.2.2</span> Comparing Performance using Equivalence Tests</h4>
<p>In the previous section, we explored how to determine whether one model significantly outperforms another in a metric of choice. However, there are cases where we may instead want to assess whether the models perform similarly in a practically meaningful way. To do this, we use an equivalence test, which differs from the traditional hypothesis test, which aimed to detect differences between models.</p>
<p>Equivalence testing is based on the concept that two models can be considered practically equivalent if their difference falls within a <strong>predefined</strong> margin of indifference, often denoted as <span class="math inline">\(\theta\)</span>. This threshold represents the maximum difference that is considered practically insignificant. To illustrate equivalence testing, let’s begin by reviewing the hypothesis testing context for assessing differences between models. Let <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> represent the mean quality of two models. The null hypothesis for a standard two-sample test of difference is:</p>
<p><span class="math display">\[
H_O:  \beta_1 = \beta_2
\]</span></p>
<p>while the alternative hypothesis is:</p>
<p><span class="math display">\[
H_A:  \beta_1 \neq \beta_2
\]</span></p>
<p>However, an equivalence test reverses this logic. The null hypothesis is that the models are not equivalent, and the alternative hypothesis is that the models are practically insignificant:</p>
<p><span id="eq-equivalence-null"><span class="math display">\[
H_0:  |\beta_1 - \beta_2| \geq \theta
\tag{14.3}\]</span></span></p>
<p><span id="eq-equivalence-alternative"><span class="math display">\[
H_A:  |\beta_1 - \beta_2| \lt \theta
\tag{14.4}\]</span></span></p>
<p>Using this framework, we might reject the null hypothesis and conclude that the models are equivalent within the predefined margin of indifference.</p>
<p>A commonly used approach for equivalence testing is the Two One-Sided Test (TOST) procedure <span class="citation" data-cites="schuirmann1987comparison">(<a href="#ref-schuirmann1987comparison" role="doc-biblioref">Schuirmann 1987</a>)</span>. This method involves conducting two separate one-sided hypothesis tests as defined in <a href="#eq-equivalence-null" class="quarto-xref">Equation&nbsp;<span>14.3</span></a> and <a href="#eq-equivalence-alternative" class="quarto-xref">Equation&nbsp;<span>14.4</span></a>. Specifically, one test assesses the lower bound comparison while the other test assesses the upper bound comparison as follows:</p>
<p>Lower bound:</p>
<p><span class="math display">\[
H_0:  \beta_1 - \beta_2 \geq -\theta
\]</span></p>
<p><span class="math display">\[
H_A:  \beta_1 - \beta_2 &gt; -\theta
\]</span> Upper bound:</p>
<p><span class="math display">\[
H_0:  \beta_1 - \beta_2 \leq \theta
\]</span> <span class="math display">\[
H_A:  \beta_1 - \beta_2 &gt; \theta
\]</span></p>
<p>Each test is conducted at a desired significance level <span class="math inline">\(\alpha\)</span>, and if both null hypotheses are rejected, we conclude that the model performance is equivalent based on the predefined margin of indifference.</p>
<p>Schuirmann showed that the two one-sided hypotheses can be practically evaluated by constructing a <span class="math inline">\(100(1-2\alpha)\%\)</span> confidence interval for <span class="math inline">\(\beta_1 - \beta_2\)</span>. If this interval is contained within the boundaries of (<span class="math inline">\(-\theta\)</span>, <span class="math inline">\(\theta\)</span>), then we can reject the null hypothesis and conclude that the two models have equivalent performance.</p>
<p>Selecting an appropriate margin of indifference is crucial and should be determined prior to conducting the statistical test. What value should we choose? The answer to this question is problem-specific and depends on what we believe makes a sensible difference in performance.</p>
<p>From the previous section, we saw that the largest expected difference between any pair of models was 4%. For the sake of this illustration, let’s suppose that the margin of practical indifference between models is at least <span class="math inline">\(\pm\)</span> 3 percent in accuracy.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>To perform the equivalence tests, we use the same ANOVA model as when testing for differences in <a href="#eq-one-way-model-with-blocks" class="quarto-xref">Equation&nbsp;<span>14.2</span></a> and estimate the 90% confidence intervals about each pairwise difference. Because we are making multiple pairwise comparisons, the intervals need to be adjusted to minimize the chance of making a false positive finding. This adjustment can be done using either the Tukey or FDR procedures.</p>
<p><a href="#fig-equivalence-intervals" class="quarto-xref">Figure&nbsp;<span>14.3</span></a> presents the Tukey-adjusted 90% confidence intervals for each pairwise difference between models. For the forestation data, we would <strong>only</strong> conclude that the boosting ensemble and the logistic regression are equivalent.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-equivalence-intervals" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-equivalence-intervals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-equivalence-intervals-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-equivalence-intervals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.3: Pairwise comparisons of models using equivalence testing. The Tukey-adjusted 90% confidence interval of each pairwise difference is illustrated with vertical bands. For these comparisons, the margin of practical equivalence was set to +/- 3% accuracy.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://tidymodels.aml4td.org/chapters/comparing-models.html#sec-comparing-equivalence"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
</section>
</section>
<section id="sec-compare-resample-bayes" class="level3" data-number="14.1.3">
<h3 data-number="14.1.3" class="anchored" data-anchor-id="sec-compare-resample-bayes"><span class="header-section-number">14.1.3</span> Comparisons Using Bayesian Models</h3>
<p>How would we use a Bayesian approach to fit the model from <a href="#eq-one-way-model-with-blocks" class="quarto-xref">Equation&nbsp;<span>14.2</span></a>? To start, we can again assume a Gaussian distribution for the errors with standard deviation <span class="math inline">\(\sigma\)</span>. One commonly used prior for this parameter is the exponential distribution; it is highly right-skewed and has a single parameter. Our strategy here is to use very uninformative priors so that the data have more say in the final posterior estimates than the prior. If our model were useless, the standard deviation would be very large and would probably be bounded by the standard deviation of the outcome. For our data, that value for the accuracy is 4.1%. We’ll specify an exponential prior to use this as the mean of its distribution.</p>
<p>We’ll also need to specify priors for the three <span class="math inline">\(\beta\)</span> parameters. A fairly wide Gaussian would suffice. We’ll use <span class="math inline">\(\beta_j \sim N(0, 5)\)</span> for each.</p>
<p>For the random effects <span class="math inline">\(\beta_{0i}\)</span>, the sample size is fairly low (10 resamples per model). Let’s specify a bell-shaped distribution with a wide tail: a <span class="math inline">\(t\)</span>-distribution with a single degree of freedom. This would enable the Bayesian model to have some resample-to-resample effects that might be considered outliers if we assumed a Gaussian distribution.</p>
<p>We’ll discuss training Bayesian models in <span class="quarto-unresolved-ref">?sec-logistic-bayes</span>, so we’ll summarize here. Given our priors, there is no analytically defined distribution for the posterior. To train the model, we’ll use a Markov-chain Monte Carlo (MCMC) method to slowly iterate the posterior to an optimal location, not unlike the simulated annealing process previously described. To do this, we create <strong>chains</strong> of parameters. These are a controlled random walk from a starting point. Once that walk appears to converge, we continue generating random data points that are consistent with the optimized posterior. These random points will numerically approximate the posterior, and from these, we can make inferences. We’ll create 10 independent chains, and each will have a warm-up phase of 5,000 iterations and then another 5,000 samples to approximate the posterior. If all goes well, we will have a random sample of 50,000 posterior samples.</p>
<p>The resulting posterior distributions for the mean accuracy for each of the three models are shown in <a href="#fig-bayesian-model-posterior" class="quarto-xref">Figure&nbsp;<span>14.4</span></a> along with 90% credible intervals. The posteriors are relatively bell-shaped, and although there are discernible shifts between the models, there are overlaps in these distributions.</p>
<p>We can also use the posteriors to estimate how much of the error in the data was associated with the resample-to-resample effect (i.e., the previously described nuisance parameter). The percentage of total error attributable to the resample-to-resample effects is 82.5%. This illustrates how important it is to account for all of the systematic effects, wanted or unwanted, in the model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bayesian-model-posterior" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayesian-model-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-bayesian-model-posterior-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayesian-model-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.4: Posterior distributions of accuracy for each of the models. The horizontal bars represent the 90% credible intervals about the posterior accuracy values for each model.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Since we are interested in contrasting models, we can get a sample of the posterior and take the difference between the parameters that correspond to the model terms (i.e., <span class="math inline">\(\beta\)</span> parameters). We can create a large number of these samples to form posterior distributions of the pairwise contrasts and compute credible intervals. Bayesian modeling does not use the null hypothesis testing paradigm as Frequentist methods, so it is unclear whether <em>post hoc</em> adjustments are needed or how that would be computed. See <span class="citation" data-cites="gelman2012we">Gelman, Hill, and Yajima (<a href="#ref-gelman2012we" role="doc-biblioref">2012</a>)</span> and <span class="citation" data-cites="ogle2019should">Ogle et al. (<a href="#ref-ogle2019should" role="doc-biblioref">2019</a>)</span> for discussions. <a href="#fig-bayesian-contrast-posterior" class="quarto-xref">Figure&nbsp;<span>14.5</span></a> illustrates posteriors for the pairwise contrasts.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bayesian-contrast-posterior" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayesian-contrast-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-bayesian-contrast-posterior-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayesian-contrast-posterior-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.5: Posterior distributions of pairwise differences in accuracy for each pair of models. The vertical dashed lines represent the 90% credible intervals for each contrast.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Based on these results, we would reach the same conclusion as the Frequentist results; the boosting and logistic regression models are the only pair to appear to have comparable accuracies. We can compute probability statements such as “There is a 85.4% probability that the boosting ensemble exhibits a higher accuracy than logistic regression.”</p>
<p>In addition to utilizing the posterior distribution to compute probabilities of difference, we can also use this distribution to calculate probabilities of similarity or equivalence. The region of practical equivalence (ROPE) defines a range of metric values that we believe contains practically insignificant results <span class="citation" data-cites="kruschke2014doing">(<a href="#ref-kruschke2014doing" role="doc-biblioref">Kruschke 2014</a>)</span>. When using the equivalence testing from <span class="quarto-unresolved-ref">?sec-comparing-models-equivalence-tests</span>, we considered models equivalent if the accuracy was within 3%. Using this region, the posterior distribution of the parameter of interest is used to generate a probability that the parameter is within this region. If a large proportion of the posterior distribution falls within the ROPE, we can conclude that the difference is minimal.</p>
<p>The primary difference between the Frequentist and Bayesian equivalence testing lies in interpretation and flexibility. Frequentist equivalence testing is based on pre-specified significance levels and long-run error rates. Bayesian ROPE, on the other hand, provides a probability-based assessment of practical equivalence. This is particularly useful in predictive modeling, where slight differences in performance may not be operationally relevant.</p>
<p><a href="#fig-bayesian-ROPE" class="quarto-xref">Figure&nbsp;<span>14.6</span></a> illustrates the ROPE for the forestation data, defined as <span class="math inline">\(\pm\)</span> 3% accuracy. The probability mass within this region, shown in blue, represents the likelihood that the models have equivalent performance based on this criterion. <a href="#tbl-bayesian-ROPE" class="quarto-xref">Table&nbsp;<span>14.2</span></a> summarizes the probabilities for each model comparison.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bayesian-ROPE" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayesian-ROPE-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-bayesian-ROPE-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayesian-ROPE-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.6: Posterior distributions of pairwise differences in accuracy for each pair of models. The vertical dashed lines represent the region of practical equivalence. The probability mass within this region represents the probability that the models are practically equivalent within +/- 3% accuracy.
</figcaption>
</figure>
</div>
</div>
</div>
<p>For instance, there is an overwhelming probability that boosting and logistic regression are practically equivalent. The other two comparisons (with naive Bayes) show scant evidence of the same.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-bayesian-ROPE" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-bayesian-ROPE-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="xuoteiengo" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#xuoteiengo table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#xuoteiengo thead, #xuoteiengo tbody, #xuoteiengo tfoot, #xuoteiengo tr, #xuoteiengo td, #xuoteiengo th {
  border-style: none;
}

#xuoteiengo p {
  margin: 0;
  padding: 0;
}

#xuoteiengo .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#xuoteiengo .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#xuoteiengo .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#xuoteiengo .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#xuoteiengo .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#xuoteiengo .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#xuoteiengo .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#xuoteiengo .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#xuoteiengo .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#xuoteiengo .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#xuoteiengo .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#xuoteiengo .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#xuoteiengo .gt_spanner_row {
  border-bottom-style: hidden;
}

#xuoteiengo .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#xuoteiengo .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#xuoteiengo .gt_from_md > :first-child {
  margin-top: 0;
}

#xuoteiengo .gt_from_md > :last-child {
  margin-bottom: 0;
}

#xuoteiengo .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#xuoteiengo .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#xuoteiengo .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#xuoteiengo .gt_row_group_first td {
  border-top-width: 2px;
}

#xuoteiengo .gt_row_group_first th {
  border-top-width: 2px;
}

#xuoteiengo .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#xuoteiengo .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#xuoteiengo .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#xuoteiengo .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#xuoteiengo .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#xuoteiengo .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#xuoteiengo .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#xuoteiengo .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#xuoteiengo .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#xuoteiengo .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#xuoteiengo .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#xuoteiengo .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#xuoteiengo .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#xuoteiengo .gt_left {
  text-align: left;
}

#xuoteiengo .gt_center {
  text-align: center;
}

#xuoteiengo .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#xuoteiengo .gt_font_normal {
  font-weight: normal;
}

#xuoteiengo .gt_font_bold {
  font-weight: bold;
}

#xuoteiengo .gt_font_italic {
  font-style: italic;
}

#xuoteiengo .gt_super {
  font-size: 65%;
}

#xuoteiengo .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#xuoteiengo .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#xuoteiengo .gt_indent_1 {
  text-indent: 5px;
}

#xuoteiengo .gt_indent_2 {
  text-indent: 10px;
}

#xuoteiengo .gt_indent_3 {
  text-indent: 15px;
}

#xuoteiengo .gt_indent_4 {
  text-indent: 20px;
}

#xuoteiengo .gt_indent_5 {
  text-indent: 25px;
}

#xuoteiengo .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#xuoteiengo div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_col_headings header">
<th id="Comparison" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">Comparison</th>
<th id="Probability-of-Practical-Equivalence" class="gt_col_heading gt_columns_bottom_border gt_center" data-quarto-table-cell-role="th" scope="col">Probability of Practical Equivalence</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_center" headers="Comparison">Boosting vs Logistic</td>
<td class="gt_row gt_center" headers="Probability of Practical Equivalence">0.997</td>
</tr>
<tr class="even">
<td class="gt_row gt_center" headers="Comparison">Boosting vs Naive Bayes</td>
<td class="gt_row gt_center" headers="Probability of Practical Equivalence">0.081</td>
</tr>
<tr class="odd">
<td class="gt_row gt_center" headers="Comparison">Logistic vs Naive Bayes</td>
<td class="gt_row gt_center" headers="Probability of Practical Equivalence">0.362</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-bayesian-ROPE-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;14.2: Probability of practical equivalence between each pair of models’ performance.
</figcaption>
</figure>
</div>
</div>
<p><a href="https://tidymodels.aml4td.org/chapters/comparing-models.html#sec-comparing-equivalence"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
</section>
</section>
<section id="sec-compare-holdout" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="sec-compare-holdout"><span class="header-section-number">14.2</span> Single Holdout Data Sets</h2>
<p>Unlike resampled data sets, validation sets and test sets offer a single “look” at how well the model operates. In the case of the validation set, we would repeatedly use it to guide our model development process, much like how we would rely on resamples. For the test set, it should only be evaluated once, hopefully on a single model, but perhaps to make a final choice between a select few. It is not intended for repeat use. In the discussions below, we’ll use the term “holdout set” to describe the validation or test set, without loss of generality. In this scenario, the focus will be on Frequentist methods by way of bootstrap sampling <span class="citation" data-cites="Efron1979boot efron2003second">(<a href="#ref-Efron1979boot" role="doc-biblioref">Efron 1979</a>, <a href="#ref-efron2003second" role="doc-biblioref">2003</a>)</span>, which we have seen previously.</p>
<p>You were first introduced to the bootstrap in <a href="resampling.html#sec-bootstrap" class="quarto-xref"><span>Section 10.6</span></a>, where it was applied to estimate model performance during tuning. In essence, the bootstrap involves resampling with replacement from the available data to estimate the sampling variability of a statistic. This variability can then be used to construct confidence intervals of the performance metrics of interest, offering a range of plausible values for model performance on similar validation sets.</p>
<p><a href="resampling.html#fig-bootstrap-scheme" class="quarto-xref">Figure&nbsp;<span>10.7</span></a> illustrates the bootstrap process during the model-building tuning phase. Recall that resampling with replacement from the training data generates multiple bootstrap samples of the same size as the original. Because sampling is done with replacement, some observations may appear multiple times within a sample, while others may be omitted. The omitted samples are used as holdout sets to evaluate model performance.</p>
<p>To adapt this idea to make predictions on the single holdout set, then repeatedly draw bootstrap samples from it. Each bootstrap sample is the same size as the holdout set and is created via random sampling with replacement (as illustrated in <a href="#fig-bootstrap-single-holdout-graphic" class="quarto-xref">Figure&nbsp;<span>14.7</span></a>). We compute our metric(s) of interest on each analysis set, which are just the bootstrap samples. The corresponding assessment sets are not used in this process.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bootstrap-single-holdout-graphic" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bootstrap-single-holdout-graphic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../premade/boostrap_stat.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bootstrap-single-holdout-graphic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.7: A schematic of bootstraps resamples created from a validation set.
</figcaption>
</figure>
</div>
</div>
</div>
<p>This process yields a distribution of performance metrics, from which bootstrap confidence intervals can be derived. These intervals offer an estimate of the uncertainty around the holdout set’s performance and give us a sound way to express the expected range of performance across other holdout sets drawn from the same population.</p>
<p>There are several methods for computing bootstrap confidence intervals. See <span class="citation" data-cites="davison1997bootstrap">Davison and Hinkley (<a href="#ref-davison1997bootstrap" role="doc-biblioref">1997</a>)</span> and Chapter 11 of <span class="citation" data-cites="EfronHastie2016a">Efron and Hastie (<a href="#ref-EfronHastie2016a" role="doc-biblioref">2016</a>)</span>. We’ll describe one that is straightforward and often used: percentile intervals. The idea is simple: for an interval with <span class="math inline">\(100 (1 - \alpha)\)</span>% confidence, we compute the <span class="math inline">\(\alpha/2\)</span> quantiles on both ends of the bootstrap distribution. For our 90% intervals, we determine the 5% and 95% quantiles. Since the method relies on estimating very small areas in the distributional tails, it is important to create many bootstrap samples (i.e., thousands) to guarantee dependable results.</p>
<p>Let’s suppose that we considered a wide variety of models and feature sets, and still found our boosted tree and logistic regression to be the best. We’ve previously seen that, while the ensemble appears to perform best, the results are fairly similar, and the logistic model is simpler and perhaps more explainable. We might take both of these pipelines to the test set to make one final comparison before making a choice.</p>
<p>We fit the final models on the entire training set and then predict the test set of 1,371 locations. The accuracies for the boosting and logistic models were very close; they were 87.7% and 87.3%, respectively. Is this difference within the experimental noise or could there be a (statistical) difference?</p>
<p>We arrange the data so that there are separate columns for the boosted tree and logistic regression predictions (i.e., they are merged by the row number of the test set). Using this data, 5,000 bootstrap samples were created. From each of these, we can compute intervals for the accuracy of each and the difference in accuracy between them.</p>
<p><a href="#fig-bootstrap-test" class="quarto-xref">Figure&nbsp;<span>14.8</span></a> shows the bootstrap distributions of the individual model results. They are fairly similar, with a small shift between them. Above each histogram are two 90% confidence intervals. One is the bootstrap percentile interval, and the other is a theoretically based asymmetric interval that assumes that the correct/incorrect data for each model follows a Bernoulli distribution. For each model, these intervals are almost identical. We computed each to demonstrate that the bootstrap has very good statistical performance (compared to its theoretical counterpart).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bootstrap-test" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bootstrap-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-bootstrap-test-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bootstrap-test-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.8: For both models, the bootstrap distributions of the accuracy statistics are shown as histograms. The intervals at the top of each panel show the 90% confidence intervals computed using the bootstrap and via the traditional analytical method.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="dangerous-box">
<p>The confidence intervals between models substantially overlap. <em>Ordinarily</em>, we should take that as reliable information that there is no statistical difference between the two models. However, this is not true for this particular situation.</p>
</div>
<p>The issue is that the two sets of predictions are highly correlated. On the test set, they agree 93.1% of the time. Unlike our previous mixed model approach from <a href="#eq-one-way-model-with-blocks" class="quarto-xref">Equation&nbsp;<span>14.2</span></a>, the individual confidence intervals have no way to correct for this issue (since they evaluate one model at a time).</p>
<p>When computing the difference between two things (A and B), the variance of their difference is:</p>
<p><span id="eq-diff-var"><span class="math display">\[
Var[A-B] = Var[A] + Var[B] - 2Cov[A, B]
\tag{14.5}\]</span></span></p>
<p>When A and B are related, their covariance will be very high and, if we ignore it, the power of any statistical test on that difference can be severely underpowered. This is the same issue as shown in <a href="#sec-nhtm" class="quarto-xref"><span>Section 14.1.2</span></a>. When we didn’t account for the resampling effect, we accidentally sabotaged the test’s ability to find a difference (if there was one).</p>
<p>For the test set, we compute the difference in accuracy by resampling the matched pairs of predictions. From this, the bootstrap estimate of the difference was 0.4% with 90% bootstrap interval (-0.8%, 1.5%). This does indicate that the models have statistically indistinguishable accuracies, but the lower bound is <em>very</em> close to zero. With slightly different models or a different random split of the data, they might very well be considered different<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. There is an overwhelmingly strong case to make that they are practically equivalent, though.</p>
<p>Also, as the data set size increases, the variation we expect to see in the summary statistic will decrease. This concept is illustrated in <a href="#fig-interval-width" class="quarto-xref">Figure&nbsp;<span>14.9</span></a>. In this figure, we have randomly selected subsets of varying size from the data set and then computed a 90% confidence interval using these smaller sets. Notice that as the sample size decreases, the width of the confidence interval increases. Therefore, the smaller the data set, the higher the variability will be in the estimate of model quality, and the more important it is to understand the range of potential uncertainty. This pattern is true of any interval procedure.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-interval-width" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interval-width-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="comparing-models_files/figure-html/fig-interval-width-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interval-width-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14.9: 90% confidence interval widths of accuracy for data sets of varying size, assuming the same performance as the boosted ensemble.
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="https://tidymodels.aml4td.org/chapters/comparing-models.html#sec-compare-holdout"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
</section>
<section id="sec-compare-conclusion" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="sec-compare-conclusion"><span class="header-section-number">14.3</span> Conclusion</h2>
<p>Selecting the best predictive model involves assessing performance metrics and accounting for practical considerations. Thus far, this chapter has outlined both Frequentist and Bayesian approaches to comparing model performance, emphasizing the importance of appropriate statistical techniques when evaluating differences. The Frequentist approach provides a formal hypothesis testing framework, while the Bayesian approach offers a more direct probability-based interpretation of model differences. When there is just one data set for evaluation, like a validation set or test set, then the bootstrap technique can be used to create an interval about the performance metric (or differences between models).</p>
<p>Ultimately, while statistical significance can indicate meaningful differences between models, practical significance should also guide decision-making. Equivalence testing and Bayesian ROPE analysis help determine whether models perform similarly within a defined threshold of practical relevance. In our forestation classification example, these methods suggested that while the boosting model demonstrated superior predictive performance overall, differences between some models may not always be large enough to drive a clear choice.</p>
<p>In practice, model selection is rarely based on performance alone. Factors such as interpretability, computational cost, and deployment feasibility must also be considered. By combining quantitative performance assessment with practical domain knowledge, we can make informed decisions that balance accuracy with real-world constraints.</p>
</section>
<section id="chapter-references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="chapter-references">Chapter References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-benjamini1995controlling" class="csl-entry" role="listitem">
Benjamini, Yoav, and Yosef Hochberg. 1995. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Controlling+the+false+discovery+rate+a+practical+and+powerful+approach+to+multiple+testing&amp;as_ylo=1995&amp;as_yhi=1995&amp;btnG=">Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing</a>.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 57 (1): 289–300.
</div>
<div id="ref-davison1997bootstrap" class="csl-entry" role="listitem">
Davison, A, and D Hinkley. 1997. <em><span class="nocase">Bootstrap Methods and Their Application</span></em>. Cambridge University Press.
</div>
<div id="ref-dudoit2008multiple" class="csl-entry" role="listitem">
Dudoit, S, and M Van Der Laan. 2008. <em>Multiple Testing Procedures with Applications to Genomics</em>. Springer.
</div>
<div id="ref-Efron1979boot" class="csl-entry" role="listitem">
Efron, B. 1979. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Bootstrap+Methods+Another+Look+at+the+Jackknife&amp;as_ylo=1979&amp;as_yhi=1979&amp;btnG=">Bootstrap Methods: Another Look at the Jackknife</a>.”</span> <em>The Annals of Statistics</em> 7 (1): 1–26.
</div>
<div id="ref-efron2003second" class="csl-entry" role="listitem">
Efron, B. 2003. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Second+thoughts+on+the+bootstrap&amp;as_ylo=2003&amp;as_yhi=2003&amp;btnG=">Second Thoughts on the Bootstrap</a>.”</span> <em>Statistical Science</em>, 135–40.
</div>
<div id="ref-EfronHastie2016a" class="csl-entry" role="listitem">
Efron, B, and T Hastie. 2016. <em><a href="https://hastie.su.domains/CASI/">Computer Age Statistical Inference</a></em>. Cambridge University Press.
</div>
<div id="ref-gelman2012we" class="csl-entry" role="listitem">
Gelman, A, J Hill, and M Yajima. 2012. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Why+we+usually+don+t+have+to+worry+about+multiple+comparisons&amp;as_ylo=2012&amp;as_yhi=2012&amp;btnG=">Why We (Usually) Don’t Have to Worry about Multiple Comparisons</a>.”</span> <em>Journal of Research on Educational Effectiveness</em> 5 (2): 189–211.
</div>
<div id="ref-hsu1996multiple" class="csl-entry" role="listitem">
Hsu, J. 1996. <em>Multiple Comparisons: Theory and Methods</em>. Chapman; Hall/CRC.
</div>
<div id="ref-kruschke2014doing" class="csl-entry" role="listitem">
Kruschke, J. 2014. <em>Doing <span>Bayesian</span> Data Analysis: A Tutorial with <span>R</span>, <span>JAGS</span>, and <span>Stan</span></em>. Academic Press.
</div>
<div id="ref-kutner2004applied" class="csl-entry" role="listitem">
Kutner, M, C Nachtsheim, and J Neter. 2004. <em>Applied Linear Regression Models</em>. McGraw-Hill/Irwin.
</div>
<div id="ref-ogle2019should" class="csl-entry" role="listitem">
Ogle, K, D Peltier, M Fell, J Guo, H Kropp, and J Barber. 2019. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Should+we+be+concerned+about+multiple+comparisons+in+hierarchical+Bayesian+models+&amp;as_ylo=2019&amp;as_yhi=2019&amp;btnG=">Should We Be Concerned about Multiple Comparisons in Hierarchical Bayesian Models?</a>”</span> <em>Methods in Ecology and Evolution</em> 10 (4): 553–64.
</div>
<div id="ref-schuirmann1987comparison" class="csl-entry" role="listitem">
Schuirmann, Donald J. 1987. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+comparison+of+the+two+one+sided+tests+procedure+and+the+power+approach+for+assessing+the+equivalence+of+average+bioavailability&amp;as_ylo=1987&amp;as_yhi=1987&amp;btnG=">A Comparison of the Two One-Sided Tests Procedure and the Power Approach for Assessing the Equivalence of Average Bioavailability</a>.”</span> <em>Journal of Pharmacokinetics and Biopharmaceutics</em> 15: 657–80.
</div>
<div id="ref-tukey1949comparing" class="csl-entry" role="listitem">
Tukey, John W. 1949. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Comparing+individual+means+in+the+analysis+of+variance&amp;as_ylo=1949&amp;as_yhi=1949&amp;btnG=">Comparing Individual Means in the Analysis of Variance</a>.”</span> <em>Biometrics</em>, 99–114.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>This isn’t normally our first choice. However, the outcome classes are fairly balanced. Also, accuracy is intuitively understandable, and the broader set of classification metrics has yet to be described in detail.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This is another example of an analysis of variance (ANOVA) model.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>It may seem odd that we would assume a Gaussian distribution for a variable with values between zero and one. Almost all performance statistics are means; accuracy is the average of 0/1 data. The Central Limit Theorem tells us that, despite the original data distribution, the mean tends to normality as the sample size increases. Assessment and test sets often have enough data points to trust this assumption.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This is common notation for reporting the <em>F</em>-statistic, where the first number represents the ratio of the mean square of the model to the mean square of the error. The second and third numbers represent the degrees of freedom of the numerator and denominator, respectively.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>This again echoes the discussion of racing from <a href="grid-search.html#sec-racing" class="quarto-xref"><span>Section 11.3.3</span></a>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>When performing an equivalence test, the margin of practical indifference should be specified <em>before</em> the test is performed.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>One reason to avoid using metrics based on qualitative predictions (e.g., “yes” or “no”) is that they have a diminished capability to detect differences. They tend to contain far less information than their corresponding class probabilities. A metric such as the Brier score would have additional precision and might be able to tell the two models apart.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/aml4td\.org");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/feature-selection.html" class="pagination-link" aria-label="Feature Selection">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Feature Selection</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>




</body></html>