---
knitr:
  opts_chunk:
    cache.path: "../_cache/cls-linear/"
---

# Generalized Linear and Additive Classifiers {#sec-cls-linear}

```{r}
#| label: cls-linear-setup
#| include: false

source("../R/_common.R")
source("../R/_themes.R")
source("../R/_themes_ggplot.R")

# ------------------------------------------------------------------------------

library(tidymodels)
library(embed)
library(bestNormalize)
library(probably)
library(patchwork)
library(future.mirai)

# ------------------------------------------------------------------------------
# set options

tidymodels_prefer()
theme_set(theme_bw())
set_options()
plan(mirai_multisession)

# ------------------------------------------------------------------------------
# load data 

load("../RData/forested_data.RData")
```

## Exploring Forestation Data  {#sec-forestation-eda}


```{r}
#| label: county
#| include: false

obs_rates <- 
  forested_train |> 
  summarize(
    rate = mean(class == "Yes"),
    events = sum(class == "Yes"),
    total = length(class),
    .by = c(county)
  ) |> 
  mutate(
    hstat = map2(events, total, binom.test, conf.level = 0.9),
    pct = rate * 100,
    .lower = map_dbl(hstat, ~ .x$conf.int[1]),
    .upper = map_dbl(hstat, ~ .x$conf.int[2]),
    county = tools::toTitleCase(gsub("_", " ", county)),
    county = factor(county),
    county = reorder(county, rate),
    `# Locations` = total
  )

# obs_rates |> 
#   ggplot(aes(y = county, col = `# Locations`)) + 
#   geom_point(aes(x = rate)) + 
#   geom_errorbar(aes(xmin = .lower, xmax = .upper)) + 
#   labs(x = "Percent Forested", y = NULL)
```

## Logistic Regression {#sec-logistic-reg}

Logistic regression is a classification model that can be used when there are $C = 2$ classes. As with all binary classification models, we want to accurately estimate the probability of an event^[We'll assume that class $j = 1$ is the class that is considered the event, for $j = 1, \ldots, C$ classes.]. As discussed in the previous chapter, the probability parameter $\pi$ should be between zero and one, and we often frame the problem in terms of the probability model based on the Bernoulli likelihood function: 

$$
\ell(\pi_i; y_{ij}) = \prod_{i=1}^{n_{tr}} \pi_i^{y_{i1}} (1-\pi_i)^{y_{i2}}
$$ {#eq-bernoulli}

where $\pi_i$ is the theoretical probability of an event for sample $i$ ($i = 1, \ldots, n_{tr}$). 

Generally, we have a tabular data set of predictors that we want to affect $\pi_i$ in some effective and understandable way. One pattern that we've seen in previous chapters is a linear combination of predictors and parameters: 

$$
\boldsymbol{x}_i'\boldsymbol{\beta} = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ip}
$$ {#eq-linear-predictor}

This is often referred to as the "linear predictor" and is commonly denoted as $\eta_i$ The range of this value is [-$\infty$, $\infty$], so we can't directly model the probability of the event using this equation as it would easily exceed the natural boundaries for $\pi_i$. One approach is to embed the linear predictor inside a nonlinear function. The logistic model takes the form:

$$
\pi_i = \frac{1}{1 + \exp(-\boldsymbol{x}_i'\boldsymbol{\beta})}
$$ {#eq-logistic}

This keeps the probability values within [0, 1] no matter how large or small the linear predictor becomes^[Technically, logistic regression uses this nonlinear function, but there are many other functions to choose from. The probit and complementary log-log transformations can be used [@glm] as well as many others. See @morgan2018analysis for more specialized "link functions." From a broader view, we might refer to our model as "binary regression" or "binomial regression."]. This nonlinear function can be derived using differential equations for growth curves. Although the model has been rediscovered several times, it was first derived in the 1800s and was not commonly known as the "logistic" model until 1925. See @cramer2004early for a history. 

```{r}
#| label: precipitation-fit
#| include: false

linear_percip_fit <- 
  logistic_reg() %>% 
  fit(class ~ log10(precip_annual), data = forested_train)

linear_percip_coef <- 
  linear_percip_fit %>% 
  extract_fit_engine() %>% 
  coef() 
# glm models the probability of the second factor level
linear_percip_coef <- -linear_percip_coef
linear_percip_coef <- format(linear_percip_coef, digits = 3)

```

For a single predictor, $x$, the logistic model results in a symmetric, sigmoidal function across values of $x$. To demonstrate, a simple logistic regression model was fit to the binary outcome data with a single predictor: the annual precipitation. That predictor has a fairly right-skewed distribution, so a log (base 10) transformation was used on the data prior to training the model. 

There are various ways to find parameter estimates, which will be discussed in subsequent subsections. The most basic method is maximum likelihood estimation, where we use a numerical optimization method to minimize the loss function, which is the negative log-likelihood. The log-likelihood is more numerically stable to work with, and it is generally not challenging to find maximum likelihood estimates (MLEs) of our $\boldsymbol{\beta}$ parameters. Statistically, the MLEs are estimates that best explain the data. They are also unbiased estimates of the true parameters^[Recall from @sec-variance-bias that unbiased estimates might have high variance. For the forestation data, we'll see that some of our logistic regression parameter estimates have irrationally large variances. Later in this chapter, biased methods (via regularization) are also discussed.].

We solved the log-likelihood equations (based on @eq-bernoulli) to estimate the parameters, producing the linear predictor function:  

$$
\boldsymbol{x}_i'\boldsymbol{\beta} = `r linear_percip_coef[1]` + `r linear_percip_coef[2]` \log_{10}(precipitation_i)
$$

@fig-precipitation shows this pattern using the annual precipitation predictor in the forestation data in green. The curve shows a smooth function that increases in $x$ and has an asymptote of 1.0. 

Since the outcome data have only two qualitative values, it is difficult to visualize how well the curve fits the data. However, our training set for this example is fairly large, and we can show the observed event rate over the range of precipitation by binning the data into 50 groups. The breakpoints for the bins are quantiles of the log-10 training set predictor values. @fig-precipitation has an option to overlay these data with the model fit. 

::: {#fig-precipitation}

::: {.figure-content}

```{shinylive-r}
#| label: fig-precipitation
#| out-width: "80%"
#| viewerHeight: 600
#| standalone: true

library(shiny)
library(bslib)
library(tidymodels)
library(splines2)
library(scales)

light_bg <- "#fcfefe" # from aml4td.scss
grid_theme <- bs_theme(
  bg = light_bg, fg = "#595959"
)

theme_light_bl<- function(...) {
  
  ret <- ggplot2::theme_bw(...)
  
  col_rect <- ggplot2::element_rect(fill = light_bg, colour = light_bg)
  ret$panel.background  <- col_rect
  ret$plot.background   <- col_rect
  ret$legend.background <- col_rect
  ret$legend.key        <- col_rect
  
  ret$legend.position <- "top"
  
  ret
}

# ------------------------------------------------------------------------------

ui <- page_fillable(
  theme = bs_theme(bg = "#fcfefe", fg = "#595959"),
  padding = "1rem",
  layout_columns(
    fill = FALSE,
    col_widths = breakpoints(sm = c(-1, 5, 5, -1)),
    column(
      width = 4,
      checkboxGroupInput(
        inputId = "include",
        label = "Include",
        choices = list("Binned Data" = "Data", "Untransformed" = "fit_linear", 
                       "Splines" = "fit_spline", GAM = "fit_gam"),
        selected = c("fit_linear"),
        inline = TRUE
      )
    ),
    column(
      width = 4,
      radioButtons(
        inputId = "yaxis",
        label = "y-axis",
        choices = c("Event Rate" = "rate", "Logit" = "logit"),
        inline = TRUE
      )
    )
  ),
  as_fill_carrier(plotOutput("plot"))
)


server <- function(input, output) {
  load(url("https://raw.githubusercontent.com/aml4td/website/main/RData/forested_data.RData"))
  
  percip <- 
    forested_train %>% 
    mutate(precip_annual = log10(precip_annual))
  
  percip_bin <- 
    percip %>% 
    select(class, precip_annual) %>% 
    mutate(percip_bin = ntile(precip_annual, 50)) %>% 
    summarize(
      rate = mean(class == "Yes"),
      percip = median(precip_annual),
      n = length(precip_annual),
      .by = c(percip_bin)
    ) %>% 
    mutate(logit = binomial()$linkfun(rate))
  
  percip_rng <- extendrange(percip_bin$percip)
  # percip_rng[1] <- 0.0
  
  percip_grid <- tibble(precip_annual = seq(percip_rng[1], percip_rng[2], length.out = 100))
  
  linear_fit <- 
    logistic_reg() %>% 
    fit(class ~ precip_annual, data = percip)
  
  linear_pred <- 
    augment(linear_fit, new_data = percip_grid) %>% 
    mutate(Model = "Linear Term", group = "fit_linear")
  
  num_spline <- 9
  spline_fit <- 
    logistic_reg() %>% 
    fit(class ~ naturalSpline(precip_annual, df = num_spline), data = percip)
  
  spline_lab <- paste0("Natural Splines (", num_spline, " df)")
  
  spline_pred <- 
    augment(spline_fit, new_data = percip_grid) %>% 
    mutate(Model = spline_lab, group = "fit_spline")
  
  gam_fit <- 
    gen_additive_mod() %>% 
    set_mode("classification") %>% 
    fit(class ~ s(precip_annual), data = percip)
  gam_lab <- paste0("GAM (", round(sum(gam_fit$fit$edf[-1]), 1), " df)")
  
  gam_pred <- 
    augment(gam_fit, new_data = percip_grid) %>% 
    mutate(Model = gam_lab, group = "fit_gam")
  
  predictions <- 
    bind_rows(linear_pred, spline_pred, gam_pred) %>% 
    mutate(Model = factor(Model, levels = c("Linear Term", spline_lab, gam_lab))) %>% 
    mutate(logit = binomial()$linkfun(.pred_Yes))
  
  output$plot <-
    renderPlot({
      
      if (input$yaxis == "rate") {
        p <- 
          percip_bin %>% 
          ggplot(aes(percip)) + 
          labs(x = "Log10 Annual Percipitation", y = "Probability of Forestation") + 
          lims(y = 0:1)
      } else {
        p <- 
          percip_bin %>% 
          ggplot(aes(percip)) + 
          labs(x = "Log10 Annual Percipitation", y = "Logit")
      }
      
      
      if (any(input$include == "Data")) {
        if (input$yaxis == "rate") {
          p <- p +  geom_point(aes(y = rate), alpha = 1 / 3, cex = 3) 
        } else {
          p <- p +  geom_point(aes(y = logit), alpha = 1 / 3, cex = 3) 
        }
      }
      
      if (any(grepl("fit_", input$include))) {
        curve_data <- dplyr::filter(predictions, group %in% input$include)
        
        if (input$yaxis == "rate") {
          p <- p +
            geom_line(data = curve_data, 
                      aes(x = precip_annual, y = .pred_Yes, color = Model),
                      linewidth = 1)
        } else {
          p <- p +
            geom_line(data = curve_data, 
                      aes(x = precip_annual, y = logit, color = Model),
                      linewidth = 1) 
        }
        
        p <- p + 
          theme(legend.position = "top") + 
          scale_color_brewer(drop = FALSE, palette = "Dark2")
      }
      
      p <- p + theme_light_bl()
      print(p)
    }, res = 100)
}

app <- shinyApp(ui = ui, server = server)

```
:::

An example of a logistic regression model with a single predictor (annual precipitation, in log10 units)

:::

Overlaying the estimated event rates shows that the model does a poor job of representing the relationship between the probability of forestation and precipitation. The data trend is not monotonically increasing; in the middle of the precipitation range, there is a small drop in the binned rates that recovers and begins to increase once more. Our simple linear predictor is not flexible enough to emulate this motif.

### Generalized Linear Models {.unnumbered}

Logistic regression belongs to a broader class of _generalized linear models_, or GLMs [@glm]. These models can be used with different types of outcomes, such as numeric outcomes or count data. The idea is to have a model regress the linear predictor against a function of the outcome data. In our current case, the _logit_ function (the inverse of @eq-logistic) is applicable: 

$$
log\left(\frac{\pi_i}{1 - \pi_i}\right) = \eta_i = \boldsymbol{x}_i'\boldsymbol{\beta}
$$ {#eq-logit}

Looking back to @fig-precipitation, we can change the y-axis data and show how the logit changes for our fitted model. The line visualizes the estimated linear predictor for these data. Sadly, when the representation of our data is similarly changed, the pattern is not linear; our linear model isn't effectively emulating the nonlinear pattern in the data. 

There are significant benefits to framing logistic regression inside the class of generalized linear models. First, it gives us some nice theoretical guarantees about the likelihood function, allowing us to use simple gradient-based optimization methods to optimize the log-likelihood. Second, it provides an inferential framework for our parameters. This enables us to understand how important our predictors are by way of hypothesis tests and confidence intervals. 

It's easy to take these benefits for granted. Suppose we were to find parameter estimates using some other log function, such as the Brier score or the area under the ROC curve. In that case, it might be difficult to solve the required equations, let alone derive the methods to make inferences regarding parameters. 

Before proceeding further, let's talk about the linear predictor. The "linear" in "linear predictor" and "generalized linear model" means that the model is _linear in the parameters_ $\boldsymbol{\beta}$. This does not mean that the model can only produce linear class boundaries. Our model terms $x_{ij}$ can represent any function of one or more parameters. We can use the feature engineering tools shown in Chapters [-@sec-numeric-predictors] through [-@sec-interactions-nonlinear] to create a better model. 

For example, in @fig-precipitation, we saw that using the log precipitation values as our single predictor $x$ didn't work well. When plotted on the logit scale, there is a clear nonlinear function in the binned rates. We know how to estimate a general nonlinear function of a parameter: spline functions. @fig-precipitation can also show the results when nine natural spline features are used in the model. Visually, we can see that this expansion is far more effective at predicting the outcome. We can also quantify this using several metrics mentioned in the previous chapter (e.g., Brier score, cross-entropy, etc).  

Logistic regression models can be drastically improved by including better representations of our predictors. Since it is an interpretable and stable model, we might be motivated to spend more time developing this model via exploratory data analysis and feature engineering. In many teaching materials and websites, we see analyses that quickly label the results of a logistic model as ineffective (due to the use of simple model terms) before moving on to more black-box machine-learning methods. The virtue of learning about your data and how the predictors related to the outcome can not only improve the logistic model but enable a more complete understanding and description of _why_ it works. 

```{r}
#| label: forest-logistic-elements
#| include: false

bare_rec <- 
  recipe(class ~ ., data = forested_train) %>% 
  step_dummy(county) %>% 
  step_zv(all_predictors())

transformed_rec <- 
  recipe(class ~ ., data = forested_train) %>% 
  step_orderNorm(all_numeric_predictors()) %>% 
  step_dummy(county) %>% 
  step_zv(all_predictors())

forest_rec <- 
  recipe(class ~ ., data = forested_train) %>% 
  step_orderNorm(all_numeric_predictors()) %>% 
  step_lencode_mixed(county, outcome = "class")

forest_int_rec <- 
  forest_rec %>% 
  step_interact(
    ~ dew_temp:elevation + longitude:vapor_min + 
      longitude:vapor_max + dew_temp:temp_january_min + 
      dew_temp:vapor_max + latitude:longitude + 
      longitude:roughness + temp_annual_max:dew_temp + 
      temp_annual_min:dew_temp + 
      temp_annual_max:vapor_max
  )

forest_spline_rec <- 
  forest_int_rec %>% 
  step_spline_natural(
    all_numeric_predictors(), -county, -eastness, -northness, -year, -contains("_x_"),
    deg_free = 10) %>% 
  step_lincomb(all_predictors())

forest_set <- 
  workflow_set(
    preproc = list(simple = bare_rec, "encoded + transformations" = transformed_rec, 
                   encoded = forest_rec, "encoded + interactions" = forest_int_rec, 
                   "encoded + transformations + splines" = forest_spline_rec),
    model = list(logistic_mle = logistic_reg())
  )

cls_mtr <- metric_set(brier_class, roc_auc, pr_auc, mn_log_loss)
```


```{r}
#| label: forest-logistic-run
#| include: false
#| cache: true
forest_res <-
  forest_set %>% 
  workflow_map(
    fn = "fit_resamples",
    resamples = forested_rs,
    control = control_resamples(save_pred = TRUE),
    metrics = cls_mtr, 
    seed = 693,
    verbose = FALSE
  )

set.seed(365)
brier_perm <- 
  forest_res %>% 
  extract_workflow_set_result("simple_logistic_mle") %>% 
  collect_predictions(summarize = TRUE) %>% 
  permutations(permute = "class", times = 50) %>% 
  mutate(
    data = map(splits, analysis),
    brier = map_dbl(data, ~ brier_class(.x, class, .pred_Yes)$.estimate)
  ) %>% 
  summarize(
    permutation = mean(brier),
    n = length(brier),
    std_err = sd(brier) / sqrt(n)
  ) %>% 
  mutate(
    lower = permutation - qnorm(.95) * std_err,
    upper = permutation + qnorm(.95) * std_err
  )
```

### Forestation Model Development {.unnumbered}

We can assess each of these feature engineering steps by fitting logistic regression pipelines that sequentially add steps: 

- A **simple** preprocessor that only converts the `r length(levels(forested_train$county))` counties to binary indicators and removes potential zero-variance predictors. 
- We can add a **normalization** step that transforms the numeric predictors using the ORD transformation. 
- We'll replace the county  code dummy variable operation with an effect **encoding** step (from the previous pipeline).
- We can add our potential **interactions** to our preprocessor operations. 
- Finally, we can supplement our interaction pipeline with ten **spline** terms for the previously listed predictor set. 

For each of these preprocessing/model configurations, we’ll resample the training set and estimate several performance metrics (but will focus on the Brier score). 

We can see the resampling results in @fig-forest-logistic. It shows that most steps incrementally reduce the Brier score. One of the largest drops occurs when we avoid making many county indicators and use an effect encoding instead. The normalization step is estimated to help, but the error bars indicate that this improvement might be within the statistical noise of resampling. The end result is a 1/3 reduction in the Brier score by adding better representations of our predictors. 

Note about linear dependencies and widly large coefficients

```{r}
#| label: fig-forest-logistic
#| echo: false
#| out-width: 70%
#| fig-width: 6
#| fig-height: 3.25
#| fig-cap: Cross-validated Brier scores for several stages of feature engineering of the forestation data using basic logistic regression. The red dashed line represents the permutation estimate of the no-information rate. The error bars are 90% confidence intervals based on the naive standard error estimates produced during resampling. 

forest_res %>% 
  rank_results(rank_metric = "brier_class") %>% 
  filter(.metric == "brier_class") %>% 
  mutate(
    pipeline = gsub("_logistic_mle", "", wflow_id), 
    pipeline = factor(pipeline),
    pipeline = reorder(pipeline, -mean),
    ci_pm = qnorm(0.95) * std_err
  ) %>% 
  ggplot(aes(mean, pipeline)) + 
  geom_vline(xintercept = brier_perm$permutation, col = "red", lty = 2) +
  geom_vline(xintercept = 0, col = "green", lty = 2) +
  geom_point() +
  geom_errorbar(aes(xmin = mean - ci_pm, xmax = mean + ci_pm), width = 1 / 3) +
  labs(x = "Brier Score", y = NULL)
```

```{r}
#| label: logistic-spline-mtr
#| include: false
logistic_mtr <- 
  forest_res %>% 
  extract_workflow_set_result("encoded + transformations + splines_logistic_mle") %>% 
  collect_metrics(summarize = TRUE)
```

Along with the Brier score values of `r signif(logistic_mtr$mean[logistic_mtr$.metric == "brier_class"], 3)`, the spline pipeline had the following resampling estimates: ROC AUC = `r signif(logistic_mtr$mean[logistic_mtr$.metric == "roc_auc"], 3)`, a PR AUC = `r signif(logistic_mtr$mean[logistic_mtr$.metric == "pr_auc"], 3)`, and a cross-entropy = `r signif(logistic_mtr$mean[logistic_mtr$.metric == "mn_log_loss"], 3)`. During resampling, there were `r logistic_mtr$n[1]` resamples, leading to `r logistic_mtr$n[1]` ROC curves, and so on. We can pool the `r logistic_mtr$n[1]` sets of assessment set predictions and produce approximate ROC and calibration curves. These are shown in @fig-forest-logistic-diag. The calibration curve indicates that the model has trouble reliably predicting samples whose true probabilities are less than one-half. The ROC curve is unremarkable. 

```{r}
#| label: fig-forest-logistic-diag
#| echo: false
#| out-width: 80%
#| fig-width: 8
#| fig-height: 4
#| fig-cap: Calibration and ROC curves for the pooled assessment sets for the logistic regression model and the full preprocessing pipeline (e.g. up to spline terms). 

logistic_pred <- 
  forest_res %>% 
  extract_workflow_set_result("encoded + transformations + splines_logistic_mle") %>% 
  collect_predictions(summarize = TRUE)

logitic_cal <- cal_plot_windowed(logistic_pred, class, .pred_Yes, step_size = 0.02)
logitic_roc <- 
  logistic_pred %>% 
  roc_curve(class, .pred_Yes) %>% 
  ggplot(aes(1 - specificity, sensitivity)) + 
  geom_abline(col = "red", lty = 2) +
  geom_step(direction = "vh") + 
  coord_obs_pred()

logitic_cal + logitic_roc
```

From here, we could investigate which terms had the greatest influence on the model. Were the 10 interactions that we identified important or statistically significant? Should we have added more or less? We might plot the predicted values to see if there are specific geographic locations that corresponded to the poorly calibrated values. Perhaps we could also refine the model by using a supervised feature filter, and so on. 

Instead, we’ll move on to a different way to estimate the logistic model’s unknown parameters using different objective functions that use the likelihood but in different ways. 

### Interpretation {.unnumbered}

```{r}
#| label: odds-calc
#| include: false
ref_level <- "yakima"
ref_cnty <- tools::toTitleCase(gsub("_", " ", ref_level))
other_level <- "skamania"
other_term <- paste0("county", other_level)
other_cnty <- tools::toTitleCase(gsub("_", " ", other_level))

releveled <- forested_train |> 
  mutate(county = relevel(county, ref = ref_level))

county_coef <- 
  logistic_reg() |> 
  fit(class ~ county, data = releveled) |> 
  tidy(conf.int = TRUE, conf.level = 0.90)

ref_coef <- 
  county_coef |> 
  filter(term %in% c("(Intercept)")) |> 
  mutate(
    coef = format(-estimate, digits = 3, scientific = FALSE),
    odds = format(exp(-estimate), digits = 3, scientific = FALSE),
    prob = binomial()$linkinv(-estimate),
    xin = format(1/prob, digits = 2, scientific = FALSE),
    prob = format(prob * 100, digits = 3)
    )

other_coef <- 
  county_coef |> 
  filter(term %in% c(other_term)) |> 
  mutate(
    coef = format(-estimate, digits = 3, scientific = FALSE),
    .upper = format(exp(-conf.low), digits = 3, scientific = FALSE),
    .lower= format(exp(-conf.high), digits = 3, scientific = FALSE),
    odds = format(exp(-estimate), digits = 3, scientific = FALSE),
    prob = binomial()$linkinv(-estimate),
    xin = format(1/prob, digits = 2, scientific = FALSE),
    prob = format(prob * 100, digits = 3)
  )

other_change_coef <- 
  county_coef |> 
  filter(term %in% c("(Intercept)", other_term)) |> 
  summarize(estimate = sum(estimate)) |> 
  mutate(
    coef = format(-estimate, digits = 3, scientific = FALSE),
    odds = format(exp(-estimate), digits = 3, scientific = FALSE),
    prob = binomial()$linkinv(-estimate),
    xin = format(1/prob, digits = 2, scientific = FALSE),
    prob = format(prob * 100, digits = 3)
  )
```

The logit function has a meaningful interpretation since it contains the _odds_ of an event occurring. Let's consider a simple case where we are modeling the change by county. If we use `r ref_cnty` county as the reference cell (recall @sec-indicators), the intercept of a logistic model is `r ref_coef$coef`. This corresponds to a probability of `r ref_coef$prob`%. The odds of some event that occurs with probability $\pi$ is 

$$
odds = \pi / (1-\pi)
$$ 

or "one in $1/\pi$." For `r ref_cnty`, this relates to the logistic regression model since


$$
log\left(\frac{Pr[\text{`r ref_cnty` forested}]}{Pr[\text{`r ref_cnty` unforested}]}\right) = log\left(\text{`r ref_cnty` odds}\right) = \beta_0
$$

Therefore, the odds of a tree being forested in this county are _exp_(`r ref_coef$coef`) = `r ref_coef$odds` or, one in about `r ref_coef$xin` locations. 

Alternatively, consider Skamania County, which contains  Gifford Pinchot National Forest. It's model coefficient is `r other_coef$coef` However, recall that with a reference cell encoding, this is the change in the logit relative to the reference value (`r ref_cnty` County). If we are interested in the probability of forestation for Skamania, we have to look at the sum of both coefficients (`r other_change_coef$coef` logit units) which means that the probability of forestation estimated to be about `r other_change_coef$prob`%.

One way of assessing how much more likely an event is to occur is the odds ratio. For example, if we wanted to compute the odds ratio of forestation between `r ref_cnty` and Skamania counties, we can use different sets of coefficients from the linear predictor. Since the forestation rate is higher in Skamania than `r ref_cnty`, the odds ratio of interest is

$$
\frac{\text{Skamania odds}}{\text{`r ref_cnty` odds}}
$$

We know that 

$$
log\left(\text{Skamania odds}\right) = log\left(\frac{Pr[\text{Skamania forested}]}{Pr[\text{Skamania unforested}]}\right) = \beta_0 +\beta_1
$$

so that 

$$
\frac{\text{Skamania odds}}{\text{`r ref_cnty` odds}} = \frac{exp(\beta_0 +\beta_1)}{exp(\beta_0)} = exp(\beta_0 + \beta_1 - \beta_0) = exp(\beta_1)
$$

From our estimated coefficient, the odds of being forested in Skamania is `r other_coef$odds` times larger than in `r ref_cnty`. Since we are using maximum likelihood estimation, we can also compute confidence intervals for this odds ratio; the 90% interval is (`r other_coef$.lower`, `r other_coef$.upper`). 

For numeric predictors, such as eastness or elevation, exponentiating the coefficient gives us a _per unit_ odds ratio. Since the predictors might be in different units, the interpretation can be more complex depending on the situation^[This might be one factor that leads some to discretize numeric predictors; they can compute odds ratios for "low" and "high" predictor ranges.].

In either case, the logistic regression model does have a structure that lends itself to natural probabilistic interpretation. 

### Multicollinearity

Look at coefs

Look at 2 predictor demo

correlation of features

harms interpretation and rankings

PCA/PLS/filters

what about interactions; hierarchy principle

### Regularized {#sec-logistic-penalized}

ridge
lasso
elasticnet/glmnet
adaptive lasso
Univariate-Guided
MCP
SCAD

relaxed lasso


### Bayesian Estimation {#sec-logistic-bayes}

## Multinomial Regression {#sec-multinomial-reg}

## Generalized Additive Models {#sec-cls-gam}

## Linear Discriminants {#sec-lda}

## Chapter References {.unnumbered}
