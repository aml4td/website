<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12&nbsp; Iterative Search – Applied Machine Learning for Tabular Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/feature-selection.html" rel="next">
<link href="../chapters/grid-search.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-ac94f01b84e0cf733daf4ed4b084c36a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<meta name="shinylive:serviceworker_dir" content="..">
<script src="../site_libs/quarto-contrib/shinylive-0.9.1/shinylive/load-shinylive-sw.js" type="module"></script>
<script src="../site_libs/quarto-contrib/shinylive-0.9.1/shinylive/run-python-blocks.js" type="module"></script>
<link href="../site_libs/quarto-contrib/shinylive-0.9.1/shinylive/shinylive.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/shinylive-quarto-css/shinylive-quarto.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-7T996NL20Z"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-7T996NL20Z', { 'anonymize_ip': true});
</script>
<script src="../site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <a class="flex-grow-1 no-decor" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
          <h1 class="quarto-secondary-nav-title"><span id="sec-iterative-search" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Iterative Search</span></span></h1>
        </a>     
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../"></a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/aml4td/website/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/news.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">News</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/contributing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contributing</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/whole-game.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Whole Game</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Preparation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/initial-data-splitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Initial Data Splitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/missing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Missing Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/numeric-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Transforming Numeric Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/categorical-predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Working with Categorical Predictors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Embeddings</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/interactions-nonlinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Interactions and Nonlinear Features</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/overfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Overfitting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/resampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Measuring Performance with Resampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/grid-search.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Grid Search</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/iterative-search.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Iterative Search</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/feature-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Feature Selection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/comparing-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Comparing Models</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Classification</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Regression</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Characterization</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Finalization</span></span>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-barley-svm" id="toc-sec-barley-svm" class="nav-link active" data-scroll-target="#sec-barley-svm"><span class="header-section-number">12.1</span> Example: Predicting Barley Amounts using Support Vector Machines</a></li>
  <li><a href="#sec-gradient-opt" id="toc-sec-gradient-opt" class="nav-link" data-scroll-target="#sec-gradient-opt"><span class="header-section-number">12.2</span> Sidebar: Gradient-Based Optimization</a></li>
  <li><a href="#sec-sim-anneal" id="toc-sec-sim-anneal" class="nav-link" data-scroll-target="#sec-sim-anneal"><span class="header-section-number">12.3</span> Simulated Annealing</a></li>
  <li><a href="#sec-genetic-algo" id="toc-sec-genetic-algo" class="nav-link" data-scroll-target="#sec-genetic-algo"><span class="header-section-number">12.4</span> Genetic Algorithms</a>
  <ul class="collapse">
  <li><a href="#sec-ga-generations" id="toc-sec-ga-generations" class="nav-link" data-scroll-target="#sec-ga-generations"><span class="header-section-number">12.4.1</span> Assembling Generations</a></li>
  <li><a href="#sec-2D-example" id="toc-sec-2D-example" class="nav-link" data-scroll-target="#sec-2D-example"><span class="header-section-number">12.4.2</span> Two Parameter Example</a></li>
  <li><a href="#sec-ga-summary" id="toc-sec-ga-summary" class="nav-link" data-scroll-target="#sec-ga-summary"><span class="header-section-number">12.4.3</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-bayes" id="toc-sec-bayes" class="nav-link" data-scroll-target="#sec-bayes"><span class="header-section-number">12.5</span> Sidebar: Bayesian Models</a>
  <ul class="collapse">
  <li><a href="#sec-single-proportion" id="toc-sec-single-proportion" class="nav-link" data-scroll-target="#sec-single-proportion"><span class="header-section-number">12.5.1</span> A Single Proportion</a></li>
  <li><a href="#sec-freq-and-bayes" id="toc-sec-freq-and-bayes" class="nav-link" data-scroll-target="#sec-freq-and-bayes"><span class="header-section-number">12.5.2</span> What is not Bayesian?</a></li>
  </ul></li>
  <li><a href="#sec-bayes-opt" id="toc-sec-bayes-opt" class="nav-link" data-scroll-target="#sec-bayes-opt"><span class="header-section-number">12.6</span> Bayesian Optimization</a>
  <ul class="collapse">
  <li><a href="#sec-acquisition" id="toc-sec-acquisition" class="nav-link" data-scroll-target="#sec-acquisition"><span class="header-section-number">12.6.1</span> How Does Bayesian Optimization Work?</a></li>
  <li><a href="#sec-gp" id="toc-sec-gp" class="nav-link" data-scroll-target="#sec-gp"><span class="header-section-number">12.6.2</span> Gaussian Process Models</a></li>
  <li><a href="#sec-ba-2D" id="toc-sec-ba-2D" class="nav-link" data-scroll-target="#sec-ba-2D"><span class="header-section-number">12.6.3</span> A Two Dimensional Illustration</a></li>
  </ul></li>
  <li><a href="#sec-bayes-opt-nnet" id="toc-sec-bayes-opt-nnet" class="nav-link" data-scroll-target="#sec-bayes-opt-nnet"><span class="header-section-number">12.7</span> Example: Tuning a Neural Network</a></li>
  <li><a href="#sec-iterative-summary" id="toc-sec-iterative-summary" class="nav-link" data-scroll-target="#sec-iterative-summary"><span class="header-section-number">12.8</span> Summary</a></li>
  <li><a href="#chapter-references" id="toc-chapter-references" class="nav-link" data-scroll-target="#chapter-references">Chapter References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span id="sec-iterative-search" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Iterative Search</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Grid search is a static procedure; we predetermine which candidates will be evaluated before beginning. How can we adaptively optimize tuning parameters in a sequential manner? Perhaps more importantly, <em>when</em> is this a good approach?</p>
<p>Previously, we’ve seen that a plateau of good performance in the parameter space is possible. This is often the case but will not always be true. If the region of optimal performance is small, we must create a large space-filling design to find it. When there are many tuning parameters, the computational expense can be unreasonable. An even worse situation is one where the previously described speed-up techniques (such as the submodel trick from <a href="grid-search.html#sec-submodels" class="quarto-xref"><span>Section 11.3.1</span></a>) are not applicable. Racing can be very efficient, but if the training set is very large, it may be that using a validation set is more appropriate than multiple resamples; in this case, racing cannot be used. Finally, there are practical considerations when the data set is very large. Most parallel processing techniques require the data to be in memory for each parallel worker, restricting their utility.</p>
<p>Generally, we are not often constrained by these issues <em>for models used for tabular data</em>. However, there are a few models that might be better optimized sequentially. The first two that come to mind are large neural networks<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. and support vector machines<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> (SVMs) <span class="citation" data-cites="scholkopf2001 cristianini2004">(<a href="#ref-scholkopf2001" role="doc-biblioref">Schölkopf and Smola 2001</a>; <a href="#ref-cristianini2004" role="doc-biblioref">Shawe-Taylor and Cristianini 2004</a>)</span>. For the former, as the number of layers increases, so does the number of tuning parameters. Neural networks also have many important tuning parameters associated with the model’s training, such as the learning rate, regularization parameters, etc. These models also require more preprocessing than others; they are suspectable to the effects of uninformative predictors, missing data, and collinearity. Depending on the data set, there can be many pre-model tuning parameters.</p>
<p>Support vector machines are models with fewer tuning parameters than neural networks but with similar preprocessing requirements. Unfortunately, the tuning parameter space can have large areas of poor performance with “islands” where the model works well. The location of these will change from data set to data set. We’ll see an example of this shortly where two model parameters are tuned.</p>
<p>These two models, in particular, are more likely to benefit from an optimization method that chooses candidates as the process evolves.</p>
<p>In theory, any iterative optimization procedures can be used. In general, gradient methods, such as steepest descent or Newton’s method, are the most commonly used technique for nonlinear optimization. These tools are suboptimal when it comes to parameter tuning but play important parts in other areas of machine learning and, for this reason, they will be discussed later.</p>
<p>Derivative-free techniques can be helpful for model tuning. Traditional examples are genetic algorithms, simulated annealing, particle swarm optimization, etc. We’ll consider the first two of these in Sections <a href="#sec-sim-anneal" class="quarto-xref"><span>12.3</span></a> and <a href="#sec-genetic-algo" class="quarto-xref"><span>12.4</span></a>. Currently, the most well-known iterative tool for tuning models is Bayesian optimization. This will be examined in <a href="#sec-bayes-opt" class="quarto-xref"><span>Section 12.6</span></a>. However, before this, <a href="#sec-bayes" class="quarto-xref"><span>Section 12.5</span></a> will flesh out what it means for a model to be Bayesian.</p>
<p>To get started, let’s revisit a data set.</p>
<section id="sec-barley-svm" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="sec-barley-svm"><span class="header-section-number">12.1</span> Example: Predicting Barley Amounts using Support Vector Machines</h2>
<p>We’ll return to the data previously seen in <a href="embeddings.html#sec-barley" class="quarto-xref"><span>Section 7.1</span></a> where we want to predict the percentage of barley oil in a mixture. Recall that the predictors are extremely correlated with one another. In <a href="embeddings.html" class="quarto-xref"><span>Chapter 7</span></a>, we considered embedding methods like PCA to preprocess the data and these models were able to achieve RMSE values of about 6% (shown in <a href="embeddings.html#fig-barley-linear-bakeoff" class="quarto-xref">Figure&nbsp;<span>7.6</span></a>).</p>
<p>In this chapter, we’ll model these data in two different scenarios. First, we’ll use them as a “toy problem” where only two tuning parameters are optimized for a support vector machine model. This is a little unrealistic, but it allows us to visualize how iterative search methods work in a 2D space. Second, in <a href="#sec-bayes-opt-nnet" class="quarto-xref"><span>Section 12.7</span></a>, we’ll get serious and optimize a larger group of parameters for neural networks simultaneously with additional parameters for a specialized preprocessing technique.</p>
<p>Let’s start with the toy example that uses an SVM regression model. This highly flexible nonlinear model can represent the predictor data in higher dimensions using a <em>kernel transformation</em> <span class="citation" data-cites="hofmann2008">(<a href="#ref-hofmann2008" role="doc-biblioref">Hofmann, Schölkopf, and Smola 2008</a>)</span>. This type of function combines numeric predictor vectors from two data points using a dot product. There are many different types of kernel functions, but for a <em>polynomial</em> kernel, it is:</p>
<p><span id="eq-kernel-poly"><span class="math display">\[
k(\boldsymbol{x}_1, \boldsymbol{x}_2) = (a\boldsymbol{x}_1'\boldsymbol{x}_2 + b)^q
\tag{12.1}\]</span></span></p>
<p>where <span class="math inline">\(a\)</span> is called the scaling factor, <span class="math inline">\(b\)</span> is a constant offset value, and <span class="math inline">\(q\)</span> is the polynomial degree. The dot product of predictor vectors (<span class="math inline">\(\boldsymbol{x}_i\)</span>) measures both angle and distance between points. Note that for the kernel function to work in an appropriate way, the two vectors must have elements with consistent units (i.e., they have been standardized).</p>
<p>The kernel function operates much like a polynomial basis expansion; it projects a data point into a much larger, nonlinear space. The idea is that a more complex representation of the predictors might enable the model to make better predictions.</p>
<p>For our toy example, we’ll take the 550 predictors, project them to a reduced space of 10 principal components, and standardize those features to have the same mean and standard deviation. A quartic polynomial with zero offset is applied, and the scale parameter, <span class="math inline">\(a\)</span>, will be tuned. This parameter helps define how much influence the dot product has in the polynomial expansion.</p>
<p>The most commonly adjusted parameter in SVMs is the cost value, which is independent of the chosen kernel function. This parameter determines how strongly the model is penalized for incorrect predictions on the training set. A higher cost value pushes the SVM to create a more complex model. As shown earlier in <a href="overfitting.html#fig-two-class-overfit" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>, small cost values result in the SVM making less effort to classify samples correctly, leading to underfitting. In contrast, extremely high cost values cause the model to overfit to the training set.</p>
<p>Just as in <a href="embeddings.html" class="quarto-xref"><span>Chapter 7</span></a>, the RMSE will be computed from a validation set and these statistics will be used to guide our efforts.</p>
<p>Let’s define a wide space for our two tuning parameters: cost will vary from 2<sup>-10</sup> to 2<sup>10</sup> and the scale factor<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> is allowed to range from 10<sup>-10</sup> to 10<sup>-0.1</sup>.</p>
<p><a href="#fig-svm-grid" class="quarto-xref">Figure&nbsp;<span>12.1</span></a> visualizes the RMSE across these ranges<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> where darker colors indicate smaller RMSE values. The lower left diagonal area is a virtual “dead zone” with very large RMSE results that don’t appear to change much. There is also a diagonal wedge of good performance (symbolized by the darker colors). The figure shows the location of the smallest RMSE value and a diagonal ridge of parameter combinations with nearly equal results. Any points on this line would produce good models (at least for this toy example). Note that there is a small locale of excessively large RMSE values in the upper right. Therefore, increasing both tuning parameters to their upper limits is a bad idea.</p>
<div class="cell" data-layout-align="center" data-fig-altalt="Heatmap showing optimization results for SVM parameters. A dark red diagonal ridge indicates optimal performance zones where cost and scaling factors are inversely related. The brightest point marks the lowest RMSE value at high scaling factor and low cost.">
<div class="cell-output-display">
<div id="fig-svm-grid" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-svm-grid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="iterative-search_files/figure-html/fig-svm-grid-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-svm-grid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.1: A visualization of model performance when only the SVM cost and scaling factor parameters are optimized. It shows the combination with the smallest RMSE and a ridge of candidate values with nearly equivalent performance.
</figcaption>
</figure>
</div>
</div>
</div>
<p>In the next section, we explore gradient descent optimization and explain why it may not be suitable for model tuning. Following that, we delve into two traditional global search methods—simulated annealing and genetic algorithms—and their application in parameter space exploration. We then shift our focus to Bayesian optimization, concluding with an in-depth analysis of the barley prediction problem.</p>
</section>
<section id="sec-gradient-opt" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="sec-gradient-opt"><span class="header-section-number">12.2</span> Sidebar: Gradient-Based Optimization</h2>
<p>To formalize the concept of optimization, we need an objective function that defines what we are trying to optimize. This function, often called a loss function (specifically to be minimized), is denoted by <span class="math inline">\(\psi()\)</span>. The parameters that modify <span class="math inline">\(\psi()\)</span> are represented by <span class="math inline">\(\boldsymbol{\theta}\)</span>, a <span class="math inline">\(p \times 1\)</span> vector of real numbers. For simplicity, we will assume that <span class="math inline">\(\psi()\)</span> is smooth and generally differentiable. Additionally, without loss of generality, we will assume that <em>smaller</em> values of <span class="math inline">\(\psi()\)</span> are better.</p>
<p>We’ll denote the first derivative (<span class="math inline">\(\psi'(\boldsymbol{\theta})\)</span>), for simplicity, as <span class="math inline">\(g(\boldsymbol{\theta})\)</span> (<span class="math inline">\(p\times 1\)</span>). The matrix of second deriviatives, called the Hessian matrix, is symbolized as <span class="math inline">\(H(\boldsymbol{\theta})\)</span> (<span class="math inline">\(p\times  p\)</span>).</p>
<p>We start with an initial guess, <span class="math inline">\(\boldsymbol{\theta}_0\)</span>, and compute the gradient at this point, yielding a <span class="math inline">\(p\)</span>-dimensional directional vector. To get to our next parameter value, simple gradient descent uses the update:</p>
<p><span id="eq-gd-step"><span class="math display">\[
\boldsymbol{\theta}_{i+1} = \boldsymbol{\theta}_i - \alpha\:g(\boldsymbol{\theta}_i)
\tag{12.2}\]</span></span></p>
<p>The value <span class="math inline">\(\alpha\)</span> defines how far to move in the chosen direction. It can either be a fixed constant<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> or adjusted using a secondary method called a line search. In a line search, <span class="math inline">\(\alpha\)</span> is incrementally increased until the objective function worsens.</p>
<p>We proceed to iterate this process until some measure of convergence is achieved. For example, the optimization could be halted if the objective function does not improve more than a very small value. <span class="citation" data-cites="lu2022gradient">Lu (<a href="#ref-lu2022gradient" role="doc-biblioref">2022</a>)</span> and <span class="citation" data-cites="zhang2019gradient">Zhang (<a href="#ref-zhang2019gradient" role="doc-biblioref">2019</a>)</span> are excellent introductions to gradient-based optimization that is focused on training models.</p>
<p>As a simple demonstration, <a href="#fig-grad-descent" class="quarto-xref">Figure&nbsp;<span>12.2</span></a> shows <span class="math inline">\(\psi(\theta) = \theta\: cos(\theta/2)\)</span> for values of <span class="math inline">\(\theta\)</span> between <span class="math inline">\(\pm 10.0\)</span>. We want to minimize this function. There is a <em>global</em> minimum at about <span class="math inline">\(\theta \approx 6.85\)</span> while there are <em>local</em> minima at <span class="math inline">\(\theta = -10.0\)</span> and <span class="math inline">\(\theta \approx -1.72\)</span>. These are false solutions where some search procedures might become trapped.</p>
<div class="columns">
<div class="column" style="width:5%;">

</div><div class="column" style="width:90%;">
<div id="fig-grad-descent" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-grad-descent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="figure-content">
<pre class="shinylive-r" data-engine="r"><code>#| label: shiny-grad-descent
#| viewerHeight: 600
#| viewerWidth: "100%"
#| standalone: true
library(shiny)
library(bslib)
library(ggplot2)
library(dplyr)

source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-setup.R")
source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-gd.R")

app</code></pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-grad-descent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.2: An example of simple gradient descent for the function <span class="math inline">\(\psi(\theta) = \theta\: cos(\theta/2)\)</span>.
</figcaption>
</figure>
</div>
</div><div class="column" style="width:5%;">

</div>
</div>
<p>The figure enables the choice of <span class="math inline">\(\theta_0\)</span>, the value of <span class="math inline">\(\alpha\)</span>, and how many iterations to used. Consider a few configurations:</p>
<ul>
<li><p>Starting at <span class="math inline">\(\theta = 3\)</span>, a learning rate of <span class="math inline">\(\alpha = 2.0\)</span> is inappropriate. The search initially moves towards the global minimum but then reverses course and jumps past the best value, then becomes trapped around one of the local optima.</p></li>
<li><p>If we keep <span class="math inline">\(\theta = 3\)</span> and decrease learning rate to <span class="math inline">\(\alpha = 1.0\)</span>, we quickly find the best result.</p></li>
<li><p>However, if we tried decreasing the learning rate too low, say <span class="math inline">\(\alpha = 0.01\)</span>, the optimization moves too slowly.</p></li>
</ul>
<p>The learning rate plays a crucial role in the optimization process. Additionally, the starting value is significant; values below 2.0 consistently fail to reach the optimum.</p>
<p>This gradient descent algorithm outlined above is extremely basic. There are far more complex versions, the most well-known of which is the Newton-Raphson method (a.k.a. Newton’s Method) that incorporates the second derivative matrix <span class="math inline">\(H(\boldsymbol{\theta})\)</span> in the updating formula<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<p>We often know <em>when</em> gradient-based optimization will work well. If we know the equation for the objective function, we can determine its properties, such as whether it is a convex function, and theory can tell us if a global optimum can be found via the use of gradients. For example, squared error loss <span class="math inline">\(\psi(\boldsymbol{\theta}) = (y-\hat{y})^2\)</span>, is convex when the relationship for the predicted value <span class="math inline">\(\hat{y}\)</span> is a well-behaved function of <span class="math inline">\(\boldsymbol{\theta}\)</span> (such as in linear regression).</p>
<p>However, there are additional considerations when it comes to optimizations for predictive models. First, since data are not deterministic, the loss function is not only a random variable but can be excessively noisy. This noise can have a detrimental effect on how well the optimization proceeds.</p>
<p>Second, our objective function is often a performance metric, such as RMSE. However, not all metrics are mathematically well-behaved—they may lack smoothness or convexity. In the case of deep neural networks, even when the objective function is simple (e.g., squared error loss), the model equations can create a non-convex optimization landscape. As a result, the optimized parameters may correspond to a local optimum rather than a global one.</p>
<p>This issue arises because traditional gradient-based methods are inherently <em>greedy</em>. They optimize by moving in the direction that appears most favorable based on the current estimates of <span class="math inline">\(\boldsymbol{\theta}\)</span>. While this approach is generally effective, it can lead to the optimization process becoming trapped in a local optimum, particularly with complex or non-standard objective functions.</p>
<p>There are additional complications when the tuning parameters, <span class="math inline">\(\boldsymbol{\theta}\)</span>, are not real numbers. For instance, the number of spline terms is an integer, but the update equation might produce a fractional value for this number. Other parameters are qualitative, such as the choice of activation function in a neural network, which cannot be represented as continuous numerical values.</p>
<p>During model tuning, we know to avoid repredicting the training set (due to overfitting). Procedures such as resampling make the evaluation of <span class="math inline">\(\psi()\)</span> computationally expensive since multiple models should be trained. Unless we use symbolic gradient equations, the numerical process of approximating the gradient vector <span class="math inline">\(g(\boldsymbol{\theta})\)</span> can require a large number of function evaluations.</p>
<p>Later, we’ll discuss <em>stochastic gradient descent</em> (SGD) <span class="citation" data-cites="udl2023">(<a href="#ref-udl2023" role="doc-biblioref">Prince 2023, chap. 6</a>)</span>. This method is commonly used to train complex networks with large amounts of training data. SGD approximates the gradient by using only a small subset of the data at a time. Although this introduces some variation in the direction of descent, it can be beneficial as it helps the algorithm escape from local minima. Additionally, when dealing with large datasets, computer memory may not be able to store all the data at once. In such cases, SGD is often the only viable option because it doesn’t require the entire dataset to be loaded into memory and can also be much faster.</p>
<p>Until then, the next three chapters will describe different stochastic optimization, gradient-free methods that are well-suited for parameter tuning since they can sidestep some of the issues described above.</p>
</section>
<section id="sec-sim-anneal" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="sec-sim-anneal"><span class="header-section-number">12.3</span> Simulated Annealing</h2>
<p>Non-greedy search methods are not constrained to always proceed in the absolute best direction (as defined by the gradient). One such method is <em>simulated annealing</em> (SA)<span class="citation" data-cites="spall2005introduction kirkpatrick1983optimization">(<a href="#ref-kirkpatrick1983optimization" role="doc-biblioref">Kirkpatrick, Gelatt, and Vecchi 1983</a>; <a href="#ref-spall2005introduction" role="doc-biblioref">Spall 2005</a>)</span>. It is a controlled random search that moves in random directions but with some amount of control over the path. It can also incorporate restarts if the algorithm moves into clearly poor regions.</p>
<p>Given an initial solution, simulated annealing (SA) creates a random perturbation of the current candidate solution, typically within a small local neighborhood. The objective function is then evaluated for the new candidate and compared to the previous solution. If the new candidate results in an improvement, the process moves forward by using it to make the next step. If the new candidate is worse, there are two options:</p>
<ul>
<li>We can accept the current solution as “suboptimal” and use it as the basis for the next perturbation, or</li>
<li>we can discard the current solution and treat it as if it never occurred. The next candidate point will then be a perturbation of the last “acceptable” solution.</li>
</ul>
<p>For our SVM example, suppose we start with a candidate where</p>
<p><span class="math display">\[x_0 = \left[log_2 (cost), log_{10} (scale)\right] = [-10, -0.1]\]</span></p>
<p>and had an associated RMSE value of 6.10%. For the next candidate, a perturbation of this values is created, say <span class="math inline">\(x_1 = [-7.11, -0.225]\)</span>. Suppose that the corresponding RMSE was measured at 5.97%. Since <span class="math inline">\(x_1\)</span> has a better performance metric it is automatically accepted and is used to create the next parameter.</p>
<p>However, suppose that the RMSE value for <span class="math inline">\(x_1\)</span> was 7.00%, meaning that the new candidate did worse than the initial one. In this case, simulated annealing generates a probability threshold for accepting the worse solution. Typically, the probability depends on two quantities:</p>
<p>Simulated annealing generates a probability threshold for accepting the worse solution. Typically, the probability depends on two quantities:</p>
<ul>
<li>The difference between the current and previous objective function values. If the new candidate is nearly as good as the current solution, the probability of acceptance will be higher compared to a candidate that is significantly worse.</li>
<li>The probability of acceptance should decrease over time as the search progresses. This is often achieved using an exponentially decaying function, known as the “cooling schedule.”</li>
</ul>
<p>An often used equation for the probability, assuming that smaller values are better, is</p>
<p><span class="math display">\[
Pr[accept] = \exp\Bigl[-i\bigl(\hat{Q}(\boldsymbol{\theta}_{i}) - \hat{Q}(\boldsymbol{\theta}_{i-1})\bigr)\Bigr]
\]</span></p>
<p>where <span class="math inline">\(i\)</span> is the iteration number. To compare 6.1% versus 7.0%, the acceptance probability is 0.407. To make the determination, a random uniform number <span class="math inline">\(\mathcal{U}\)</span> is generated and, if <span class="math inline">\(\mathcal{U} \le Pr[accept]\)</span>, we accept <span class="math inline">\(\boldsymbol{\theta}_{i}\)</span> and use it to make <span class="math inline">\(\boldsymbol{\theta}_{i+1}\)</span>. Note that the probability “cools” over time; if this difference were to occur at a later iteration, say <span class="math inline">\(i = 5\)</span>, the probability would drop to 0.0111.</p>
<p>One small matter is related to the scale of the objective function. The difference in the exponent is very sensitive to scale. If, for example, instead of percentages we were to use the proportions 0.61 and 0.70, the probability of acceptance would change from 40.7% to 91.4%. One way to mitigate this issue is to use a normalized difference by dividing the raw difference by the previous objective function (i.e., (0.70-0.61) / 0.70). This is the approach used in the SA analyses here.</p>
<p>This process continues until either a pre-defined number of iterations is reached or there is no improvement after a certain number of iterations. The best result found during the optimization process is used as the final value, as there is no formal concept of “convergence” for this method. Additionally, as mentioned earlier, a restart rule can prevent simulated annealing from getting stuck in suboptimal regions if no better results have been found within a certain timeframe. When the process is restarted, it can either continue from the best candidate found in previous iterations or start from a random point in the parameter space.</p>
<p>How should the candidates be perturbed from iteration to iteration? When the tuning parameters are all numeric, we can create a random distance and angle from the current values. A similar process can be used for integers by “flooring” them to the nearest whole number. For qualitative tuning parameters, a random subset of parameters is chosen to change to a different value chosen at random. The amount of change should be large enough to search the parameters space and potentially get out of a local optimum.</p>
<p>It is important to perform computations on the parameters in their transformed space to ensure that the full range of possible values is treated equally. For example, when working with the SVM cost parameter, we use its log (base 2) scale. When perturbing the parameter values, we make sure to adjust them in the log space rather than the original scale. This approach applies to all other search methods discussed in this chapter.</p>
<p>To illustrate, a very small initial space-filling design with three candidates was generated and evaluated. The results are in <a href="#tbl-svm-initial" class="quarto-xref">Table&nbsp;<span>12.1</span></a>. To start the SA search<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, we will start with the candidate with the smallest RMSE and proceed for 50 iterations without a rule for early stopping. A restart to the last known best results was enforced after eight suboptimal iterations.</p>
<div class="columns">
<div class="column" style="width:25%;">

</div><div class="column" style="width:50%;">
<div id="tbl-svm-initial" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-svm-initial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="table-responsive">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">RMSE (%)</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Cost (log-2)</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Scale (log-10)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">6.10</td>
<td style="text-align: right;">-10</td>
<td style="text-align: right;">-0.1</td>
</tr>
<tr class="even">
<td style="text-align: left;">7.33</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">-5.0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">17.04</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">-10.0</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-svm-initial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.1: The initial set of candidates used for iterative search with the toy example from <a href="#fig-svm-grid" class="quarto-xref">Figure&nbsp;<span>12.1</span></a>. One candidate does poorly while the other two have relatively similar results.
</figcaption>
</figure>
</div>
</div><div class="column" style="width:25%;">

</div>
</div>
<p><a href="#fig-sa-example" class="quarto-xref">Figure&nbsp;<span>12.3</span></a> contains an animation of the results of the SA search. In the figure, the initial points are represented by open circles, and a grey diagonal line shows the ridge of values that corresponds to the best RMSE results.</p>
<div class="columns">
<div class="column" style="width:15%;">

</div><div class="column" style="width:70%;">
<div id="fig-sa-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sa-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="figure-content">
<pre class="shinylive-r" data-engine="r"><code>#| label: shiny-sa-example
#| viewerHeight: 600
#| viewerWidth: "100%"
#| standalone: true
#| fig-alt: A two-dimensional parameter space with axes for the scale parameter and the SVM cost is shown. Three initial points are shown. The SA algorithm progresses from a point with low cost and a large value of the scale factor to meander to the ridge of optimal performance, starting several times along the way. 
library(shiny)
library(bslib)
library(ggplot2)
library(dplyr)
library(purrr)
library(scales)

source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-setup.R")
source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-sa.R")

app</code></pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sa-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.3: An example of how simulated annealing can investigate the tuning parameter space. The open circles represent a small initial grid. The thick diagonal grey light is a ridge where the model has the smallest RMSE. The asterisk denotes the current best candidate.
</figcaption>
</figure>
</div>
</div><div class="column" style="width:15%;">

</div>
</div>
<p>During the search, there were 4 iterations where a new global best result was discovered (iterations 1, 14, 15, and 40). There were also 5 restarts at iterations 9, 23, 31, 39, and 48. In the end, the best results occurred with a cost value of 2<sup>-2.5</sup> and a scale factor of 10<sup>-0.98</sup>. The corresponding validation set RMSE was 5.78%. With this random seed, the search gets near the ridge of best performance shown in <a href="#fig-svm-grid" class="quarto-xref">Figure&nbsp;<span>12.1</span></a> but only lingers there for short times. It does spend a fair amount of time meandering in regions of poor performance.</p>
<p>Simulated annealing has several attractive qualities. First, the process of generating new candidates works with any type of parameter, whether real, integer, or qualitative. This is not true for the other two iterative methods we’ll discuss. Additionally, the perturbation process is very fast, meaning there is minimal computational overhead to compute the next objective function value. Since we are effectively generating new candidate sets, we can also apply constraints to individual parameters or groups of parameters. For example, if a tuning parameter is restricted to odd integers, this would not pose a significant problem for simulated annealing.</p>
<p>There are a few downsides to this method. Compared to the other search methods, SA makes small incremental changes. If we start far away from the optimum, many iterations might be required to reach it. One way to mitigate this issue is to do a small space-filling design and start from the best point (as we did). In fact, applying SA search after a grid search (perhaps using racing) can be a good way to verify that the grid search was effective.</p>
<p>Another disadvantage is that a single candidate is processed at a time. If the training set size is not excessive, we could parallel process the multiple candidates simultaneously. We could make a batch of perturbations and pick the best value to keep or apply the probabilistic process of accepting a poor value.</p>
<p>This optimization took 31.5s per candidate to execute for these data.</p>
<p><a href="https://tidymodels.aml4td.org/chapters/iterative-search.html#sec-sim-anneal"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
</section>
<section id="sec-genetic-algo" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="sec-genetic-algo"><span class="header-section-number">12.4</span> Genetic Algorithms</h2>
<p>Genetic algorithms (GAs) <span class="citation" data-cites="Mitchell1996AnIT eiben2015introduction">(<a href="#ref-Mitchell1996AnIT" role="doc-biblioref">Mitchell 1996</a>; <a href="#ref-eiben2015introduction" role="doc-biblioref">Eiben and Smith 2015</a>)</span> are an optimization method that mimics the process of evolution through natural selection. While GAs are not ideally suited for parameter tuning in our case—since a standard GA search typically requires hundreds to millions of objective function evaluations—we will limit the search to a smaller scale for practical reasons. Nevertheless, genetic algorithms can often find solutions near the optimal value fairly quickly. Additionally, as previously mentioned, there is usually a region of acceptable candidates. Finally, GAs are highly unlikely to become trapped in a locally optimal solution.</p>
<p>Instead of search iterations, genetic algorithms are counted in <em>generations</em>. A generation is a group of candidate values that are evaluated at the same time (as a batch)<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Once their corresponding performance metrics are computed, a small set of the best candidates is selected and is used to create the next generation via <em>reproduction</em>. Reproduction would entail combining a pair of “parent” candidates by swapping information<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>, and then random mutations can be applied. Once the next generation is created, the process continues for some pre-defined time limit or maximum number of generations.</p>
<p>How, exactly, does this work? The first step is to pick a numerical representation for each candidate. Let’s consider methods for our main types of data.</p>
<section id="real-valued-parameters" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="real-valued-parameters">Real-Valued Parameters</h4>
<p>For real numbers, there are two encoding methods: one option is to keep them as-is (i.e., floating point values) and another converts the values to a binary encoding.</p>
<p>When keeping the values as real numbers, we can make two children from a pair of well-performing candidates via a linear combination. For candidate vectors <span class="math inline">\(\boldsymbol{\theta}_j\)</span>, we can use:</p>
<p><span class="math display">\[
\begin{align}
\boldsymbol{\theta}^{\:kid}_1 &amp;= \alpha \boldsymbol{\theta}^{\:par}_1 + (1 - \alpha) \boldsymbol{\theta}^{\:par}_2 \notag \\
\boldsymbol{\theta}^{\:kid}_2 &amp;= (1-\alpha) \boldsymbol{\theta}^{\:par}_1 + \alpha \boldsymbol{\theta}^{\:par}_2 \notag \\
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is a random standard uniform number. Notice that the two children’s candidate values will always be in-between the values of their parents.</p>
<p>For mutation, a candidate’s values are either locally perturbed or simulated with rate <span class="math inline">\(\pi_m\)</span>. For example, we might mutate the log cost value by simulating a random number across the range that defines its search space.</p>
<p>Binary encodings for real numbers were suggested in the early days of genetic algorithms. In this case, each candidate value is encoded as a set of binary integers. For example, consider a log<sub>2</sub> cost value of -2.34. To convert this to binary, we multiply it by 100 (assuming a limit of two decimal places) to convert it to an integer. If we use 8 binary digits (a.k.a. “bits”) to represent 234, we get <code>11101010</code>. If the candidates could have both positive and negative numbers, we can add an extra bit at the start that is 1 when the value is positive, yielding: <code>011101010</code>.</p>
<p>The method of <em>cross-over</em> was often used for the reproduction of binary representations. For a single cross-over, a random location between digits was created for each candidate value, and the binary digits were swapped. For example, a representation with five bits might have parents <code>ABCDE</code> and <code>VWXYZ.</code> If they were crossed over between the second and third elements, the children would be <code>ABXYZ</code> and <code>VWCDE</code>. There are reproduction methods that use multiple cross-over points to create a more granular sharing of information.</p>
<p>There are systematic bias that can occur when crossing binary representations as described by <span class="citation" data-cites="rana1999distributional">Rana (<a href="#ref-rana1999distributional" role="doc-biblioref">1999</a>)</span> and <span class="citation" data-cites="Soule2009">Soule (<a href="#ref-Soule2009" role="doc-biblioref">2009</a>)</span>. For example, there are positional biases. For example, if the first bits (<code>A</code> and <code>V</code>) capture the sign of the value, the sign is more likely to follow the initial bits than the later bits to an offspring.</p>
<p>For mutating a binary representation, each child’s bit would be flipped at a rate of <span class="math inline">\(\pi_m\)</span>.</p>
<p>After these reproduction and mutation, the values are decoded into real numbers.</p>
</section>
<section id="integer-parameters" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="integer-parameters">Integer Parameters</h4>
<p>For integers, the same approach can be used as real numbers, but after the usual operations, the decimal values are coerced to integers via rounding. If a binary encoding is used, the same process can be used for integers as real numbers; they are all just bits to the encoding process.</p>
</section>
<section id="qualitative-parameters" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="qualitative-parameters">Qualitative Parameters</h4>
<p>For qualitative tuning parameters, one (inelegant) approach is to encode them into values on the real line or as integers. For example, for a parameter with values “red,”, “blue,” and “green”, we could map them to bins of <code>[0, 1/3)</code>, <code>[1/3, 2/3)</code>, and <code>[2/3, 1]</code>. From here, we reproduce and mutate them as described above, then convert them back to their non-numeric categories. This is more palatable when there is a natural ordering of the values but is otherwise a workable but unfortunate approach. Mutation is simple though; at rate <span class="math inline">\(\pi_m\)</span>, a value is flipped to a random selection of the possible values.</p>
</section>
<section id="sec-ga-generations" class="level3" data-number="12.4.1">
<h3 data-number="12.4.1" class="anchored" data-anchor-id="sec-ga-generations"><span class="header-section-number">12.4.1</span> Assembling Generations</h3>
<p>Now that we know how to generate new candidates, we can form new generations. The first step is to determine the population size. Typically, the minimum population size within a generation is 25 to 50 candidates. However, this may be infeasible depending on the computational cost of the model and the characteristics of the training set, such as its size. While fewer candidates can be used, the risk is that we may fail to sample any acceptable results. In such cases, combining the best results will only produce more mediocre candidates. Increasing the mutation rate can help mitigate this issue. For the first iteration, random sampling of the parameter space is commonly used. It is highly recommended to use a space-filling design for the initial candidate set to ensure a more comprehensive exploration.</p>
<p>Finally, there is the choice of which candidates to reproduce at each generation. There are myriad techniques for selecting which candidates are used to make the next generation of candidates. The simplest is to pick two parents by randomly selecting them with probabilities that are proportional to their performance (i.e., the best candidates are chosen most often). There is also the idea of <em>elitism</em> in selection. Depending on the size of the generation, we could retain a few of the best-performing candidates from the previous generation. The performance values of these candidates would not have to be recomputed (saving time), and their information is likely to persist in a few good candidates for the next generation.</p>
</section>
<section id="sec-2D-example" class="level3" data-number="12.4.2">
<h3 data-number="12.4.2" class="anchored" data-anchor-id="sec-2D-example"><span class="header-section-number">12.4.2</span> Two Parameter Example</h3>
<p>To illustrate genetic algorithms in two dimensions, a population size of 8 was used for 7 generations. These values are <em>not</em> optimal defaults but were selected to align with the previous SA search and the optimization method discussed in the next section. The two tuning parameters were kept as floating-point values. Parental selection was based on sampling weights proportional to the RMSE values (with smaller values being better). The mutation rate was set at 10%, and elitism was applied by retaining the best candidate from each generation. All computations within a generation were performed in parallel. On average, the optimization took 17.2s per candidate. <a href="#fig-ga-example" class="quarto-xref">Figure&nbsp;<span>12.4</span></a> illustrates the results of the search.</p>
<div class="columns">
<div class="column" style="width:15%;">

</div><div class="column" style="width:70%;">
<div id="fig-ga-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ga-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="figure-content">
<pre class="shinylive-r" data-engine="r"><code>#| label: shiny-ga-example
#| viewerHeight: 600
#| viewerWidth: "100%"
#| standalone: true
#| fig-alt: A two-dimensional parameter space with axes for the scale parameter and the SVM cost is shown. Eight initial points are shown, one near the ridge of best results. As generations increase, new generations are gathered around the ridge. 
library(shiny)
library(bslib)
library(ggplot2)
library(dplyr)
library(purrr)
library(scales)

source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-setup.R")
source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-ga.R")

app</code></pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ga-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.4: Several generations of a genetic algorithm that search tuning parameter space. The thick diagonal grey light is a ridge where the model has the smallest RMSE. The asterisk denotes the current best candidate.
</figcaption>
</figure>
</div>
</div><div class="column" style="width:15%;">

</div>
</div>
<p>A space-filling design was used to ensure that the initial population was diverse. Fortuitously, one design point was very close to the ridge, with an RMSE of 5.83%. After this, there were 4 generations with better candidates (with almost identical performance): 5.82%, 5.772%, 5.765%, and 5.764%. We can see that, after three generations, the search is concentrated around the ridge of optimal performance. In later generations, some candidates have outliers in one dimension; this is the effect of mutation during reproduction.</p>
</section>
<section id="sec-ga-summary" class="level3" data-number="12.4.3">
<h3 data-number="12.4.3" class="anchored" data-anchor-id="sec-ga-summary"><span class="header-section-number">12.4.3</span> Summary</h3>
<p>This small toy example is not ideal for demonstrating genetic algorithms. The example’s low parameter dimensionality and the relatively low computational cost per candidate might give the impression that genetic algorithms are a universal solution to optimization problems. While genetic algorithms are versatile and powerful tools for global optimization, they come with limitations. Like simulated annealing, they have minimal overhead between generations, but in most real-world applications, there are more than just two parameters. This typically means that larger populations and more generations are needed. If the dataset is not excessively large, parallel processing can help manage the increased computational demands.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<p><a href="https://tidymodels.aml4td.org/chapters/iterative-search.html#sec-genetic-algo"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
<p>Now we’ll take a look at what makes a Bayesian model Bayesian.</p>
</section>
</section>
<section id="sec-bayes" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="sec-bayes"><span class="header-section-number">12.5</span> Sidebar: Bayesian Models</h2>
<p>We’ve superficially described an application of Bayesian analysis in <a href="categorical-predictors.html#sec-effect-encodings" class="quarto-xref"><span>Section 6.4.3</span></a>. Before discussing Bayesian optimization, we should give a general description of Bayesian analysis, especially since it will appear again several times after this chapter.</p>
<p>Many models make probabilistic assumptions about their data or parameters. For example, a linear regression model has the form</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1x_1 + \cdots + \beta_px_p + \epsilon_i
\]</span></p>
<p>Using ordinary least squares estimation, we can make assumptions regarding the model errors (<span class="math inline">\(\epsilon_i\)</span>). We can assume that the residuals are independent of one another and follow a Gaussian distribution with zero mean and a constant standard deviation. From there, it follows that the regression parameters (<span class="math inline">\(\beta\)</span> coefficients) also follow Gaussian distributions.</p>
<p>Based on these assumptions, our objective function is the Gaussian likelihood function, generally denoted as <span class="math inline">\(\ell(z|\theta)\)</span>, although we often maximize the log of this value. We fix the outcome and predictor data and try to find values of <span class="math inline">\(\sigma\)</span> and the <span class="math inline">\(\beta\)</span> parameters that maximize the objective function (log <span class="math inline">\(\ell(z|\theta)\)</span>). This process is maximum likelihood estimation.</p>
<div class="important-box">
<p>One important point is that each model parameter is treated as a single value. Our maximum likelihood estimate (MLE) is a point estimate and, based on our assumptions about the residuals, we know the distribution of the MLEs.</p>
</div>
<p>The consequence of this is that we cannot make inferences about the true, unknown model parameters since they are considered to be single points. Instead, our inference focuses on the MLEs. This leads to the circuitous explanation of hypothesis tests and confidence intervals. For example, the explaination of a 90% confidence interval is:</p>
<blockquote class="blockquote">
<p>“We believe that if we were to repeat this experiment a large number of times, the true parameter value would fall between <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> 90% of the time.”</p>
</blockquote>
<p>A Bayesian approach takes a different perspective on probability assumptions. It assumes that the unknown parameters are drawn from a prior distribution that represents our beliefs or knowledge about them before observing the data. We denote this prior distribution as <span class="math inline">\(\pi(\theta)\)</span>. The term “prior” is crucial because the modeler should define this distribution before seeing the observed data.</p>
<p>For example, consider our model for the time to deliver food in <a href="introduction.html#eq-log-linear" class="quarto-xref">Equation&nbsp;<span>1.1</span></a>. A reasonable prior for the regression parameter associated with distance would have a distribution that assigns zero probability to negative values, since we would never expect (log) delivery times to decrease with distance. If we worked at the restaurant, we could be more specific based on our experience. We might believe that, all other factors being equal, each additional mile from the restaurant doubles the delivery time. Using this assumption, we could define a probability distribution that reflects this belief.</p>
<p>Once we have our prior distributions for our parameters and assumptions regarding our data distributions, we can write down the equations required to estimate our results. Bayes’ Rule is a basic probability statement that combines the prior distribution with our likelihood function:</p>
<p><span id="eq-bayes-rule-distr"><span class="math display">\[
\pi(\theta|x) = \frac{\pi(\theta) \ell(x|\theta)} {\pi(x)}
\tag{12.3}\]</span></span></p>
<p><span class="math inline">\(\pi(\theta|x)\)</span> is the posterior distribution: the probability distribution of our parameters, given the observed data. This is the endpoint for any Bayesian analysis.</p>
<p>Another important point is that Bayesian estimation has a much more difficult goal than maximum likelihood estimation. The latter needs to find point estimates of its parameters while Bayesian estimation has to estimate the entire posterior distribution <span class="math inline">\(\pi(\theta|x)\)</span>. In a moment, we’ll look at a simple problem with a simple solution. However, in most other cases, the computational requirements for Bayesian estimation are considerably higher. That’s the bad news.</p>
<p>The good news is that, once we find the posterior distribution, it is incredibly useful. First, we can make direct statements about parameter values. Unlike confidence intervals, Bayesian methods allow us to say things like</p>
<blockquote class="blockquote">
<p>“We believe that there is a 90% probability that the true value of the parameter is between <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span>.”</p>
</blockquote>
<p>It also lets us easily make similar statements regarding more complex combinations of parameters (such as ratios, etc).</p>
<p>Finally, we should mention the effect of the prior on the computations. It does pull the likelihood <span class="math inline">\(\ell(x|\theta)\)</span> towards it. For example, suppose that for <a href="introduction.html#eq-log-linear" class="quarto-xref">Equation&nbsp;<span>1.1</span></a> we used a highly restrictive prior for <span class="math inline">\(\beta_1\)</span> that was a uniform distribution between [0.7, 0.9]. In that case, the posterior would be confined to this range<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>. That said, the effect of the prior on the posterior <em>decreases</em> as our training set size <em>increases</em>. We saw this in <a href="categorical-predictors.html#sec-effect-encodings" class="quarto-xref"><span>Section 6.4.3</span></a> where two travel agents were contrasted; one with many reservations in the data and another with very few.</p>
<p>To illustrate, let’s look at a very simple example.</p>
<section id="sec-single-proportion" class="level3" data-number="12.5.1">
<h3 data-number="12.5.1" class="anchored" data-anchor-id="sec-single-proportion"><span class="header-section-number">12.5.1</span> A Single Proportion</h3>
<p>For the forestry data discussed earlier in <a href="resampling.html#sec-spatial-resampling" class="quarto-xref"><span>Section 10.8</span></a>, the outcome is categorical, with the values “yes” and “no” representing the question “Is this location forested?” We can use the training dataset to estimate the probability (<span class="math inline">\(\pi\)</span>) of the event occurring. The simplest estimate is the sample proportion, which is calculated by dividing the number of occurrences of the event (e.g., “yes” responses) by the total number of data points. This gives the estimate <span class="math inline">\(\hat{\pi}\)</span> = 56.167%).</p>
<p>To estimate this rate using maximum likelihood estimation, we might assume that the data follow a binomial distribution with theoretical probability <span class="math inline">\(\pi\)</span>. From there we can solve equations that find a value of <span class="math inline">\(\pi\)</span> that correspond to the largest likelihood. It turns out that the sample proportion is also the maximum likelihood estimate.</p>
<p>Instead of treating the unknown parameter as a single value, Bayesian methods propose that the parameter comes from a <em>distribution</em> of possible values. This distribution reflects our prior understanding or belief about the parameter based on what we know of the situation. For this reason, it is called a <em>prior</em> distribution. If we think that locations in Washington state are very likely to be forested, we would choose a distribution that has more area for higher probabilities.</p>
<p>For a binomial model, an example of a prior is the Beta distribution. The Beta distribution is very flexable and has values range between zero and one. It is indexed by two parameters: <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. <a href="#fig-beta-dist" class="quarto-xref">Figure&nbsp;<span>12.5</span></a> shows different versions of the Beta distribution for different values.</p>
<p>To settle on a specific prior, we would posit different questions such as:</p>
<ul>
<li>“Are there rate values that we would <em>never</em> believe possible?”</li>
<li>“What is the most likely value that we would expect and how certain are we of that?”</li>
<li>“Do we think that the distribution of possible values is symmetric?”</li>
</ul>
<p>and so on.</p>
<p>From these answers, we would experiment with different values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> until we find a combination that encapsulates what we believe. If we think that larger probabilities of forestation are more likely, we might choose a Beta prior that has values of <span class="math inline">\(\alpha\)</span> that are larger than <span class="math inline">\(\beta\)</span>, which places more mass on larger values (as seen below). This is an example of an <em>informative prior</em>, albeit a weak one. As our prior distribution is more peaked it reflects that, before seeing any data, we have strong beliefs. If we honestly have no idea, we could choose a uniform distribution between zero and one using <span class="math inline">\(\alpha = \beta = 1\)</span>.</p>
<div class="cell" data-layout-align="center" data-fig-altalt="Three panel plot showing Beta distributions with varying parameters. Left panel (beta=1): curves showing increasing probability density as alpha increases from 1 to 5, with steeper growth near probability=1. Center panel (beta=3): several curves peaking at different points with means near 0.5. Right panel (beta=5): curves skewed left, with peaks shifting leftward as alpha increases. X-axis shows probability of forestation from 0 to 1, Y-axis shows probability density.">
<div class="cell-output-display">
<div id="fig-beta-dist" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-beta-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="iterative-search_files/figure-html/fig-beta-dist-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beta-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.5: Examples of the Beta distribution for different values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We’ll use values of <span class="math inline">\(\alpha = 5\)</span> and <span class="math inline">\(\beta = 3\)</span>. If the training set has <span class="math inline">\(n_{tr}\)</span> points and <span class="math inline">\(n_+\)</span> of them are known to be forested, the ordinary sample proportion estimate is <span class="math inline">\(\hat{p} = n_+ / n_{tr}\)</span>. In a Bayesian analysis, the final estimate is a function of both the prior distribution and our observed data. For a Beta prior, the Bayesian estimate is</p>
<p><span id="eq-beta-bin-mean"><span class="math display">\[
\hat{p}_{BB} = \frac{n_+ +\alpha}{n_{tr} + \alpha + \beta}
\tag{12.4}\]</span></span></p>
<p>If, before seeing the data, we had chosen <span class="math inline">\(\alpha = 5\)</span> and <span class="math inline">\(\beta = 1\)</span>, we estimate that <span class="math inline">\(\hat{p}_{BB} = 56.201\)</span>%. This is pretty close to our simple estimate because there is so much data in the training set (<span class="math inline">\(n_{tr}\)</span> = 4,832) that the influence of the prior is severely diminished. As a counter-example, suppose we took a very small sample that resulted in <span class="math inline">\(n_y\)</span> = 1 and <span class="math inline">\(n_{tr}\)</span> = 3, the prior would pull the estimate from the MLE of 33.3% to 54.5%.</p>
<p>Now suppose that for regulatory purposes, we were required to produce an interval estimate for our parameter. From these data and our prior, we could say that the true probability of forestation has a 90% chance of being between 55% and 57.3%.</p>
<p>We did mention that it can be very difficult to compute the posterior distribution. We deliberately chose the Beta distribution because, if we assume a binomial distribution for our data and a <span class="math inline">\(Beta(\alpha, \beta)\)</span> prior, the posterior is <span class="math inline">\(Beta(\alpha + n_y, n_{tr} - n_y + \beta)\)</span>. More often than not, we will not have a simple analytical solution for the posterior. That said, we’ll see this happen again in <a href="#sec-gp" class="quarto-xref"><span>Section 12.6.2</span></a>.</p>
<p>For a Bayesian model, the predictions also have a posterior <em>distribution</em>, reflecting the probability of a wide range of values. As with non-Bayesian models, we often summarize the posterior using the most likely value (perhaps using the mean or mode of the distribution). We can also measure the uncertainty in the prediction using the estimated standard deviation.</p>
</section>
<section id="sec-freq-and-bayes" class="level3" data-number="12.5.2">
<h3 data-number="12.5.2" class="anchored" data-anchor-id="sec-freq-and-bayes"><span class="header-section-number">12.5.2</span> What is not Bayesian?</h3>
<p>Most other methods fall into the category of “Frequentist.” The terms “Frequentist” and “Bayesian” correspond to different philosophies of interpreting probability. They are not the only two philosophies, but between them, they account for the vast majority of data analytic methods.</p>
<p>Maximum likelihood estimation is a good example of a Frequentist approach. As we said, when training a model, the optimal parameters are the ones that maximize the probability that we actually did get the data that we observed. If we flip a coin 100 times and 90 of them come up heads, MLE would not choose parameter values that are inconsistent with the results from our 100 observed results.</p>
<p>Coin flipping does present a good window into how both philosophies operate. Consider the probability of getting heads when tossing a specific coin. The two points of view are:</p>
<p>Frequentists:</p>
<blockquote class="blockquote">
<p>The probability of being heads is a single unknown value representing the long-term rate at which one would get heads with that coin after infinite tosses. Once we toss the coin, there is no uncertainty. If it is heads, the probability that it is heads is exactly 100%.</p>
</blockquote>
<p>Bayesians:</p>
<blockquote class="blockquote">
<p>The probability of heads is a random variable with an unknown distribution. We can incorporate our beliefs about that distribution into our analyses, often making them somewhat biased. We update our beliefs with data so that our inferences and predictions are a combination of both. We can make direct probabilistic statements about unknown parameters so if a coin was heads, we can still estimate the probability that it <em>would</em> be heads.</p>
</blockquote>
<p>If you are unsure about the tool that you are using, terms like “maximum likelihood estimation”, “confidence intervals”, and “hypothesis testing” should tell you that it takes a Frequentist view. Terms such as “prior,” “posterior,” or “credible interval” are more indicative of a Bayesian methodology.</p>
<p><span class="citation" data-cites="bland1998bayesians">Bland and Altman (<a href="#ref-bland1998bayesians" role="doc-biblioref">1998</a>)</span> and <span class="citation" data-cites="fornacon2022understanding">Fornacon-Wood et al. (<a href="#ref-fornacon2022understanding" role="doc-biblioref">2022</a>)</span> are fairly non-technical discussions of the two camps, while <span class="citation" data-cites="Wagenmakers2008">Wagenmakers et al. (<a href="#ref-Wagenmakers2008" role="doc-biblioref">2008</a>)</span> discusses more mathematical differences. Discussions on this subject can be <em>vigorous</em>. <span class="citation" data-cites="gill2005clinicians">Gill, Sabin, and Schmid (<a href="#ref-gill2005clinicians" role="doc-biblioref">2005</a>)</span>’s discussion of how medical doctors make decisions is interesting and elicited numerous letters to the <em>British Medical Journal</em> <span class="citation" data-cites="mccrossin2005clinicians chitty2005clinicians hutchon2005clinicians">(<a href="#ref-chitty2005clinicians" role="doc-biblioref">Chitty 2005</a>; <a href="#ref-hutchon2005clinicians" role="doc-biblioref">Hutchon 2005</a>; <a href="#ref-mccrossin2005clinicians" role="doc-biblioref">McCrossin 2005</a>)</span>. Others have had pragmatic, if not emphatic, thoughts on the subject <span class="citation" data-cites="breiman1997no">(<a href="#ref-breiman1997no" role="doc-biblioref">Breiman 1997</a>)</span>.</p>
<div class="note-box">
<p>To summarize:</p>
<ul>
<li>Bayesian models require a prior distribution for all of our model parameters.</li>
<li>The prior and observed data are combined into a posterior distribution.</li>
<li>Different statistics can be estimated from the posterior, including individual predictions.<br>
</li>
</ul>
</div>
<p>We’ll encounter even more Bayesian methods in subsequent chapters. For example, in <a href="comparing-models.html" class="quarto-xref"><span>Chapter 14</span></a>, both Frequentist and Bayesian approaches to inference are discussed. In <span class="quarto-unresolved-ref">?sec-cls-metrics</span>, we’ll describe the process of developing a prior for muticlass problem based on Wordle scores and how priors can affect our results.</p>
<p>Now that we know more about Bayesian statistics, let’s see how they can be used to tune models.</p>
</section>
</section>
<section id="sec-bayes-opt" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="sec-bayes-opt"><span class="header-section-number">12.6</span> Bayesian Optimization</h2>
<p>Bayesian optimization (BO) is a search procedure that uses an overarching statistical model to predict the next set of candidate values based on past performance. It is currently the most used iterative search routine for optimizing models. The technique originated with <span class="citation" data-cites="movckus1975bayesian">Močkus (<a href="#ref-movckus1975bayesian" role="doc-biblioref">1975</a>)</span> and was further developed by <span class="citation" data-cites="jones1998efficient">Jones, Schonlau, and Welch (<a href="#ref-jones1998efficient" role="doc-biblioref">1998</a>)</span>. It is often tied to a particular Bayesian predictive model: the Gaussian process (GP) regression model <span class="citation" data-cites="binois2022survey">(<a href="#ref-binois2022survey" role="doc-biblioref">Binois and Wycoff 2022</a>)</span>.</p>
<p>Bayesian optimization and Gaussian proceses have been vibrant research areas and our discussions will scratch the surface. More recent surveys, <span class="citation" data-cites="gramacy2020surrogates">Gramacy (<a href="#ref-gramacy2020surrogates" role="doc-biblioref">2020</a>)</span> and <span class="citation" data-cites="garnett2023">Garnett (<a href="#ref-garnett2023" role="doc-biblioref">2023</a>)</span>, are comprehensive resources for these methodologies.</p>
<p>However, before diving into the details of Gaussian proceseses, we should discuss how any Bayesian method can be used for optimization. Similar to the racing model from <a href="grid-search.html#eq-perf-mod-racing" class="quarto-xref">Equation&nbsp;<span>11.1</span></a>, the Bayesian model’s outcome will be our estimated performance statistic (i.e., <span class="math inline">\(\hat{Q}\)</span>). The predictors for this model will be the tuning parameter values (<span class="math inline">\(\boldsymbol{\theta}\)</span>):</p>
<p><span id="eq-surrogate"><span class="math display">\[
Q_j = f(\boldsymbol{\theta}_j)+ \epsilon_{j}
\tag{12.5}\]</span></span></p>
<p>where <span class="math inline">\(j\)</span> is the iteration number, <span class="math inline">\(f(\cdot)\)</span> is a <em>surrogate model</em>, and <span class="math inline">\(\epsilon\)</span> is an error term. For the barley data, we’ve used RMSE as our primary metric. Using a Bayesian model for <span class="math inline">\(f(\cdot)\)</span> enables us to predict what we expected the RMSE to be for different candidate points.</p>
<p>Since a Bayesian model produces a posterior (predictive) distribution, we can obtain the distribution of the performance metric for a potential new candidate. We often summarize this predictive distribution with the mean and standard deviation. <a href="#fig-two-candidates" class="quarto-xref">Figure&nbsp;<span>12.6</span></a> shows two hypothetical candidates and their respective predictive distributions. The first candidate has a slightly better predicted RMSE (on average). The area under the distribution curve to the right of the vertical line reflects the probability of being worse than the current solution which, for this candidate, is 16%.</p>
<div class="cell" data-layout-align="center" data-fig-altalt="Line graph comparing two candidates' performance distributions across RMSE values (ranging from 3 to 9). Candidate 1 shows a wider, flatter curve centered around RMSE of 5.75, while Candidate 2 displays a narrow, tall peak at an RMSE of 5.5. A vertical dashed line marks the 'Current best' position at an RMSE of 6.0.">
<div class="cell-output-display">
<div id="fig-two-candidates" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-two-candidates-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="iterative-search_files/figure-html/fig-two-candidates-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:55.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-two-candidates-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.6: An example of a choice between two candidates where performance is gauged by RMSE. One candidate has slightly better predicted mean performance and another where the mean RMSE is predicted to be much lower but with high uncertainty.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The second candidate has a mean RMSE that is predicted to have about a 2-fold improvement over the first but comes with considerably large uncertainty. On average, this is a better choice but there is more area to the right of the vertical line. The probability of the second candidate having worse results than the current best is 26%.</p>
<p>Which option is better? The first candidate is a safer choice, while the second comes with higher risk but also a greater potential reward. The decision often depends on our perspective. However, it’s important to understand why the second candidate has such a large variance in outcomes.</p>
<p>We’ve previously discussed the variance-bias tradeoff and demonstrated that large uncertainty in the performance metric can often be explained by <em>model variance</em>. Recall that models might vary due to predictive instability caused by a model that is far more complex than is required, such as the polynomial example in <a href="interactions-nonlinear.html#sec-variance-bias" class="quarto-xref"><span>Section 8.4</span></a>.</p>
<p>However, there is another reason that the noise in our performance statistic can be large. Back in <a href="initial-data-splitting.html#sec-spatial-splitting" class="quarto-xref"><span>Section 3.9</span></a>, we described <em>spatial autocorrelation</em>, where objects are more similar to closer objects than to objects further away. If our Bayesian model reflects spatial variability, the increased uncertainty can be attributed to how each candidate relates spatially to the existing set. If our model’s variance in <a href="#fig-two-candidates" class="quarto-xref">Figure&nbsp;<span>12.6</span></a> is based on spatial effects, it implies that the first candidate is closer to the current collection of tuning parameter candidates. Conversely, the large uncertainty for the second candidate suggests that it is placed far away from existing results.</p>
<p>This example illustrates two different search strategies: <em>exploitation</em> and <em>extrapolation</em>.</p>
<ul>
<li><p>Exploitation involves focusing the search near existing data, leveraging known results to refine and optimize solutions within familiar territory.</p></li>
<li><p>Extrapolation emphasizes exploring new, untested areas more aggressively in search of novel candidates that could lead to model improvements.</p></li>
</ul>
<p>Using the Bayesian model in <a href="#eq-surrogate" class="quarto-xref">Equation&nbsp;<span>12.5</span></a> is beneficial because it allows for both mean and variance predictions, which can be weighted differently when evaluating potential new candidates. If our surrogate Bayesian model effectively captures spatial effects, we can leverage this to optimize the model. The next section outlines the overall optimization process.</p>
<section id="sec-acquisition" class="level3" data-number="12.6.1">
<h3 data-number="12.6.1" class="anchored" data-anchor-id="sec-acquisition"><span class="header-section-number">12.6.1</span> How Does Bayesian Optimization Work?</h3>
<p>The search process begins with an initial set of candidates (<span class="math inline">\(s_0\)</span>) and their corresponding performance statistics (_j$). These data are used to build a surrogate model, where the performance metric serves as the outcome and the candidate values act as predictors. The model then predicts the mean and standard deviation of the metric for new candidate values.</p>
<p>To guide the search, we use an <em>acquisition function</em>—an objective function that combines the predicted mean and standard deviation into a single value <span class="citation" data-cites="garnett2023">(<a href="#ref-garnett2023" role="doc-biblioref">Garnett 2023, chap. 7</a>)</span>. The next candidate to be evaluated is the one that optimizes this acquisition function. This process is then repeated iteratively.</p>
<p>One of the most well-known acquisition functions is based on the notion of <strong>expected improvement</strong> <span class="citation" data-cites="jones1998efficient">(<a href="#ref-jones1998efficient" role="doc-biblioref">Jones, Schonlau, and Welch 1998, sec. 4</a>)</span>. If the current best metric value is denoted as <span class="math inline">\(\hat{Q}_{opt}\)</span>, the expected improvement is the positive part of <span class="math inline">\(\delta(\hat{\boldsymbol{\theta}}) = Q_{opt} - \mu(\hat{\boldsymbol{\theta}})\)</span>, where <span class="math inline">\(\mu(\hat{\boldsymbol{\theta}})\)</span> is the mean of the posterior prediction (assuming that smaller metrics are better). They found that, probabilistically, the expected improvement is</p>
<p><span id="eq-exp-improve"><span class="math display">\[
EI(\hat{\boldsymbol{\theta}}; Q_{opt}) = \delta(\hat{\boldsymbol{\theta}}) \Phi\left(\frac{\delta(\hat{\boldsymbol{\theta}})}{\sigma(\hat{\boldsymbol{\theta}})}\right) + \sigma(\hat{\boldsymbol{\theta}}) \phi\left(\frac{\delta(\hat{\boldsymbol{\theta}})}{\sigma(\hat{\boldsymbol{\theta}})}\right)
\tag{12.6}\]</span></span></p>
<p>where <span class="math inline">\(\Phi(\cdot)\)</span> is the cumulative standard normal and <span class="math inline">\(\phi(\cdot)\)</span> is the standard normal density.</p>
<p>Expected improvement balances both mean and variance, but their influence can shift throughout the optimization process. Consider a parameter space where most regions have already been sampled to some extent. If the Bayesian model is influenced by spatial variation, the remaining unexplored areas will generally have low variance (<span class="math inline">\(\sigma\)</span>), causing one term in <a href="#eq-exp-improve" class="quarto-xref">Equation&nbsp;<span>12.6</span></a> to dominate the optimization. In contrast, during the early iterations, variance tends to be much higher. Unless there is a strong mean effect, spatial variance will dominate, leading the search to focus more on extrapolation.</p>
<p>Additionally, the expected improvement can be altered to include a tradeoff factor <span class="math inline">\(\xi\)</span> so that improvement is the positive part of</p>
<p><span class="math display">\[
\delta(\hat{\boldsymbol{\theta}}) = Q_{opt} - \mu(\hat{\boldsymbol{\theta}}) + \xi
\]</span></p>
<p>This effectively inflates the value of the current best and the resulting value of <span class="math inline">\(\delta(\hat{\boldsymbol{\theta}})\)</span> helps emphasize extrapolation. <span class="math inline">\(\xi\)</span> could be a single constant or a function that changes the tradeoff value as a function of iterations.</p>
<p>Similar to simulated annealing, sampling continues until reaching a predefined limit on iterations or computational time. Additionally, an early stopping rule can be used to end the search early if no new best result is found within a set number of iterations.</p>
<p>Let’s see how this approach works in a single dimension. <a href="#fig-bo-example" class="quarto-xref">Figure&nbsp;<span>12.8</span></a> shows how expected improvement can be used to find the global minimum of <span class="math inline">\(\psi(\theta) = \theta\: cos(\theta/2)\)</span>. The light grey line in the lower panel represents the true value of <span class="math inline">\(\psi(\theta)\)</span> across the parameter space. The process starts with <span class="math inline">\(s_0 = 2\)</span> candidate points at -8.0 and 3.0. From these two points, the surrogate model is fit and the dark line in the lower panel shows the predicted objective function values across the space. The magnitude of the line represents the mean of the posterior. Notice that the predicted line fails to capture the true trend, which is not unexpected with two data points.</p>
<p>If we optimized only on the mean prediction, we would select the next point near <span class="math inline">\(\theta = 3\)</span> since it has the lowest predicted value. This approach relies entirely on exploitation.</p>
<p>The color of the line depicts the predicted variance, which drops to zero near the existing points and explodes in the regions in between our two points. If we focused solely on the variance of the objective function, we would choose the next point in an area far from the two sampled points, such as the interval <span class="math inline">\(-6 \le \theta \le 1\)</span> or <span class="math inline">\(\theta \ge 4\)</span>.</p>
<p>By combining the mean and variance predictions through expected improvement, we strike a balance between the two. In the first iteration, two areas near (but not exactly at) <span class="math inline">\(\theta = 3.0\)</span> are predicted to have large expected improvements. The region on the left is sampled first, and once <span class="math inline">\(\psi(\theta = 3)\)</span> is evaluated, the next point moves closer to the true global optimum. This process continues, alternating between sampling near the best result and exploring regions with few nearby candidate values. After 15 iterations, the search is very close to the true global optimum.</p>
<div id="fig-bayes-opt" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bayes-opt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="figure-content">
<pre class="shinylive-r" data-engine="r"><code>#| label: shiny-bayes-opt
#| viewerHeight: 600
#| viewerWidth: "100%"
#| standalone: true
#| fig-alt: A single curve is shown with alternating peaks and valleys. The x-axis is the parameter, and the y-axis shows the objective function. Above this is another curve where the y-axis is expected improvement. As the optimization proceeds, the top curve shows several peaks of expected improvement, and the candidate points begin to cluster around the global minimum. 
library(shiny)
library(bslib)
library(ggplot2)
library(patchwork)
library(dplyr)

load(url("https://raw.githubusercontent.com/aml4td/website/main/RData/bayesian_opt_1d.RData"))

source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-setup.R")
source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-bo-1d.R")

app</code></pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bayes-opt-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.7: An example of Bayesian optimization for the function <span class="math inline">\(\psi(\theta) = \theta\: cos(\theta/2)\)</span>. The top plot shows the expected improvement for the current iteration. The bottom panel shows the true curve in grey and the mean prediction line (colored by the predicted standard deviation). The vertical line indicates the location of the next candidate.
</figcaption>
</figure>
</div>
<p>Numerous other acquisition functions can be used. For example, instead of expected improvement, we can maximize the probability of improvement:</p>
<p><span class="math display">\[
PI(\hat{\boldsymbol{\theta}}) = \Phi\left(\frac{\tau - \mu(\hat{\boldsymbol{\theta}})}{\sigma(\hat{\boldsymbol{\theta}})}\right)
\]</span></p>
<p>where <span class="math inline">\(\tau\)</span> is some performance metric goal (e.g., an <em>R</em><sup>2</sup> of 80%). This is generally deprecated in favor of EI for a few reasons. Most importantly, PI does not directly incorporate the current best value. Additionally, the value of <span class="math inline">\(\tau\)</span> is arbitrary and the search can be inconsistent across values of <span class="math inline">\(\tau\)</span> <span class="citation" data-cites="jones2001taxonomy">(<a href="#ref-jones2001taxonomy" role="doc-biblioref">Jones 2001</a>)</span>.</p>
<p>Another acquisition function is based on confidence bounds <span class="citation" data-cites="cox1992statistical">(<a href="#ref-cox1992statistical" role="doc-biblioref">Cox and John 1992</a>)</span>. For minimizing the performance statistic, the lower bound would be computed:</p>
<p><span class="math display">\[
CB(\hat{\boldsymbol{\theta}}) = \mu(\hat{\boldsymbol{\theta}}) - \kappa\: \sigma(\hat{\boldsymbol{\theta}})
\]</span></p>
<p>where <span class="math inline">\(\kappa\)</span> sets the confidence level and often has values that are <em>much</em> smaller than range used for statistical inference (e.g., centered around 1.64). This multiplier also modulates between extrapolation (large <span class="math inline">\(\kappa\)</span>) and exploitation (small <span class="math inline">\(\kappa\)</span>) for the search.</p>
<p>Bayesian optimization offers more than just different acquisition functions; there are also various other modifications that can enhance its efficiency. For instance, similar to simulated annealing, the default approach samples one candidate at a time. While this works, it can be computationally inefficient, especially when models can be fitted in parallel. To improve this, modifications allow for multiple candidates to be <em>simulated</em> at once. In this approach, the candidate with the highest predicted acquisition value is chosen, and its predicted performance is treated as if it were derived from an actual assessment. A new GP model is then created using this imputed data point, and the process continues by acquiring the next point. This cycle repeats until the desired number of new candidates is obtained (see <span class="citation" data-cites="azimi2010batch">Azimi, Fern, and Fern (<a href="#ref-azimi2010batch" role="doc-biblioref">2010</a>)</span>). Alternatively, we can focus on the most promising areas of the parameter space and sample several different points. For example, in iteration five of <a href="#fig-bayes-opt" class="quarto-xref">Figure&nbsp;<span>12.7</span></a>, where there are three peaks showing improvement, we could sample each of these peaks and create a batch of three new candidates to evaluate all at once, rather than individually.</p>
<p>Now that the general optimization process has been outlined, let’s focus on the most popular model associated with Bayesian optimization.</p>
</section>
<section id="sec-gp" class="level3" data-number="12.6.2">
<h3 data-number="12.6.2" class="anchored" data-anchor-id="sec-gp"><span class="header-section-number">12.6.2</span> Gaussian Process Models</h3>
<p>GPs <span class="citation" data-cites="williams2006gaussian garnett2023">(<a href="#ref-williams2006gaussian" role="doc-biblioref">Williams and Rasmussen 2006</a>; <a href="#ref-garnett2023" role="doc-biblioref">Garnett 2023</a>)</span> are often motivated as special cases of stochastic processes, which are the collection of random variables that are indexed by one or more variables. The most common example of a stochastic process is the stock market. A stock price is a random variable that is indexed by time. A Gaussian process is just a stochastic process whose data are assumed to be multivariate normal.</p>
<p>Gaussian processes are different from basic multivariable normal distributions. Let’s say that we collected the heights and weights of 100 students in a specific grade. If we collect the heights and weights into a two-dimensional vector <span class="math inline">\(\boldsymbol{x} = [height, weight]\)</span>, we might assume that the data is multivariate normal, with a 2D population mean <em>vector</em> and a 2 <span class="math inline">\(\times\)</span> 2 covariance matrix, i.e., <span class="math inline">\(\boldsymbol{x} \sim N(\boldsymbol{\mu}, \Sigma)\)</span>. In this case, the data are a sample of people at a static time point.</p>
<p>However, a Gaussian process is a <strong>sequence of data</strong> so we have to specify their means and covariances dynamically; there are mean and covariance <em>functions</em> instead of vectors and matrices. The mean function is often denoted as <span class="math inline">\(\mu(\boldsymbol{x})\)</span>. One way of writing the covariance function is <span class="math inline">\(\Sigma(\boldsymbol{x}, \boldsymbol{x}') = k(\boldsymbol{x}, \boldsymbol{x}') + \sigma^2_{\epsilon}I\)</span> where <span class="math inline">\(k(\cdot, \cdot)\)</span> is a <strong>kernel function</strong> and <span class="math inline">\(\sigma_{\epsilon}\)</span> is a constant error term.</p>
<p>We’ve seen kernels before, back in <a href="#eq-kernel-poly" class="quarto-xref">Equation&nbsp;<span>12.1</span></a> when they were associated with support vector machine models. For Gaussian processes, the kernel will define the variance between two data points in the process. Some kernels can be written as a function of the difference <span class="math inline">\(\delta_{ii'} = ||\boldsymbol{x} - \boldsymbol{x}'||\)</span>. A common kernel is the squared exponential:</p>
<p><span id="eq-kernel-sq-expo"><span class="math display">\[
k(\boldsymbol{x}, \boldsymbol{x}') = \exp\left(-\sigma d_{ii'}^2 \right)
\tag{12.7}\]</span></span></p>
<p>Note that this covariance function has it’s own parameter <span class="math inline">\(\sigma\)</span>, similar to <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(q\)</span> in <a href="#eq-kernel-poly" class="quarto-xref">Equation&nbsp;<span>12.1</span></a> (<span class="math inline">\(\sigma\)</span> is unrelated to <span class="math inline">\(\sigma_{\epsilon}\)</span>).</p>
<p>The squared exponential function shows that as the two vectors become more different from one another (i.e., further away), the exponentiated difference becomes large, indicating high variance (apart from <span class="math inline">\(\sigma^2_{\epsilon}\)</span>). For two identical vectors, this covariance function yields a variance of <span class="math inline">\(\sigma^2_{\epsilon}\)</span>. Now, we can see why the previous section had a strong emphasis on spatial variability for Bayesian optimization. <a href="#fig-bayes-opt" class="quarto-xref">Figure&nbsp;<span>12.7</span></a> used this kernel function.</p>
<p>A more general covariance function uses the Matern kernel:</p>
<p><span id="eq-kernel-matern"><span class="math display">\[
k_{\nu }(\delta_{ii'})=
{\frac {2^{1-\nu }}{\Gamma (\nu )}}{\Bigg (}{\sqrt {2\nu }}{\frac {\delta_{ii'}}{\rho }}{\Bigg )}^{\nu }\mathcal{K}_{\nu }{\Bigg (}{\sqrt {2\nu }}{\frac {\delta_{ii'}}{\rho }}{\Bigg )}
\tag{12.8}\]</span></span></p>
<p>where <span class="math inline">\(\mathcal{K}(\cdot)\)</span> is the Bessel function, <span class="math inline">\(\Gamma(\cdot)\)</span> is the Gamma function, and <span class="math inline">\(\rho\)</span> and <span class="math inline">\(\nu\)</span> are tuning parameters.</p>
<p>So far, our covariance functions have assumed that all tuning parameters are numeric. A common, though simplistic, approach for incorporating qualitative parameters into a Gaussian process is to convert them into binary indicators and treat them as generic numeric predictors. However, this method is problematic because it’s unlikely that these binary indicators follow a Gaussian distribution. Additionally, if the qualitative tuning parameters have many levels, this approach can rapidly increase the dimensionality of the Gaussian space, which in turn raises the computational costs of training the GP model.</p>
<p>Alternatively, special “categorical kernels” take integers corresponding to levels of a categorical predictor as inputs. For example, one based on an exchangeable correlation structure is:</p>
<p><span id="eq-kernel-categorical"><span class="math display">\[
k(x, x') = \rho I(x \ne x') + I(x = x')
\tag{12.9}\]</span></span></p>
<p>where <span class="math inline">\(\rho &lt; 1\)</span> <span class="citation" data-cites="joseph2007functionally">(<a href="#ref-joseph2007functionally" role="doc-biblioref">Joseph and Delaney 2007</a>)</span>. More extensive discussions of models with <em>mixed types</em> can be found in <span class="citation" data-cites="qian2008bayesian">Qian and Wu (<a href="#ref-qian2008bayesian" role="doc-biblioref">2008</a>)</span>, <span class="citation" data-cites="zhou2011simple">Zhou, Qian, and Zhou (<a href="#ref-zhou2011simple" role="doc-biblioref">2011</a>)</span>, and <span class="citation" data-cites="saves2023mixed">Saves et al. (<a href="#ref-saves2023mixed" role="doc-biblioref">2023</a>)</span>.</p>
<p>Multiple kernels can be used to accommodate a pipeline with both quantitative and qualitative tuning parameters. Depending on the situation, an overall kernel can be created via addition or multiplication.</p>
<p><span class="citation" data-cites="genton2001classes">Genton (<a href="#ref-genton2001classes" role="doc-biblioref">2001</a>)</span>, Part II of <span class="citation" data-cites="cristianini2004">Shawe-Taylor and Cristianini (<a href="#ref-cristianini2004" role="doc-biblioref">2004</a>)</span>, and Chapter 4 of <span class="citation" data-cites="garnett2023">Garnett (<a href="#ref-garnett2023" role="doc-biblioref">2023</a>)</span> contain overviews of kernel functions, their different classes, and how they can be used and combined for data analysis.</p>
<p>How does this relate to iterative tuning parameter optimization? Suppose that our multivariate random variable is the concatenation of an outcome variable and one or more predictors, our vector of random variable could be thought of as <span class="math inline">\(\boldsymbol{d} = [y, x_1, ..., x_p]\)</span>. In a model, we’d like to predict the value of <span class="math inline">\(y\)</span> is for a specific set of <span class="math inline">\(x\)</span> values. Mathematically, this is <span class="math inline">\(Pr[y | \boldsymbol{x}]\)</span> and, since this collection of data is multivariate normal, there are some nice linear algebra equations that can be used to compute this. This ties into Bayesian analysis since we can write <a href="#eq-bayes-rule-distr" class="quarto-xref">Equation&nbsp;<span>12.3</span></a> in terms of probabilities:</p>
<p><span id="eq-bayes-rule"><span class="math display">\[
Pr[y | \boldsymbol{x}] = \frac{Pr[y] Pr[\boldsymbol{x} | y]}{Pr[\boldsymbol{x}]} = \frac{(prior)\times (likelihood)}{(evidence)}
\tag{12.10}\]</span></span></p>
<p>The GP model is Bayesian because we have specified the distributions for the outcome and predictors (<span class="math inline">\(Pr[y]\)</span> and <span class="math inline">\(Pr[\boldsymbol{x}]\)</span>, respectively) simultaneously. The kernel function is the primary driver of the prior distribution of Gaussian processes.</p>
<p><em>In theory</em>, each of these is easy to compute with a simple multivariate normal. However, we don’t know the value of <span class="math inline">\(\sigma^2_{\epsilon}\)</span> nor do we know the values of any kernel parameters used by <span class="math inline">\(k(\cdot,\cdot)\)</span>. The error term can be estimated a variety of ways, including maximum likelihood, cross-validation, and others (see <span class="citation" data-cites="ameli2022noise">Ameli and Shadden (<a href="#ref-ameli2022noise" role="doc-biblioref">2022</a>)</span> for a survey of methods). For the kernel tuning parameters, it is common to maximize the marginal likelihood to estimate these structural parameters <span class="citation" data-cites="williams2006gaussian">(<a href="#ref-williams2006gaussian" role="doc-biblioref">Williams and Rasmussen 2006, chap. 5</a>)</span>. The Gaussian nature of this model enables a number of relatively straightforward procedures for these purposes (that does not involve another layer of resampling).</p>
<p>Howver, training Gaussian process models can be difficult and the computation cost of training these models increases <em>cubically</em> with the number of data points. In our application, the training set size is the number of tuning parameter candidates with performance statistics. However, after the initial GP model has been trained, there are updating algorithms that can prevent the model from being completely re-estimated from scratch thus reducing training time.</p>
<div class="note-box">
<p>In summary, Gaussian process models are nonlinear models that can use tuning parameter values to make predictions on future performance statistics. They can predict the mean and variance of performance, the latter being mostly driven by spatial variability.</p>
</div>
<p>In <a href="#fig-bayes-opt" class="quarto-xref">Figure&nbsp;<span>12.7</span></a> we’ve seen how well Bayesian optimization works for a simple one-dimensional function. Let’s apply it in context by using it to optimize our two SVM tuning parameters.</p>
</section>
<section id="sec-ba-2D" class="level3" data-number="12.6.3">
<h3 data-number="12.6.3" class="anchored" data-anchor-id="sec-ba-2D"><span class="header-section-number">12.6.3</span> A Two Dimensional Illustration</h3>
<p>Returning the the SVM example, we initialize the GP model using the same three points shown in <a href="#tbl-svm-initial" class="quarto-xref">Table&nbsp;<span>12.1</span></a>. We again use the squared exponential kernel in <a href="#eq-kernel-sq-expo" class="quarto-xref">Equation&nbsp;<span>12.7</span></a> to measure variability.</p>
<p><a href="#fig-bo-example" class="quarto-xref">Figure&nbsp;<span>12.8</span></a> shows the results that help us select the first new candidate value. Due to the small number of points used to fit the GP, the EI surface is virtually flat. The flatness of the acquisition function results in a fairly uninformative choice: the first point is very close to the best candidate in the initial set.</p>
<p>Once this new point is sampled, the surrogate GP model produces a clear trend in EI indicating a strong preference for higher cost values (and no effect of the scale parameter). The selected candidate is closer to the ridge of optimal performance. After acquiring this point, the next iteration shows that EI is focused on the scale parameter value and ignores the cost parameter. By iteration 13, a candidate is chosen that is nearly optimal.</p>
<p>This example shows that Bayesian optimization can make enormous leaps in parameter space, frequently choosing values of parameters at their minimum or maximum values. This is the opposite of SA, which meanders through local parameter space.</p>
<div class="columns">
<div class="column" style="width:15%;">

</div><div class="column" style="width:70%;">
<div id="fig-bo-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bo-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="figure-content">
<pre class="shinylive-r" data-engine="r"><code>#| label: shiny-bo-example
#| viewerHeight: 630
#| viewerWidth: "100%"
#| standalone: true
#| fig-alt: A two-dimensional parameter space with axes for the scale parameter and the SVM cost is shown. Three initial points are shown. The BO algorithm progresses from a point with low cost and a large scale factor value, making large jumps to different regions of the parameter space; several iterations come close to the optimal ridge. 
library(shiny)
library(bslib)
library(ggplot2)
library(dplyr)
library(purrr)
library(scales)

source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-setup.R")
source("https://raw.githubusercontent.com/aml4td/website/main/R/shiny-bo.R")

app</code></pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bo-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.8: An illustration of Bayesian optimization. The open circles represent a small initial grid. The thick diagonal grey light is a ridge where the model has the smallest RMSE. The asterisk denotes the current best candidate.
</figcaption>
</figure>
</div>
</div><div class="column" style="width:15%;">

</div>
</div>
<p>The complete search produced new optimal values at iterations iterations 4, 9, 13, 42, and 44. The decrease in RMSE shows few meaningful improvements among negligible decreases: 6.098%, 5.993%, 5.947%, 5.773%, 5.771%, and 5.77%. The search process was able to effectively tune the SVM model and find very good parameters.</p>
<p>The cost of the Gaussian process fit does become more expensive as new candidates are sampled, making the process somewhat less efficient than the previous approaches. The average time to compute each candidate was 56.2s, although the cost of each increases with iterations.</p>
<p><a href="https://tidymodels.aml4td.org/chapters/iterative-search.html#sec-bayes-opt"><i class="fa-brands fa-r-project fa-Large" aria-label="r-project"></i></a></p>
</section>
</section>
<section id="sec-bayes-opt-nnet" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="sec-bayes-opt-nnet"><span class="header-section-number">12.7</span> Example: Tuning a Neural Network</h2>
<p>We revisit the barley data, where the percentage of barley oil in a mixture is estimated using spectrographic measurements. Our previous work on these data addressed the high correlation between predictors via feature engineering with principal components.</p>
<p>In this chapter, we’ll take a more sophisticated approach to preprocessing this type of data using signal processing techniques, specifically the <strong>Savitzky-Golay</strong> (SG) method <span class="citation" data-cites="Schafer2011 rinnan2009review">(<a href="#ref-rinnan2009review" role="doc-biblioref">Rinnan, Van Den Berg, and Engelsen 2009</a>; <a href="#ref-Schafer2011" role="doc-biblioref">Schafer 2011</a>)</span>. This technique incorporates two main goals: to smooth the data from location to location (i.e., across the x-axis in <a href="embeddings.html#fig-barley-data" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>(b)) and to difference the data. Smoothing attempts to reduce measurement noise without diminishing the data patterns that could predict the outcome. Differencing can remove the correlation between locations and might also mitigate other issues, such as systematic background noise.</p>
<p>For smoothing, the SG procedure uses a moving window across a sample’s location and, within each window, uses a polynomial basis expansion to produce a smoother representation of the data. The window width and the polynomial degree are both tuning parameters.</p>
<p>Differencing has a single tuning parameter: the difference order. A zero-order difference leaves the data as-is (after smoothing). A first-order difference is the smoothed value minus the smoothed value for the next location (and so on). Savitzky and Golay’s method uses the polynomial estimates to estimate the differences/derivatives, instead of manually subtracting columns after smoothing.</p>
<p><a href="#fig-savitzky-golay" class="quarto-xref">Figure&nbsp;<span>12.9</span></a> shows an example of a small set of locations from a single spectra in <a href="embeddings.html#fig-barley-data" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>. The top row shows the effect of smoothing when differencing is not used. For a linear smoother (i.e., a polynomial degree of one), the process can over-smooth the data such that the nonlinear portions of the raw data lose significant amounts of information. This issue goes away as the polynomial order is increased. However, the higher degree polynomial nearly interpolates between data points and may not be smoothing the data in any meaningful way.</p>
<p>The bottom panel shows the data when a first-order difference is used. The pattern is completely different since the data now represent the rate of change in the outcome rather than the absolute measurement. Again, larger window sizes oversmooth the data, and the highest degree of polynomial provides minimal smoothing.</p>
<div class="cell" data-layout-align="center" data-fig-altalt="Six panel figure showing Savitzky-Golay smoothing analysis of spectral data. Top row displays original values with fitted curves for polynomial degrees 1, 2, and 5 (windows: 3, 7, 11). Bottom row shows corresponding first differences. Each panel plots wavelength against signal intensity, demonstrating increasing smoothing complexity across polynomial degrees.">
<div class="cell-output-display">
<div id="fig-savitzky-golay" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-savitzky-golay-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="iterative-search_files/figure-html/fig-savitzky-golay-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-savitzky-golay-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.9: Demonstrations of the Savitzky-Golay preprocessing method for a small region for one specific sample previously shown in <a href="embeddings.html#fig-barley-data" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We’ll want to optimize these preprocessing parameters simultaneously with the parameters for the supervised model. With this example, the supervised model of choice is a neural network with a single layer of hidden units. We’ll tune over the following parameters, described at length in <span class="quarto-unresolved-ref">?sec-cls-nnet</span>:</p>
<ul>
<li>The number of hidden units in the layer (2 to 100).</li>
<li>The type of nonlinear function that connects the input layer and the hidden layer, called the “activation function”. Possible functions are “tanh”, exponential linear unit (“ELU”) functions, rectified linear unit (“ReLU”) functions, and log-sigmoidal functions.</li>
<li>The number of epochs of degraded performance before early stopping is enacted (3 to 20).</li>
<li>The total amount of penalization for the model (-10 to 0, in log-10 units).</li>
<li>The proportion of <span class="math inline">\(L_1\)</span> penalty (a.k.a. Lasso penalization) (0 to 1).</li>
<li>The initial learning rate used during gradient descent (-2 to -0.5, in log-10 units).</li>
<li>The “scheduling” function to adjust the learning rate over iterations: “constant”, “cyclic”, or “exponential decay”.</li>
</ul>
<p>In all, there are ten tuning parameters, two of which are qualitative.</p>
<p>A space-filling design with 12 candidate points were initially processed to use as the starting point for Bayesian optimization and simulated annealing. When constructing the grid, there are two constraints on the preprocessing parameters:</p>
<ul>
<li>The smoothing polynomial degree must be greater or equal to the differentiation order.</li>
<li>The window size must be greater than the polynomial degree.</li>
</ul>
<p>An initial grid was created without constraints, and candidates who violated these rules were eliminated. The two constraints will also be applied when simulated annealing and Bayesian optimization create new candidates.</p>
<p><a href="#tbl-nnet-initial" class="quarto-xref">Table&nbsp;<span>12.2</span></a> shows the settings and their corresponding validation set RMSE values, which ranged between 4.3% and 14.4%. At least two of the settings show good performance results, especially compared to the RMSE values previously achieved when embeddings and/or SVMs were used.</p>
<div id="tbl-nnet-initial" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-nnet-initial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="table-responsive">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">RMSE (%)</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Window</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Diff. Order</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Degree</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Units</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Penalty (log-10)</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Activation</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Learn Rate (log-10)</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Rate Schedule</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Stop Iter.</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">L1 Mixture</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">4.32</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">27</td>
<td style="text-align: right;">-7.89</td>
<td style="text-align: left;">elu</td>
<td style="text-align: right;">-1.84</td>
<td style="text-align: left;">none</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">42.11</td>
</tr>
<tr class="even">
<td style="text-align: right;">4.57</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">84</td>
<td style="text-align: right;">-9.47</td>
<td style="text-align: left;">tanh</td>
<td style="text-align: right;">-0.82</td>
<td style="text-align: left;">decay</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">31.58</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4.72</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">-2.63</td>
<td style="text-align: left;">tanh</td>
<td style="text-align: right;">-1.45</td>
<td style="text-align: left;">none</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">5.26</td>
</tr>
<tr class="even">
<td style="text-align: right;">4.87</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">69</td>
<td style="text-align: right;">-5.79</td>
<td style="text-align: left;">elu</td>
<td style="text-align: right;">-1.29</td>
<td style="text-align: left;">decay</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0.00</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4.91</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">-7.37</td>
<td style="text-align: left;">elu</td>
<td style="text-align: right;">-1.05</td>
<td style="text-align: left;">cyclic</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">94.74</td>
</tr>
<tr class="even">
<td style="text-align: right;">5.88</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">79</td>
<td style="text-align: right;">-6.84</td>
<td style="text-align: left;">relu</td>
<td style="text-align: right;">-1.92</td>
<td style="text-align: left;">cyclic</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">73.68</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6.16</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">94</td>
<td style="text-align: right;">-3.68</td>
<td style="text-align: left;">elu</td>
<td style="text-align: right;">-1.21</td>
<td style="text-align: left;">decay</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">10.53</td>
</tr>
<tr class="even">
<td style="text-align: right;">6.47</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">38</td>
<td style="text-align: right;">-5.26</td>
<td style="text-align: left;">log sigmoid</td>
<td style="text-align: right;">-0.74</td>
<td style="text-align: left;">cyclic</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">15.79</td>
</tr>
<tr class="odd">
<td style="text-align: right;">7.01</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">-6.32</td>
<td style="text-align: left;">tanh</td>
<td style="text-align: right;">-1.37</td>
<td style="text-align: left;">decay</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">89.47</td>
</tr>
<tr class="even">
<td style="text-align: right;">7.72</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">53</td>
<td style="text-align: right;">-1.58</td>
<td style="text-align: left;">log sigmoid</td>
<td style="text-align: right;">-0.50</td>
<td style="text-align: left;">none</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">78.95</td>
</tr>
<tr class="odd">
<td style="text-align: right;">10.57</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">-0.53</td>
<td style="text-align: left;">elu</td>
<td style="text-align: right;">-1.68</td>
<td style="text-align: left;">decay</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">68.42</td>
</tr>
<tr class="even">
<td style="text-align: right;">14.38</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">58</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: left;">relu</td>
<td style="text-align: right;">-1.53</td>
<td style="text-align: left;">cyclic</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">52.63</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-nnet-initial-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.2: The initial set of candidates used for iterative search methods.
</figcaption>
</figure>
</div>
<p>Can we improve on these results using iterative optimization? To begin, a simulated annealing search was initialized using the best results in <a href="#tbl-nnet-initial" class="quarto-xref">Table&nbsp;<span>12.2</span></a> and ran for 50 iterations with no early stopping. If a new globally best result was not found within eight iterations, the search restarted from the previously best candidate. The search was restarted 3 times at iterations 15, 31, and 47 and improved candidates were found at iterations 2, 7, 23, 39. The overall best candidate had an RMSE value of 3.65%, with a 90% confidence interval of (3.41%, 3.9%). The improvement appears to be a legitimate improvement over the initial best configuration. The top panel of <a href="#fig-nnet-sg-iterations" class="quarto-xref">Figure&nbsp;<span>12.10</span></a> shows the RMSE values over iterations and <a href="#tbl-nnet-sg-best" class="quarto-xref">Table&nbsp;<span>12.3</span></a> lists the best candidate value.</p>
<div class="cell" data-layout-align="center" data-fig-altalt="Comparison of two optimization methods - SA (top) and BO (bottom) - showing RMSE values over 50 iterations. Both plots display RMSE (3-15 scale) vs. iteration number with error bars. Orange points mark new optimal values. Both methods show gradual error reduction, with Bayesian Optimization achieving lower and more stable RMSE values.">
<div class="cell-output-display">
<div id="fig-nnet-sg-iterations" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nnet-sg-iterations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="iterative-search_files/figure-html/fig-nnet-sg-iterations-1.svg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nnet-sg-iterations-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.10: Validation set RMSE results for the optimization. The validation set RMSE is shown on the y-axis with 90% confidence intervals. Orange points indicate iterations where a new optimal value was found and vertical lines indicate where the algorithm restarted from the previous best candidate.
</figcaption>
</figure>
</div>
</div>
</div>
<p>A Bayesian optimization was also used with a squared exponential kernel for the covariance function and used expected improvement to select candidates at each of the 50 iterations. This search found new best results at 3 iterations: 1, 10, and 47. Like the SA search, the best RMSE was substantially different than the one found in the initial grid: 3.58% with 90% confidence interval, (3.3%, 3.87%). The iterations and final values also be seen in <a href="#fig-nnet-sg-iterations" class="quarto-xref">Figure&nbsp;<span>12.10</span></a> and <a href="#tbl-nnet-sg-best" class="quarto-xref">Table&nbsp;<span>12.3</span></a>, respectively.</p>
<div class="columns">
<div class="column" style="width:15%;">

</div><div class="column" style="width:70%;">
<div id="tbl-nnet-sg-best" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-nnet-sg-best-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="table-responsive">
<table class="table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Initial Grid</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Simulated Annealing</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Bayesian Optimzation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Differentiation Order</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">Polynomial Degree</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">8</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Window Size</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">21</td>
</tr>
<tr class="even">
<td style="text-align: left;">Hidden Units</td>
<td style="text-align: left;">27</td>
<td style="text-align: left;">27</td>
<td style="text-align: left;">53</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Activation</td>
<td style="text-align: left;">elu</td>
<td style="text-align: left;">relu</td>
<td style="text-align: left;">tanh</td>
</tr>
<tr class="even">
<td style="text-align: left;">Penalty (log10)</td>
<td style="text-align: left;">-7.89</td>
<td style="text-align: left;">-9.00</td>
<td style="text-align: left;">-8.22</td>
</tr>
<tr class="odd">
<td style="text-align: left;">L1 Proportion</td>
<td style="text-align: left;">0.421</td>
<td style="text-align: left;">0.212</td>
<td style="text-align: left;">0.112</td>
</tr>
<tr class="even">
<td style="text-align: left;">Learning Rate (log10)</td>
<td style="text-align: left;">-1.84</td>
<td style="text-align: left;">-1.39</td>
<td style="text-align: left;">-1.97</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Rate Schedule</td>
<td style="text-align: left;">none</td>
<td style="text-align: left;">cyclic</td>
<td style="text-align: left;">cyclic</td>
</tr>
<tr class="even">
<td style="text-align: left;">Stopping Rule</td>
<td style="text-align: left;">12</td>
<td style="text-align: left;">14</td>
<td style="text-align: left;">14</td>
</tr>
<tr class="odd">
<td style="text-align: left;">RMSE</td>
<td style="text-align: left;">4.32%</td>
<td style="text-align: left;">3.65%</td>
<td style="text-align: left;">3.58%</td>
</tr>
<tr class="even">
<td style="text-align: left;">Conf. Int.</td>
<td style="text-align: left;">(4.03%, 4.6%)</td>
<td style="text-align: left;">(3.41%, 3.9%)</td>
<td style="text-align: left;">(3.3%, 3.87%)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-nnet-sg-best-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.3: The best results from the initial space-filling design and the two iterative searches for a neural network using Savitzky-Golay preprocessing.
</figcaption>
</figure>
</div>
</div><div class="column" style="width:15%;">

</div>
</div>
<p>Many of the parameter values for the final candidates from each search are very similar. In particular, the learning rates, regularization penalties, and SG window sizes where nearly the same.</p>
<p>In terms of computing time, simulated annealing took 1m 55.9s on average for each candidate and compared to 3m 22.3s required for BO (a 1.7-fold difference).</p>
</section>
<section id="sec-iterative-summary" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="sec-iterative-summary"><span class="header-section-number">12.8</span> Summary</h2>
<p>There are several different ways to tune models sequentially. For tabular data, these approaches are rarely the only efficient method for model optimization, but they may be preferable for certain models and large data sets.</p>
</section>
<section id="chapter-references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="chapter-references">Chapter References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-ameli2022noise" class="csl-entry" role="listitem">
Ameli, S, and S Shadden. 2022. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Noise+estimation+in+Gaussian+process+regression&amp;as_ylo=2022&amp;as_yhi=2022&amp;btnG=">Noise Estimation in Gaussian Process Regression</a>.”</span> <em>arXiv</em>.
</div>
<div id="ref-azimi2010batch" class="csl-entry" role="listitem">
Azimi, J, A Fern, and X Fern. 2010. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Batch+Bayesian+optimization+via+simulation+matching&amp;as_ylo=2010&amp;as_yhi=2010&amp;btnG=">Batch Bayesian Optimization via Simulation Matching</a>.”</span> <em>Advances in Neural Information Processing Systems</em> 23.
</div>
<div id="ref-binois2022survey" class="csl-entry" role="listitem">
Binois, M, and N Wycoff. 2022. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+survey+on+high+dimensional+Gaussian+process+modeling+with+application+to+Bayesian+optimization&amp;as_ylo=2022&amp;as_yhi=2022&amp;btnG=">A Survey on High-Dimensional Gaussian Process Modeling with Application to Bayesian Optimization</a>.”</span> <em>ACM Transactions on Evolutionary Learning and Optimization</em> 2 (2): 1–26.
</div>
<div id="ref-bland1998bayesians" class="csl-entry" role="listitem">
Bland, J, and D Altman. 1998. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Bayesians+and+frequentists&amp;as_ylo=1998&amp;as_yhi=1998&amp;btnG=">Bayesians and Frequentists</a>.”</span> <em>Bmj</em> 317 (7166): 1151–60.
</div>
<div id="ref-breiman1997no" class="csl-entry" role="listitem">
Breiman, L. 1997. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=No+Bayesians+in+foxholes&amp;as_ylo=1997&amp;as_yhi=1997&amp;btnG=">No <span>Bayesians</span> in Foxholes</a>.”</span> <em>IEEE Expert</em> 12 (6): 21–24.
</div>
<div id="ref-chitty2005clinicians" class="csl-entry" role="listitem">
Chitty, R. 2005. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Why+clinicians+are+natural+Bayesians+Is+there+a+Bayesian+doctor+in+the+house+&amp;as_ylo=2005&amp;as_yhi=2005&amp;btnG=">Why Clinicians Are Natural <span>Bayesians</span>: Is There a <span>Bayesian</span> Doctor in the House?</a>”</span> <em>BMJ: British Medical Journal</em> 330 (7504): 1390.
</div>
<div id="ref-cox1992statistical" class="csl-entry" role="listitem">
Cox, D, and S John. 1992. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+statistical+method+for+global+optimization&amp;as_ylo=1992&amp;as_yhi=1992&amp;btnG=">A Statistical Method for Global Optimization</a>.”</span> In <em><span>[Proceedings]</span> 1992 IEEE International Conference on Systems, Man, and Cybernetics</em>, 1241–46. IEEE.
</div>
<div id="ref-eiben2015introduction" class="csl-entry" role="listitem">
Eiben, A, and J Smith. 2015. <em>Introduction to Evolutionary Computing</em>. Springer.
</div>
<div id="ref-fornacon2022understanding" class="csl-entry" role="listitem">
Fornacon-Wood, I, H Mistry, C Johnson-Hart, C Faivre-Finn, J O’Connor, and G Price. 2022. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Understanding+the+differences+between+Bayesian+and+frequentist+statistics&amp;as_ylo=2022&amp;as_yhi=2022&amp;btnG=">Understanding the Differences Between Bayesian and Frequentist Statistics</a>.”</span> <em>International Journal of Radiation Oncology, Biology, Physics</em> 112 (5): 1076–82.
</div>
<div id="ref-garnett2023" class="csl-entry" role="listitem">
Garnett, R. 2023. <em><a href="https://bayesoptbook.com/">Bayesian Optimization</a></em>. Cambridge University Press.
</div>
<div id="ref-genton2001classes" class="csl-entry" role="listitem">
Genton, M. 2001. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Classes+of+kernels+for+machine+learning+a+statistics+perspective&amp;as_ylo=2001&amp;as_yhi=2001&amp;btnG=">Classes of Kernels for Machine Learning: A Statistics Perspective</a>.”</span> <em>Journal of Machine Learning Research</em> 2 (Dec): 299–312.
</div>
<div id="ref-gill2005clinicians" class="csl-entry" role="listitem">
Gill, C, L Sabin, and C Schmid. 2005. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Why+clinicians+are+natural+Bayesians+&amp;as_ylo=2005&amp;as_yhi=2005&amp;btnG=">Why Clinicians Are Natural <span>Bayesians</span></a>.”</span> <em>Bmj</em> 330 (7499): 1080–83.
</div>
<div id="ref-gramacy2020surrogates" class="csl-entry" role="listitem">
Gramacy, R. 2020. <em><a href="http://bobby.gramacy.com/surrogates/">Surrogates: <span>G</span>aussian Process Modeling, Design and Optimization for the Applied Sciences</a></em>. Chapman Hall/CRC.
</div>
<div id="ref-hofmann2008" class="csl-entry" role="listitem">
Hofmann, T, B Schölkopf, and A Smola. 2008. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Kernel+methods+in+machine+learning&amp;as_ylo=2008&amp;as_yhi=2008&amp;btnG=">Kernel Methods in Machine Learning</a>.”</span> <em>The Annals of Statistics</em> 36 (3): 1171–1220.
</div>
<div id="ref-hutchon2005clinicians" class="csl-entry" role="listitem">
Hutchon, D. 2005. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Why+clinicians+are+natural+Bayesians+Bayesian+confusion&amp;as_ylo=2005&amp;as_yhi=2005&amp;btnG=">Why Clinicians Are Natural <span>Bayesians</span>: <span>Bayesian</span> Confusion</a>.”</span> <em>BMJ: British Medical Journal</em> 330 (7504): 1390.
</div>
<div id="ref-jones2001taxonomy" class="csl-entry" role="listitem">
Jones, D. 2001. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+taxonomy+of+global+optimization+methods+based+on+response+surfaces&amp;as_ylo=2001&amp;as_yhi=2001&amp;btnG=">A Taxonomy of Global Optimization Methods Based on Response Surfaces</a>.”</span> <em>Journal of Global Optimization</em> 21: 345–83.
</div>
<div id="ref-jones1998efficient" class="csl-entry" role="listitem">
Jones, D, M Schonlau, and W Welch. 1998. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Efficient+global+optimization+of+expensive+black+box+functions&amp;as_ylo=1998&amp;as_yhi=1998&amp;btnG=">Efficient Global Optimization of Expensive Black-Box Functions</a>.”</span> <em>Journal of Global Optimization</em> 13: 455–92.
</div>
<div id="ref-joseph2007functionally" class="csl-entry" role="listitem">
Joseph, R, and J Delaney. 2007. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Functionally+induced+priors+for+the+analysis+of+experiments&amp;as_ylo=2007&amp;as_yhi=2007&amp;btnG=">Functionally Induced Priors for the Analysis of Experiments</a>.”</span> <em>Technometrics</em> 49 (1): 1–11.
</div>
<div id="ref-kirkpatrick1983optimization" class="csl-entry" role="listitem">
Kirkpatrick, S, D Gelatt, and M Vecchi. 1983. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Optimization+by+simulated+annealing&amp;as_ylo=1983&amp;as_yhi=1983&amp;btnG=">Optimization by Simulated Annealing</a>.”</span> <em>Science</em> 220 (4598): 671–80.
</div>
<div id="ref-lu2022gradient" class="csl-entry" role="listitem">
Lu, J. 2022. <em><a href="https://arxiv.org/abs/2205.00832">Gradient Descent, Stochastic Optimization, and Other Tales</a></em>. Eliva Press.
</div>
<div id="ref-mccrossin2005clinicians" class="csl-entry" role="listitem">
McCrossin, R. 2005. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Why+clinicians+are+natural+Bayesians+Clinicians+have+to+be+Bayesians+&amp;as_ylo=2005&amp;as_yhi=2005&amp;btnG=">Why Clinicians Are Natural <span>Bayesians</span>: Clinicians Have to Be <span>Bayesians</span></a>.”</span> <em>BMJ: British Medical Journal</em> 330 (7504): 1390.
</div>
<div id="ref-Mitchell1996AnIT" class="csl-entry" role="listitem">
Mitchell, M. 1996. <em>An Introduction to Genetic Algorithms</em>. MIT Press.
</div>
<div id="ref-movckus1975bayesian" class="csl-entry" role="listitem">
Močkus, J. 1975. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=On+Bayesian+methods+for+seeking+the+extremum&amp;as_ylo=1975&amp;as_yhi=1975&amp;btnG=">On Bayesian Methods for Seeking the Extremum</a>.”</span> In <em>Optimization Techniques IFIP Technical Conference</em>, 400–404. Springer.
</div>
<div id="ref-udl2023" class="csl-entry" role="listitem">
Prince, S. 2023. <em><a href="https://udlbook.github.io/udlbook/">Understanding Deep Learning</a></em>. MIT press.
</div>
<div id="ref-qian2008bayesian" class="csl-entry" role="listitem">
Qian, P, and CF Jeff Wu. 2008. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Bayesian+hierarchical+modeling+for+integrating+low+accuracy+and+high+accuracy+experiments&amp;as_ylo=2008&amp;as_yhi=2008&amp;btnG=">Bayesian Hierarchical Modeling for Integrating Low-Accuracy and High-Accuracy Experiments</a>.”</span> <em>Technometrics</em> 50 (2): 192–204.
</div>
<div id="ref-rana1999distributional" class="csl-entry" role="listitem">
Rana, S. 1999. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=The+distributional+biases+of+crossover+operators&amp;as_ylo=1999&amp;as_yhi=1999&amp;btnG=">The Distributional Biases of Crossover Operators</a>.”</span> In <em>Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1</em>, 549–56.
</div>
<div id="ref-rinnan2009review" class="csl-entry" role="listitem">
Rinnan, A, F Van Den Berg, and S Engelsen. 2009. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Review+of+the+most+common+pre+processing+techniques+for+near+infrared+spectra&amp;as_ylo=2009&amp;as_yhi=2009&amp;btnG=">Review of the Most Common Pre-Processing Techniques for Near-Infrared Spectra</a>.”</span> <em>Trends in Analytical Chemistry</em> 28 (10): 1201–22.
</div>
<div id="ref-saves2023mixed" class="csl-entry" role="listitem">
Saves, P, Y Diouane, N Bartoli, T Lefebvre, and J Morlier. 2023. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+mixed+categorical+correlation+kernel+for+Gaussian+process&amp;as_ylo=2023&amp;as_yhi=2023&amp;btnG=">A Mixed-Categorical Correlation Kernel for Gaussian Process</a>.”</span> <em>Neurocomputing</em> 550: 126472.
</div>
<div id="ref-Schafer2011" class="csl-entry" role="listitem">
Schafer, R. 2011. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=What+Is+a+Savitzky+Golay+Filter+&amp;as_ylo=2011&amp;as_yhi=2011&amp;btnG=">What Is a Savitzky-Golay Filter?</a>”</span> <em>IEEE Signal Processing Magazine</em> 28 (4): 111–17.
</div>
<div id="ref-scholkopf2001" class="csl-entry" role="listitem">
Schölkopf, B, and A Smola. 2001. <em>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</em>. The MIT Press.
</div>
<div id="ref-cristianini2004" class="csl-entry" role="listitem">
Shawe-Taylor, J., and N. Cristianini. 2004. <em>Kernel Methods for Pattern Analysis</em>. <span>C</span>ambridge <span>U</span>niversity Press.
</div>
<div id="ref-Soule2009" class="csl-entry" role="listitem">
Soule, T. 2009. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Crossover+and+Sampling+Biases+on+Nearly+Uniform+Landscapes&amp;as_ylo=2009&amp;as_yhi=2009&amp;btnG=">Crossover and Sampling Biases on Nearly Uniform Landscapes</a>.”</span> In <em>Genetic Programming Theory and Practice VI</em>, 1–15. Springer US.
</div>
<div id="ref-spall2005introduction" class="csl-entry" role="listitem">
Spall, J. 2005. <em>Introduction to Stochastic Search and Optimization: Estimation, Simulation, and Control</em>. John Wiley &amp; Sons.
</div>
<div id="ref-Wagenmakers2008" class="csl-entry" role="listitem">
Wagenmakers, E, M Lee, T Lodewyckx, and G Iverson. 2008. <span>“Bayesian Evaluation of Informative Hypotheses.”</span> In, edited by H Hoijtink, I Klugkist, and P Boelen, 181–207. New York, NY: Springer New York.
</div>
<div id="ref-williams2006gaussian" class="csl-entry" role="listitem">
Williams, C, and C Rasmussen. 2006. <em><a href="https://gaussianprocess.org/gpml">Gaussian Processes for Machine Learning</a></em>. MIT press Cambridge, MA.
</div>
<div id="ref-zhang2019gradient" class="csl-entry" role="listitem">
Zhang, J. 2019. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=Gradient+descent+based+optimization+algorithms+for+deep+learning+models+training&amp;as_ylo=2019&amp;as_yhi=2019&amp;btnG=">Gradient Descent Based Optimization Algorithms for Deep Learning Models Training</a>.”</span> <em>arXiv</em>.
</div>
<div id="ref-zhou2011simple" class="csl-entry" role="listitem">
Zhou, Q, P Qian, and S Zhou. 2011. <span>“<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C7&amp;q=A+simple+approach+to+emulation+for+computer+models+with+qualitative+and+quantitative+factors&amp;as_ylo=2011&amp;as_yhi=2011&amp;btnG=">A Simple Approach to Emulation for Computer Models with Qualitative and Quantitative Factors</a>.”</span> <em>Technometrics</em> 53 (3): 266–73.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Sections <span class="quarto-unresolved-ref">?sec-cls-svm</span> and <span class="quarto-unresolved-ref">?sec-reg-svm</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Sections <span class="quarto-unresolved-ref">?sec-cls-nnet</span> and <span class="quarto-unresolved-ref">?sec-reg-nnet</span><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Why do these two parameters use different bases? It’s mostly a convention. Both parameters have valid values that can range across many orders of magnitude. The change in cost tends to occur more slowly than the scaling factor, so a smaller base of 2 is often used.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>These are not simulated data, so this surface is an approximation of the true RMSE via the validation set using a very large regular grid. The RMSE results are estimates and would change if we used different random numbers for data splitting.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>We’ve seen <span class="math inline">\(\alpha\)</span> before when it was called the learning rate (and will revisit it later in this chapter).<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>However, computing the Hessian matrix increases the computational cost by about 3-fold.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>These values will be also used as the initial substrate for Bayesian optimization.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Think of the candidates within a generation as a population of people.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Analogous to chromosomes.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>If you have access to high-performance computing infrastructure, the parallel processing can run the individuals in the population in parallel and, within these, any resampling iterations can also be parallelized.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>We’ll see how the prior can affect some calculations later in <span class="quarto-unresolved-ref">?sec-naive-bayes</span>. <a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/aml4td\.org");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/grid-search.html" class="pagination-link" aria-label="Grid Search">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Grid Search</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/feature-selection.html" class="pagination-link" aria-label="Feature Selection">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Feature Selection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>




</body></html>